[
  {
    "id": "9ca4b5e1-5141-4e46-a05a-38aad46e31ec",
    "question_text_en": "Which technique involves reducing the precision of model parameters to achieve a smaller model size and faster inference?",
    "question_text_ko": "어떤 기술이 모델 매개변수의 정밀도를 낮춰 더 작은 모델 크기와 더 빠른 추론을 달성하는 것일까요?",
    "options_en": [
      "Pruning",
      "Quantization",
      "Knowledge Distillation",
      "Transfer Learning"
    ],
    "options_ko": [
      "전정",
      "양자화",
      "지식 증류",
      "전이 학습"
    ],
    "correct_answer": 1,
    "category": "Model Optimization",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_1_e.png",
    "source_image_ko": "day10_1_h.png",
    "created_at": "2025-11-29T12:56:06.959917+00:00",
    "updated_at": "2025-11-29T12:56:06.959917+00:00"
  },
  {
    "id": "b6665b20-ef91-46ae-a2f6-276bddda461d",
    "question_text_en": "How does ONNX act as an \"interoperability bridge\"?",
    "question_text_ko": "ONNX는 어떻게 '상호운용성 브리지' 역할을 하나요?",
    "options_en": [
      "It translates code between different programming languages used in machine learning.",
      "It enables seamless exchange and deployment of models across various frameworks and hardware platforms.",
      "It creates a standardized API for interacting with all machine learning models.",
      "It provides a cloud-based platform for storing and sharing machine learning models."
    ],
    "options_ko": [
      "머신 러닝에 사용되는 다양한 프로그래밍 언어 간의 코드를 번역합니다.",
      "다양한 프레임워크와 하드웨어 플랫폼에서 모델을 원활하게 교환하고 배포할 수 있습니다.",
      "모든 머신 러닝 모델과 상호작용하기 위한 표준화된 API를 만듭니다.",
      "머신 러닝 모델을 저장하고 공유하기 위한 클라우드 기반 플랫폼을 제공합니다."
    ],
    "correct_answer": 1,
    "category": "ONNX",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_1_e.png",
    "source_image_ko": "day10_1_h.png",
    "created_at": "2025-11-29T12:56:07.177589+00:00",
    "updated_at": "2025-11-29T12:56:07.177589+00:00"
  },
  {
    "id": "dc15cfaa-2618-49a4-b3a0-6d6abfc6d365",
    "question_text_en": "What is the key benefit of using ONNX Runtime?",
    "question_text_ko": "ONNX 런타임을 사용하는 주요 이점은 무엇입니까?",
    "options_en": [
      "It simplifies the process of training machine learning models.",
      "It optimizes model execution for improved performance across diverse platforms.",
      "It automatically generates synthetic data for training models.",
      "It ensures that all models achieve the same level of accuracy."
    ],
    "options_ko": [
      "머신 러닝 모델을 실행하는 과정을 간소화합니다.",
      "다양한 플랫폼에서 성능을 향상시키기 위해 모델 실행을 최적화합니다.",
      "모델을 훈련하기 위한 합성 데이터를 자동으로 생성합니다.",
      "이를 통해 모든 모델이 동일한 수준의 정확도를 달성할 수 있습니다."
    ],
    "correct_answer": 1,
    "category": "ONNX",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_1_e.png",
    "source_image_ko": "day10_1_h.png",
    "created_at": "2025-11-29T12:56:07.221873+00:00",
    "updated_at": "2025-11-29T12:56:07.221873+00:00"
  },
  {
    "id": "bd0cb03b-b493-4e1c-9afe-dd37d85997eb",
    "question_text_en": "What is meant by \"model drift\" in the context of large language models (LLMs)?",
    "question_text_ko": "대규모 언어 모델(LLM)의 맥락에서 '모델 드리프트'란 무엇을 의미합니까?",
    "options_en": [
      "The model's ability to adapt to new language patterns over time.",
      "The gradual decrease in a model's accuracy and effectiveness due to changes in data distribution",
      "The tendency of a model to generate biased or harmful content",
      "The process of fine-tuning a pre-trained model on a specific task."
    ],
    "options_ko": [
      "시간이 지남에 따라 새로운 언어 패턴에 적응할 수 있는 모델의 능력.",
      "데이터의 분포가 변화로 인해 모델의 정확도와 효과성이 점차 감소하는 현상",
      "모델이 편향적이거나 유해한 콘텐츠를 생성하는 경향",
      "특정 작업에 맞춰 사전 학습된 모델을 미세 조정하는 과정입니다."
    ],
    "correct_answer": 1,
    "category": "Model Evaluation",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_1_e.png",
    "source_image_ko": "day10_1_h.png",
    "created_at": "2025-11-29T12:56:07.26219+00:00",
    "updated_at": "2025-11-29T12:56:07.26219+00:00"
  },
  {
    "id": "ad39bfad-d71d-4129-b39e-668f292f8aa1",
    "question_text_en": "The F1 Score is calculated as the:",
    "question_text_ko": "F1 점수는 다음과 같이 계산됩니다.",
    "options_en": [
      "Arithmetic mean of precision and recall",
      "Harmonic mean of precision and recall",
      "Product of precision and recall",
      "Difference between precision and recall"
    ],
    "options_ko": [
      "정밀도와 재현율의 산술 평균",
      "정밀도와 재현율의 조화 평균",
      "정밀도와 재현율의 차이",
      "정밀도와 재현율의 곱"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_2_e.png",
    "source_image_ko": "day10_2_h.png",
    "created_at": "2025-11-29T12:56:07.330575+00:00",
    "updated_at": "2025-11-29T12:56:07.330575+00:00"
  },
  {
    "id": "5dc50557-6179-48cd-8d5e-0c181af7dc33",
    "question_text_en": "What is the primary focus of NVIDIA AI Enterprise?",
    "question_text_ko": "NVIDIA AI Enterprise의 주요 초점은 무엇입니까?",
    "options_en": [
      "Developing cutting-edge hardware for AI research.",
      "Providing a comprehensive platform for the entire AI model lifecycle.",
      "Exclusively focusing on large language model (LLM) development.",
      "Creating open-source AI frameworks and libraries."
    ],
    "options_ko": [
      "AI 연구를 위한 최첨단 하드웨어 개발",
      "AI 모델 수명 주기 전반에 대한 포괄적인 플랫폼을 제공합니다.",
      "대규모 언어 모델(LLM) 개발에만 집중합니다.",
      "오픈소스 프레임워크와 라이브러리를 만듭니다."
    ],
    "correct_answer": 1,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_2_e.png",
    "source_image_ko": "day10_2_h.png",
    "created_at": "2025-11-29T12:56:07.372393+00:00",
    "updated_at": "2025-11-29T12:56:07.372393+00:00"
  },
  {
    "id": "76b09821-7c4e-4d40-bb92-7061b14c9cc1",
    "question_text_en": "Which of the following is a common deployment strategy for Large Language Models (LLMs)?",
    "question_text_ko": "다음 중 대규모 언어 모델(LLM)에 대한 일반적인 배포 전략은 무엇입니까?",
    "options_en": [
      "Deploying the model as a cloud-based API",
      "Running the model only on local machines without any networking",
      "Avoiding scaling considerations for inference",
      "Using only on-premises hardware with no updates"
    ],
    "options_ko": [
      "모델을 클라우드 기반 API로 배포",
      "네트워크 없이 로컬 머신에서 모델 실행",
      "추론을 위한 스케일링 고려 사항 피하기",
      "업데이트 없이 온프레미스 하드웨어만 사용"
    ],
    "correct_answer": 0,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_2_e.png",
    "source_image_ko": "day10_2_h.png",
    "created_at": "2025-11-29T12:56:07.421201+00:00",
    "updated_at": "2025-11-29T12:56:07.421201+00:00"
  },
  {
    "id": "5af28f9c-2c70-4ebe-857a-15f30ea63ecd",
    "question_text_en": "Which of the following is a common metric used to monitor LLMs in production?",
    "question_text_ko": "다음 중 프로덕션에서 LLM을 모니터링하는 데 사용되는 일반적인 지표는 무엇입니까?",
    "options_en": [
      "Number of training epochs",
      "Response latency",
      "Model parameter count",
      "Number of layers in the neural network"
    ],
    "options_ko": [
      "훈련 에포크 수",
      "응답 지연 시간",
      "모델 매개변수 개수",
      "신경망의 계층 수"
    ],
    "correct_answer": 1,
    "category": "Monitoring and Evaluation",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_2_e.png",
    "source_image_ko": "day10_2_h.png",
    "created_at": "2025-11-29T12:56:07.47739+00:00",
    "updated_at": "2025-11-29T12:56:07.47739+00:00"
  },
  {
    "id": "0ae8b53e-32dd-49bf-a7a1-4c35f69bbcec",
    "question_text_en": "What is the primary benefit of using NVIDIA’s ecosystem for LLM deployment?",
    "question_text_ko": "LLM 배포에 NVIDIA의 생태계를 사용하는 주요 이점은 무엇입니까?",
    "options_en": [
      "Hardware-accelerated inference and training for high-efficiency",
      "Completely replacing deep learning frameworks like PyTorch and TensorFlow",
      "Eliminating the need for cloud-based deployments",
      "Avoiding AI model fine-tuning"
    ],
    "options_ko": [
      "고효율을 위한 하드웨어 가속을 통한 학습",
      "PyTorch나 TensorFlow와 같은 딥러닝 프레임워크를 완전히 대체",
      "클라우드 기반 배포의 필요성 제거",
      "AI 모델 미세 조정 방지"
    ],
    "correct_answer": 0,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": 10,
    "source_image_en": "day10_2_e.png",
    "source_image_ko": "day10_2_h.png",
    "created_at": "2025-11-29T12:56:07.523256+00:00",
    "updated_at": "2025-11-29T12:56:07.523256+00:00"
  },
  {
    "id": "dc47a84c-1d36-4bee-bf94-bfe5d50c29f1",
    "question_text_en": "What is the primary purpose of prompt engineering?",
    "question_text_ko": "신속한 엔지니어링의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train an AI language model from scratch",
      "To unlock the full potential of an AI language model and get the best possible results",
      "To replace human writers with AI",
      "To limit the capabilities of an AI language model"
    ],
    "options_ko": [
      "AI 언어 모델을 처음부터 훈련하려면",
      "AI 언어 모델의 잠재력을 최대한 활용하여 최상의 결과를 얻으려면",
      "인간 작가를 새로 대체하기 위해",
      "AI 언어 모델의 기능을 제한하려면"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_1_e.png",
    "source_image_ko": "day11_1_h.png",
    "created_at": "2025-11-29T12:56:07.585417+00:00",
    "updated_at": "2025-11-29T12:56:07.585417+00:00"
  },
  {
    "id": "eabe441c-e299-4969-80b8-11f59a49af93",
    "question_text_en": "In a scenario where even small errors can have significant consequences, which metric would you pay more attention to?",
    "question_text_ko": "2. 아무리 작은 오류라도 중대한 결과를 초래할 수 있는 상황에서 어떤 지표에 더 많은 주의를 기울여야 할까요?",
    "options_en": [
      "MAE",
      "RMSE",
      "R-squared",
      "It depends on the specific context."
    ],
    "options_ko": [
      "정확도",
      "RMSE",
      "R제곱",
      "이는 구체적인 상황에 따라 달라집니다."
    ],
    "correct_answer": 0,
    "category": "Model Evaluation Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:09.891047+00:00",
    "updated_at": "2025-11-29T12:56:09.891047+00:00"
  },
  {
    "id": "8074dce6-88a4-45b8-a195-b407a80efc9e",
    "question_text_en": "What is prompt design in the context of AI language models?",
    "question_text_ko": "AI 언어 모델의 맥락에서 신속한 디자인이란 무엇인가?",
    "options_en": [
      "A random process of generating input for the model",
      "The art of crafting clear and specific instructions to guide the AI's output",
      "A complex coding language used to program AI models",
      "A method for limiting the AI's capabilities"
    ],
    "options_ko": [
      "모델에 대한 입력을 생성하는 무작위 프로세스",
      "AI의 출력을 안내하기 위한 명확하고 구체적인 지침을 작성하는 기술",
      "AI 모델을 프로그래밍하는 데 사용되는 복잡한 코딩 언어",
      "AI의 역할을 제한하는 방법"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_1_e.png",
    "source_image_ko": "day11_1_h.png",
    "created_at": "2025-11-29T12:56:07.632002+00:00",
    "updated_at": "2025-11-29T12:56:07.632002+00:00"
  },
  {
    "id": "4b8e6cdf-9e89-47e7-a9c0-f38fd9773c97",
    "question_text_en": "What is the primary purpose of providing context in prompts for AI language models?",
    "question_text_ko": "AI 언어 모델의 프롬프트에서 맥락을 제공하는 주된 목적은 무엇입니까?",
    "options_en": [
      "To confuse the AI and test its capabilities",
      "To guide the AI's understanding and steer its output in the desired direction",
      "To make the prompt longer and more complex",
      "To provide the AI with irrelevant information"
    ],
    "options_ko": [
      "AI를 훈련스럽게 하고 그 능력을 테스트하기 위해",
      "AI의 이해를 안내하고 원하는 방향으로 출력을 조정합니다.",
      "프롬프트를 더 길고 복잡하게 만들려면",
      "AI에게 관련 없는 정보를 제공하기 위해"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_1_e.png",
    "source_image_ko": "day11_1_h.png",
    "created_at": "2025-11-29T12:56:07.689612+00:00",
    "updated_at": "2025-11-29T12:56:07.689612+00:00"
  },
  {
    "id": "a305bb41-6e55-4c39-9d9e-06778f8d5c7b",
    "question_text_en": "What is the primary goal of PEFT in the context of large language models (LLMs)?",
    "question_text_ko": "대규모 언어 모델(LLM)의 맥락에서 PET의 주요 목표는 무엇입니까?",
    "options_en": [
      "To train a new LLM from scratch",
      "To efficiently adapt pre-trained LLMs to specific tasks",
      "To reduce the size of pre-trained LLMs",
      "To improve the general language understanding of LLMs"
    ],
    "options_ko": [
      "새로운 LLM을 처음부터 교육하려면",
      "사전 훈련된 LLM을 특정 작업에 효율적으로 적용하려면",
      "사전 훈련된 LLM의 크기를 줄이려면",
      "LLM의 일반적인 언어 이해력을 향상시키기 위해"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_1_e.png",
    "source_image_ko": "day11_1_h.png",
    "created_at": "2025-11-29T12:56:07.797105+00:00",
    "updated_at": "2025-11-29T12:56:07.797105+00:00"
  },
  {
    "id": "b3514b68-596d-476a-8a33-ca74346496c5",
    "question_text_en": "What is the primary focus of prompt learning in natural language processing?",
    "question_text_ko": "자연어 처리에서 신속한 학습의 주요 초점은 무엇입니까?",
    "options_en": [
      "Training language models from scratch on massive datasets",
      "Improving the general language understanding capabilities of language models",
      "Teaching language models to better understand and respond to instructions or prompts",
      "Reducing the size of pre-trained language models"
    ],
    "options_ko": [
      "대규모 데이터 세트를 기반으로 처음부터 언어 모델 학습",
      "언어 모델의 일반 언어 이해 능력 향상",
      "지나친 프로프트를 더 잘 이해하고 이에 대응하기 위한 언어 모델 교육",
      "사전 학습된 언어 모델의 크기 줄이기"
    ],
    "correct_answer": 2,
    "category": "Natural Language Processing",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_2_e.png",
    "source_image_ko": "day11_2_h.png",
    "created_at": "2025-11-29T12:56:07.836957+00:00",
    "updated_at": "2025-11-29T12:56:07.836957+00:00"
  },
  {
    "id": "e36d60ef-f818-447d-9408-937f968b537a",
    "question_text_en": "What is the primary purpose of NVIDIA NeMo?",
    "question_text_ko": "NVIDIA NeMo의 주요 목적은 무엇입니까?",
    "options_en": [
      "To create realistic images and videos",
      "To simplify and accelerate the development and deployment of conversational AI models",
      "To analyze large datasets for business insights",
      "To translate text between different languages"
    ],
    "options_ko": [
      "사실적인 이미지와 비디오를 만들려면",
      "대화형 AI 모델의 개발 및 배포를 단순화하고 가속화하기 위해",
      "비즈니스 통찰력을 위해 대규모 데이터 세트를 분석하려면",
      "다양한 언어 간의 텍스트를 번역하려면"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_2_e.png",
    "source_image_ko": "day11_2_h.png",
    "created_at": "2025-11-29T12:56:07.873788+00:00",
    "updated_at": "2025-11-29T12:56:07.873788+00:00"
  },
  {
    "id": "50ff4f5f-a9b2-45bf-b9b7-6b7194dfab44",
    "question_text_en": "Why is it important to experiment with various prompts when working with AI language models?",
    "question_text_ko": "AI 언어 모델을 사용할 때 다양한 프롬프트를 실행하는 것이 왜 중요한가요?",
    "options_en": [
      "To keep the AI entertained and prevent boredom.",
      "To discover the most effective prompts for achieving desired outcomes.",
      "To trick the AI into revealing its hidden capabilities.",
      "To generate random and unpredictable responses."
    ],
    "options_ko": [
      "AI를 즐겁게 해주고 지루함을 방지하기 위해서입니다.",
      "원하는 결과를 얻기 위한 효과적인 프롬프트를 발견하세요.",
      "AI를 속여 숨겨진 능력을 드러내게 하는 것입니다.",
      "무작위적이고 예측할 수 없는 반응을 생성합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_2_e.png",
    "source_image_ko": "day11_2_h.png",
    "created_at": "2025-11-29T12:56:07.911436+00:00",
    "updated_at": "2025-11-29T12:56:07.911436+00:00"
  },
  {
    "id": "21a2ba83-a0e8-4766-bfc3-78c30dfb9435",
    "question_text_en": "What is the primary purpose of Retrieval Augmented Generation (RAG)?",
    "question_text_ko": "검색 증강 생성(RAG)의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train large language models (LLMs) from scratch",
      "To enhance the capabilities of LLMs by combining them with external knowledge sources",
      "To reduce the size of LLMs",
      "To replace human knowledge with AI"
    ],
    "options_ko": [
      "대규모 언어 모델(LLM)을 처음부터 훈련하려면",
      "외부 지식 소스와 결합하여 LLM의 역량을 강화합니다.",
      "LLM의 크기를 줄이려면",
      "인간의 지식을 AI로 대체하기 위해"
    ],
    "correct_answer": 1,
    "category": "Retrieval-Augmented Generation",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_2_e.png",
    "source_image_ko": "day11_2_h.png",
    "created_at": "2025-11-29T12:56:07.952728+00:00",
    "updated_at": "2025-11-29T12:56:07.952728+00:00"
  },
  {
    "id": "74bfd1fb-915a-4446-8d37-81c0f9fc35ab",
    "question_text_en": "Which type of database is commonly used in RAG for efficient document retrieval?",
    "question_text_ko": "RAG에서는 효율적인 문서 검색을 위해 일반적으로 어떤 유형의 데이터베이스를 사용합니까?",
    "options_en": [
      "Relational databases (SQL)",
      "Blockchain databases",
      "Flat file storage",
      "Vector databases"
    ],
    "options_ko": [
      "관계형 데이터베이스(SQL)",
      "블록체인 데이터베이스",
      "클라우드 파일 저장",
      "벡터 데이터베이스"
    ],
    "correct_answer": 3,
    "category": "Retrieval-Augmented Generation",
    "difficulty": "medium",
    "source_day": 11,
    "source_image_en": "day11_2_e.png",
    "source_image_ko": "day11_2_h.png",
    "created_at": "2025-11-29T12:56:07.986339+00:00",
    "updated_at": "2025-11-29T12:56:07.986339+00:00"
  },
  {
    "id": "88ad6c55-2f50-4f21-8183-d5b28457d7cf",
    "question_text_en": "Which of the following visualization techniques is best suited for displaying the frequency of different categories or items?",
    "question_text_ko": "다음 시각화 기술 중에서 다양한 범주나 항목의 빈도를 표시하는 데 가장 적합한 것은 무엇인가요?",
    "options_en": [
      "Heatmap",
      "Bar chart",
      "Scattertext",
      "Network graph"
    ],
    "options_ko": [
      "히트맵",
      "막대형 차트",
      "산점도",
      "네트워크 그래프"
    ],
    "correct_answer": 1,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_1_e.png",
    "source_image_ko": "day12_1_h.png",
    "created_at": "2025-11-29T12:56:08.023254+00:00",
    "updated_at": "2025-11-29T12:56:08.023254+00:00"
  },
  {
    "id": "4628dc39-bbb7-418a-ac1f-7ddb1c502715",
    "question_text_en": "What is the primary goal of text data visualization?",
    "question_text_ko": "텍스트 데이터 시각화의 주요 목표는 무엇인가요?",
    "options_en": [
      "To make text data more aesthetically pleasing",
      "To transform unstructured text into visual representations for easier understanding and analysis",
      "To replace the need for reading and interpreting text",
      "To create complex and intricate visual displays"
    ],
    "options_ko": [
      "텍스트 데이터를 대용 미적으로 만들기 위해",
      "구조화되지 않은 텍스트를 시각적 표현으로 변환하여 더 쉽게 이해하고 분석할 수 있도록 합니다.",
      "텍스트를 읽고 해석할 필요성을 대체하기 위해",
      "복잡하고 정교한 시각적 디스플레이를 만들려면"
    ],
    "correct_answer": 1,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_1_e.png",
    "source_image_ko": "day12_1_h.png",
    "created_at": "2025-11-29T12:56:08.057546+00:00",
    "updated_at": "2025-11-29T12:56:08.057546+00:00"
  },
  {
    "id": "418b0aa3-81d2-420e-9faa-d11e878a2363",
    "question_text_en": "Which of the following is NOT a metric directly derived from a confusion matrix?",
    "question_text_ko": "3. 다음 중 혼동 행렬에서 직접 파생된 지표가 아닌 것은 무엇입니까?",
    "options_en": [
      "Accuracy",
      "Precision",
      "Recall",
      "Mean Squared Error (MSE)"
    ],
    "options_ko": [
      "정확성",
      "정도",
      "상기력",
      "평균 제곱 오차(MSE)"
    ],
    "correct_answer": 3,
    "category": "Classification Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:09.927426+00:00",
    "updated_at": "2025-11-29T12:56:09.927426+00:00"
  },
  {
    "id": "dbc501af-b19c-4250-8e7d-1882184141fc",
    "question_text_en": "Word clouds are particularly effective for:",
    "question_text_ko": "워드 클라우드는 다음과 같은 경우에 특히 효과적입니다.",
    "options_en": [
      "Showing the exact frequency of each word in a text",
      "Displaying the relationships between different words or concepts",
      "Highlighting the most prominent or frequent words in a text",
      "Visualizing the sentiment or emotional tone of a text"
    ],
    "options_ko": [
      "텍스트에서 각 단어의 정확한 빈도 표시",
      "다양한 단어나 개념 간의 관계 표시",
      "텍스트에서 가장 눈에 띄거나 자주 등장하는 단어 강조하기",
      "텍스트의 감정이나 감정적 톤을 시각화합니다."
    ],
    "correct_answer": 2,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_1_e.png",
    "source_image_ko": "day12_1_h.png",
    "created_at": "2025-11-29T12:56:08.09295+00:00",
    "updated_at": "2025-11-29T12:56:08.09295+00:00"
  },
  {
    "id": "b8c4ed23-0211-45a8-bf97-2af4a445b8dc",
    "question_text_en": "Which visualization technique is best suited for revealing relationships between two numerical variables?",
    "question_text_ko": "두 수치 변수 간의 관계를 밝히는 데 가장 적합한 시각화 기술은 무엇인가요?",
    "options_en": [
      "Bar chart",
      "Pie chart",
      "Scatter plot",
      "Heatmap"
    ],
    "options_ko": [
      "막대형 차트",
      "파이 차트",
      "산점도",
      "히트맵"
    ],
    "correct_answer": 2,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_1_e.png",
    "source_image_ko": "day12_1_h.png",
    "created_at": "2025-11-29T12:56:08.128289+00:00",
    "updated_at": "2025-11-29T12:56:08.128289+00:00"
  },
  {
    "id": "e0b9909a-853e-4574-9d74-9434d5b52019",
    "question_text_en": "Line charts are commonly used to:",
    "question_text_ko": "선형 차트는 일반적으로 다음과 같은 경우에 사용됩니다.",
    "options_en": [
      "Show trends or changes in data over time",
      "Compare the frequencies of different categories",
      "Display the distribution of values across two dimensions",
      "Visualize the hierarchical structure of data"
    ],
    "options_ko": [
      "시간 경과에 따라 데이터의 증분 또는 변화를 표시",
      "다양한 카테고리의 범주를 비교하려고 함",
      "두 숫자의 절대 값 비교 표시",
      "데이터의 계층 구조를 시각화합니다"
    ],
    "correct_answer": 0,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_2_e.png",
    "source_image_ko": "day12_2_h.png",
    "created_at": "2025-11-29T12:56:08.162888+00:00",
    "updated_at": "2025-11-29T12:56:08.162888+00:00"
  },
  {
    "id": "ab9b82c6-b1dd-4ccd-9cd7-48ebb4cabfb9",
    "question_text_en": "What is the primary purpose of CuDF in the context of data analysis?",
    "question_text_ko": "데이터 분석 영역에서 CuDF의 주요 목적은 무엇입니까?",
    "options_en": [
      "To visualize large datasets",
      "To provide a GPU-accelerated DataFrame library for data manipulation and analysis",
      "To build machine learning models",
      "To manage database connections"
    ],
    "options_ko": [
      "대규모 데이터 세트를 시각화하려면",
      "데이터 조작 및 처리을 위한 GPU 가속 DataFrame 라이브러리 제공",
      "머신 러닝 모델을 교육하려면",
      "데이터베이스 연결을 관리하려면"
    ],
    "correct_answer": 1,
    "category": "Data Analysis Tools",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_2_e.png",
    "source_image_ko": "day12_2_h.png",
    "created_at": "2025-11-29T12:56:08.209083+00:00",
    "updated_at": "2025-11-29T12:56:08.209083+00:00"
  },
  {
    "id": "4059c474-4b78-4662-b80f-375b4eb385f7",
    "question_text_en": "Which type of plot is ideal for showing correlations between two continuous variables?",
    "question_text_ko": "두 연속 변수 간의 상관관계를 보여주는 데 가장 적합한 차트 유형은 무엇입니까?",
    "options_en": [
      "Scatter Plot",
      "Pie Chart",
      "Bar Chart",
      "Box Plot"
    ],
    "options_ko": [
      "산점도",
      "바이올린 차트",
      "매트릭스 차트",
      "상자 그림"
    ],
    "correct_answer": 0,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_2_e.png",
    "source_image_ko": "day12_2_h.png",
    "created_at": "2025-11-29T12:56:08.243824+00:00",
    "updated_at": "2025-11-29T12:56:08.243824+00:00"
  },
  {
    "id": "9c2611c9-9025-4ca6-8f75-78ac98e0be37",
    "question_text_en": "Which of the following tasks can be accelerated using Dask-cuDF?",
    "question_text_ko": "다음 중 Dask-cuDF를 사용하여 가능하게 할 수 있는 작업은 무엇입니까?",
    "options_en": [
      "Creating deep learning models",
      "Running web applications",
      "Distributed DataFrame operations across multiple GPUs",
      "Building NoSQL databases"
    ],
    "options_ko": [
      "데이터 프레임 생성",
      "연 애플리케이션의 실행",
      "여러 GPU에 걸친 분산 DataFrame 작업",
      "NoSQL 데이터베이스 구성"
    ],
    "correct_answer": 2,
    "category": "Data Analysis Tools",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_2_e.png",
    "source_image_ko": "day12_2_h.png",
    "created_at": "2025-11-29T12:56:08.278286+00:00",
    "updated_at": "2025-11-29T12:56:08.278286+00:00"
  },
  {
    "id": "0f022fa7-1936-46c7-a031-dd05e94fa3ab",
    "question_text_en": "Which visualization method is most effective for analyzing the distribution of text lengths in a dataset?",
    "question_text_ko": "데이터 세트에서 텍스트의 깊이 분류를 분석하는 데 가장 효과적인 시간절약 방법은 무엇입니까?",
    "options_en": [
      "Line Chart",
      "Heatmap",
      "Box Plot",
      "Histogram"
    ],
    "options_ko": [
      "선형 서치",
      "히프를 사용",
      "상자 스키밍",
      "워크스루 활용"
    ],
    "correct_answer": 3,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": 12,
    "source_image_en": "day12_2_e.png",
    "source_image_ko": "day12_2_h.png",
    "created_at": "2025-11-29T12:56:08.315365+00:00",
    "updated_at": "2025-11-29T12:56:08.315365+00:00"
  },
  {
    "id": "3e1ee8f2-acbc-4fbf-97a9-0dbdb6f0198a",
    "question_text_en": "How do LLMs learn to generate human-like text?",
    "question_text_ko": "1. LLM은 어떻게 인간과 유사한 텍스트를 생성하는 방법을 택하나요?",
    "options_en": [
      "By interacting with human users in real-time conversations",
      "By leveraging massive datasets and algorithms to learn patterns in language",
      "By being explicitly programmed with grammar and vocabulary rules",
      "By observing human behavior in various settings"
    ],
    "options_ko": [
      "실시간 대화에서 인간 사용자와 상호 작용하여",
      "대규모 데이터 세트와 알고리즘을 활용하여 언어 패턴을 학습합니다.",
      "완벽한 이해 구체의 인식적으로 프로그래밍되어 있음",
      "다양한 환경에서 인간의 행동을 관찰함으로써"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_1_e.png",
    "source_image_ko": "day13_1_h.png",
    "created_at": "2025-11-29T12:56:08.351551+00:00",
    "updated_at": "2025-11-29T12:56:08.351551+00:00"
  },
  {
    "id": "b7fb5da2-d185-4821-aedb-8fe5c5b7763e",
    "question_text_en": "What is a key concern when developing and deploying large language models (LLMs)?",
    "question_text_ko": "2. 대규모 언어 모델(LLM)을 개발할 때 목표할 때 가장 중요한 고려 사항은 무엇인가요?",
    "options_en": [
      "Ensuring they can generate creative and entertaining text.",
      "Minimizing their computational requirements.",
      "Identifying and mitigating potential biases in their output.",
      "Maximizing their ability to generate code."
    ],
    "options_ko": [
      "창의적이고 재미있는 텍스트를 생성할 수 있도록 보장합니다.",
      "개선 요구 사항을 최소화합니다.",
      "훈습하면서 정확한 문법과 철자를 완성합니다.",
      "모델 생성 비용을 극대화합니다."
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_1_e.png",
    "source_image_ko": "day13_1_h.png",
    "created_at": "2025-11-29T12:56:08.383223+00:00",
    "updated_at": "2025-11-29T12:56:08.383223+00:00"
  },
  {
    "id": "1bd1c6dd-89ef-429d-9e5a-a3d574288923",
    "question_text_en": "Which hyperparameter tuning method systematically explores all possible combinations from a predefined set of values?",
    "question_text_ko": "3. 여러 정렬의 각 집합에 모든 가능한 조합을 체계적으로 탐색하는 하이퍼파라미터 튜닝 방법은 무엇인가요?",
    "options_en": [
      "Grid Search",
      "Random Search",
      "Bayesian Optimization",
      "Genetic Algorithms"
    ],
    "options_ko": [
      "그리드 검색",
      "무작위 검색",
      "베이지안 최적화",
      "유전 알고리즘"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_1_e.png",
    "source_image_ko": "day13_1_h.png",
    "created_at": "2025-11-29T12:56:08.41855+00:00",
    "updated_at": "2025-11-29T12:56:08.41855+00:00"
  },
  {
    "id": "10ac3603-98c0-451d-932e-fccf1016e14d",
    "question_text_en": "What are hyperparameters in the context of large language models (LLMs)?",
    "question_text_ko": "4. 대규모 언어 모델(LLM)에서 일반적인 하이퍼파라미터는 무엇인가요?",
    "options_en": [
      "The words and phrases used to train the model.",
      "The internal settings that govern the model's architecture, learning rate, batch size, etc.",
      "The output generated by the model in response to a prompt.",
      "The evaluation metrics used to assess the model's performance."
    ],
    "options_ko": [
      "모델을 운영하는 핵심적인 하드웨어 구문입니다.",
      "모델의 아키텍처, 학습률, 배치 크기 등을 결정하는 내부 설정입니다.",
      "프로젝트에 대한 향후 모델의 성장을 측정합니다.",
      "모델의 성능을 평가하는 데 사용되는 평가 지표입니다."
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_1_e.png",
    "source_image_ko": "day13_1_h.png",
    "created_at": "2025-11-29T12:56:08.457751+00:00",
    "updated_at": "2025-11-29T12:56:08.457751+00:00"
  },
  {
    "id": "999e7bd0-216b-4810-a265-1b5e62eae606",
    "question_text_en": "What is the primary purpose of NVIDIA Triton Inference Server?",
    "question_text_ko": "1. NVIDIA Triton 추론 서버의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train large language models (LLMs) from scratch.",
      "To simplify the deployment of AI models at scale in production.",
      "To collect and preprocess data for model training.",
      "To design and optimize model architectures."
    ],
    "options_ko": [
      "연구실 없이 딥러닝을 처음부터 훈련합니다.",
      "생산 환경에서 AI 모델을 대규모로 배포하는 기본 구조합니다.",
      "모델 학습을 위해 데이터를 수집하고 정제합니다.",
      "모델 연구개발을 수행하기 최적화합니다."
    ],
    "correct_answer": 1,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_2_e.png",
    "source_image_ko": "day14_2_h.png",
    "created_at": "2025-11-29T12:56:09.053105+00:00",
    "updated_at": "2025-11-29T12:56:09.053105+00:00"
  },
  {
    "id": "441e53a5-711c-4221-b7a4-093f434f1dd3",
    "question_text_en": "What is the primary purpose of A/B testing in the context of LLMs?",
    "question_text_ko": "1. LLM에서 A/B 테스트의 주요 목적은 무엇입니까?",
    "options_en": [
      "To randomly deploy different LLM versions without any evaluation.",
      "To systematically evaluate different versions of LLMs and their impact on user experience and key metrics",
      "To compare the performance of LLMs against traditional rule-based systems",
      "To measure the computational efficiency of different LLM architectures"
    ],
    "options_ko": [
      "평가 없이 다양한 LLM 버전을 무작위로 배포합니다.",
      "실험을 진행하여 변경된 사양과 특정 목표 지표에 미치는 영향을 체계적으로 평가합니다.",
      "LLM의 성능을 기존 규제 시스템과 비교하면서",
      "다양한 LLM 아키텍처의 계산 효율성을 측정하면서"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_2_e.png",
    "source_image_ko": "day13_2_h.png",
    "created_at": "2025-11-29T12:56:08.493677+00:00",
    "updated_at": "2025-11-29T12:56:08.493677+00:00"
  },
  {
    "id": "21b58cd7-45c5-4d67-aa83-2429fc6fd4e5",
    "question_text_en": "What is the primary benefit of using a Version Control System (VCS) in LLM development regarding reproducibility?",
    "question_text_ko": "2. 재현성과 관련하여 LLM 개발에서 버전 제어 시스템(VCS)을 사용하는 주요 이유는 무엇입니까?",
    "options_en": [
      "It automatically improves the model’s accuracy.",
      "It prevents any changes from being made to the code or data.",
      "It allows for easy tracking of changes, enabling reversion to previous versions and replication of experiments.",
      "It generates new versions of the model automatically."
    ],
    "options_ko": [
      "모델의 정확도가 자동으로 향상됩니다.",
      "코드나 데이터가 전환되는 것을 방지합니다.",
      "모델 개발 과정을 사양과 다른 버전으로 되돌리고 실험을 재현할 수 있습니다.",
      "모델의 새로운 버전을 자동으로 생성합니다."
    ],
    "correct_answer": 2,
    "category": "Development Practices",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_2_e.png",
    "source_image_ko": "day13_2_h.png",
    "created_at": "2025-11-29T12:56:08.534551+00:00",
    "updated_at": "2025-11-29T12:56:08.534551+00:00"
  },
  {
    "id": "f27fbfe4-5e46-447f-b25f-1aae6a8c327d",
    "question_text_en": "Why is version control important for large language model (LLM) projects?",
    "question_text_ko": "3. 대규모 언어 모델(LLM) 프로젝트에 버전 제어가 중요한 이유는 무엇입니까?",
    "options_en": [
      "It allows for faster training of LLMs by optimizing computational resources.",
      "It enables reproducibility, collaboration, and efficient management of LLM projects.",
      "It prevents LLMs from making errors during text generation.",
      "It automates hyperparameter tuning for better model performance."
    ],
    "options_ko": [
      "이를 통해 개인 리소스를 최적화하여 LLM의 학습 속도를 높일 수 있습니다.",
      "LLM 프로젝트의 개선과, 협업 및 효율적인 관리가 가능합니다.",
      "이를 통해 LLM의 레벨과 성능 등에 오류를 찾는 과정을 실행할 수 있습니다.",
      "더 나은 모델 성능을 위해 하이퍼파라미터 튜닝을 재정립합니다."
    ],
    "correct_answer": 1,
    "category": "Development Practices",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_2_e.png",
    "source_image_ko": "day13_2_h.png",
    "created_at": "2025-11-29T12:56:08.585846+00:00",
    "updated_at": "2025-11-29T12:56:08.585846+00:00"
  },
  {
    "id": "1052d50f-4e20-43b1-88ca-ebabb2f48674",
    "question_text_en": "Why is the BioNeMo LLM service particularly suitable for the biomedical and pharmaceutical industries?",
    "question_text_ko": "4. BioNeMo LLM 서비스가 생물의학 및 헬스 산업에 특히 적합한 이유는 무엇입니까?",
    "options_en": [
      "Because it generates medical content based on general language models",
      "Because it is pre-trained on massive biomedical datasets and allows customization for specific tasks",
      "Because it replaces the need for human expertise in healthcare decision-making",
      "Because it primarily focuses on real-time conversations with healthcare professionals"
    ],
    "options_ko": [
      "평가 없이 모델을 기반으로 의료 컨텐츠를 생성하기 때문이며",
      "대규모 의료 데이터세트에 대한 사전 학습 없이도 특정 질병에 대한 사용자의 정의가 가능하기 때문입니다.",
      "이는 의료 원격진료에 있어 인간의 질병 예측이 좀 더 용이 하기 때문입니다.",
      "주요 의료 과정에서의 실시간 데이터의 흐름을 유지기 때문입니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_2_e.png",
    "source_image_ko": "day13_2_h.png",
    "created_at": "2025-11-29T12:56:08.628125+00:00",
    "updated_at": "2025-11-29T12:56:08.628125+00:00"
  },
  {
    "id": "df7c1aea-b050-49c2-91ed-4363e5798610",
    "question_text_en": "How do NVIDIA AI Agents perceive and interact with their environment?",
    "question_text_ko": "5. NVIDIA AI 엔터프라이즈 솔루션은 이렇게 변환된 인식을 어떻게 향상하고 신속 적용합니까?",
    "options_en": [
      "By following pre-programmed scripts for user interactions",
      "By processing visual and auditory inputs using computer vision and natural language models",
      "By only responding to text-based user commands",
      "By relying solely on predefined responses without real-time reasoning"
    ],
    "options_ko": [
      "사용자 속성을 위한 새로운 사전 프로그램과의 스크립트를 만들고",
      "현재의 비전과 작업의 다양한 사용이 시각적 및 관심적 인식을 제공함으로써",
      "텍스트로부터 사용자의 정밀한 단평을 모으고",
      "실시간 추천 없이 미리 정의된 응답만을 일관함으로써"
    ],
    "correct_answer": 1,
    "category": "AI Agents",
    "difficulty": "medium",
    "source_day": 13,
    "source_image_en": "day13_2_e.png",
    "source_image_ko": "day13_2_h.png",
    "created_at": "2025-11-29T12:56:08.858302+00:00",
    "updated_at": "2025-11-29T12:56:08.858302+00:00"
  },
  {
    "id": "4d520547-04b8-4ad2-aa50-28c4cea77d9c",
    "question_text_en": "What is the primary purpose of Kernel Auto-Tuning?",
    "question_text_ko": "커널 자동 튜닝의 주요 목적은 무엇입니까?",
    "options_en": [
      "To minimize memory usage during model execution",
      "To enable parallel processing of multiple input streams",
      "To select the most efficient kernels for a given GPU architecture",
      "To optimize models for mixed-precision computation"
    ],
    "options_ko": [
      "같은 성능 중 메모리 사용을 최소화하려면",
      "여러 알고리즘의 병렬 처리를 활성화하려면",
      "주어진 GPU 아키텍처에 가장 적절한 커널을 선택하려면",
      "초밥 정도 계산을 위한 모델 최적화"
    ],
    "correct_answer": 2,
    "category": "Model Optimization",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_1_e.png",
    "source_image_ko": "day14_1_h.png",
    "created_at": "2025-11-29T12:56:08.897113+00:00",
    "updated_at": "2025-11-29T12:56:08.897113+00:00"
  },
  {
    "id": "db454ff0-b42f-4a42-8deb-46b07ea6813a",
    "question_text_en": "What is the primary focus of the NVIDIA BioNeMo LLM Service?",
    "question_text_ko": "NVIDIA BioNeMo LLM 서비스의 주요 초점은 무엇입니까?",
    "options_en": [
      "General-purpose language tasks",
      "Financial analysis and predictions",
      "Biomedical and pharmaceutical applications",
      "Image and video processing"
    ],
    "options_ko": [
      "일반 언어 작업",
      "재무 분석 및 예측",
      "생물학적 및 화학 응용 분야",
      "이미지 및 비디오 처리"
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_1_e.png",
    "source_image_ko": "day14_1_h.png",
    "created_at": "2025-11-29T12:56:08.935924+00:00",
    "updated_at": "2025-11-29T12:56:08.935924+00:00"
  },
  {
    "id": "2ecce75c-bb7e-4b9b-83f6-55f178c71130",
    "question_text_en": "Which of the following capabilities falls under the “Perception” aspect of NVIDIA AI Agents?",
    "question_text_ko": "다음 기능 중 NVIDIA AI Agents의 “지각” 측면에 속하는 것은 무엇입니까?",
    "options_en": [
      "Generating creative text responses",
      "Processing visual and auditory input to understand the environment",
      "Making complex decisions based on internal knowledge",
      "Planning a sequence of actions to achieve a goal"
    ],
    "options_ko": [
      "정확한 테스트 로봇 생성",
      "주변 환경을 이해하기 위해 시각적, 청각적 입력을 처리합니다.",
      "내부 자신이 기계적 발전과 심화 연결",
      "목표를 중심하기 위한 일반의 행동 계획"
    ],
    "correct_answer": 1,
    "category": "AI Agents",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_1_e.png",
    "source_image_ko": "day14_1_h.png",
    "created_at": "2025-11-29T12:56:08.972273+00:00",
    "updated_at": "2025-11-29T12:56:08.972273+00:00"
  },
  {
    "id": "0f19a15d-940e-492f-a725-28a9c4895c1e",
    "question_text_en": "What is the core idea behind the Mixture of Experts (MoE) architectural paradigm?",
    "question_text_ko": "전문가 혼합(MoE) 모델 패러다임의 핵심 아이디어는 무엇입니까?",
    "options_en": [
      "Training multiple smaller models and combining their outputs.",
      "Dividing the model into multiple specialized experts, each focusing on a specific task or domain",
      "Reducing the size of the model by removing unnecessary parameters",
      "Fine-tuning the model on a large dataset of diverse tasks"
    ],
    "options_ko": [
      "여러 개의 작은 모델을 훈련하고 각각의 출력을 결합합니다.",
      "모델을 특정 작업이나 도메인에 연공하는 여러 전문가를 분할",
      "집중적으로 예방처리를 피하면서 모델 크기 줄이기",
      "다양한 작업의 대규모 데이터셋에 대한 모델 미세 조정"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_1_e.png",
    "source_image_ko": "day14_1_h.png",
    "created_at": "2025-11-29T12:56:09.013029+00:00",
    "updated_at": "2025-11-29T12:56:09.013029+00:00"
  },
  {
    "id": "9a43afdc-75fb-4b82-ac65-8710e26b0a96",
    "question_text_en": "What is the main purpose of NVIDIA AI Workflows?",
    "question_text_ko": "2. NVIDIA AI 솔루션의 주요 목적은 무엇입니까?",
    "options_en": [
      "To provide a marketplace for buying and selling AI models.",
      "To focus solely on data collection and preprocessing.",
      "To streamline and accelerate the entire AI development process.",
      "To automate the deployment of AI models in production."
    ],
    "options_ko": [
      "AI 모델을 할당할 수 있는 시장을 제공합니다.",
      "데이터 신뢰성 강화를 보장합니다.",
      "AI 개발 프로세스 전반의 효율성을 가속화합니다.",
      "프로덕션에서 모델의 빠른 작업을 지원합니다."
    ],
    "correct_answer": 2,
    "category": "AI Development",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_2_e.png",
    "source_image_ko": "day14_2_h.png",
    "created_at": "2025-11-29T12:56:09.091181+00:00",
    "updated_at": "2025-11-29T12:56:09.091181+00:00"
  },
  {
    "id": "50e5e2ea-5cf8-4e63-95f1-15a244a693e4",
    "question_text_en": "What is NVIDIA cuOpt?",
    "question_text_ko": "3. NVIDIA cuOpt란 무엇입니까?",
    "options_en": [
      "A cloud-based platform for managing logistics operations",
      "A GPU-accelerated optimization library",
      "A deep learning framework for image recognition",
      "A programming language for developing logistics software"
    ],
    "options_ko": [
      "유류 운영 문제를 위한 솔루션의 기본 플랫폼",
      "GPU 가속 최적화 라이브러리",
      "이미지 인식을 위한 고급 라이브러리",
      "효율적 프로그램 개발을 위한 프로그래밍 언어"
    ],
    "correct_answer": 1,
    "category": "Optimization",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_2_e.png",
    "source_image_ko": "day14_2_h.png",
    "created_at": "2025-11-29T12:56:09.132333+00:00",
    "updated_at": "2025-11-29T12:56:09.132333+00:00"
  },
  {
    "id": "2065aa7d-c5e0-49fe-b3f3-bd927a756c16",
    "question_text_en": "What is the primary purpose of NVIDIA RIVA?",
    "question_text_ko": "4. NVIDIA Riva의 주요 목적은 무엇입니까?",
    "options_en": [
      "To generate realistic images",
      "To enable developers to build and deploy real-time, highly accurate conversational AI applications",
      "To analyze large datasets for business insights",
      "To translate text between different languages"
    ],
    "options_ko": [
      "사전과 이미지 생성하기",
      "개발자가 실시간으로 음성 인식이 높은 대화형 AI 애플리케이션을 구축하고 배포할 수 있도록 지원",
      "비디오나 음성으로부터 대규모 데이터 세트를 분석하고 해석",
      "다양한 언어 간에 텍스트를 변환하기"
    ],
    "correct_answer": 1,
    "category": "Conversational AI",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_2_e.png",
    "source_image_ko": "day14_2_h.png",
    "created_at": "2025-11-29T12:56:09.169513+00:00",
    "updated_at": "2025-11-29T12:56:09.169513+00:00"
  },
  {
    "id": "b6897de9-95c7-4db9-a46f-9b8d9cd588e3",
    "question_text_en": "What is NVIDIA Merlin?",
    "question_text_ko": "5. NVIDIA Merlin이란 무엇입니까?",
    "options_en": [
      "A cloud-based platform for managing customer relationships",
      "A deep learning framework for image recognition",
      "An open-source framework for building and deploying recommender systems",
      "A programming language for developing e-commerce websites"
    ],
    "options_ko": [
      "고객 관계 관리를 위한 솔루션의 기본 플랫폼",
      "이미지 인식을 위한 라이브러리입니다",
      "추천 시스템 구성 및 배포를 위한 오픈 소스 프레임워크",
      "정보처리 형식에서 제품을 위한 프로그래밍 언어"
    ],
    "correct_answer": 2,
    "category": "Recommender Systems",
    "difficulty": "medium",
    "source_day": 14,
    "source_image_en": "day14_2_e.png",
    "source_image_ko": "day14_2_h.png",
    "created_at": "2025-11-29T12:56:09.204257+00:00",
    "updated_at": "2025-11-29T12:56:09.204257+00:00"
  },
  {
    "id": "7fe682d1-af82-444d-bf60-a2f44cffac1b",
    "question_text_en": "The concept of Explainable AI (XAI) is most closely associated with which pillar of responsible AI?",
    "question_text_ko": "설명 가능한 AI(XAI) 개념은 책임 있는 AI의 기둥 중 가장 밀접하게 연관되어 있습니까?",
    "options_en": [
      "Fairness",
      "Transparency & Explainability",
      "Accountability",
      "Privacy"
    ],
    "options_ko": [
      "공정성",
      "투명성 및 설명 가능성",
      "책임",
      "존중"
    ],
    "correct_answer": 1,
    "category": "Explainable AI",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_1_e.png",
    "source_image_ko": "day15_1_h.png",
    "created_at": "2025-11-29T12:56:09.240674+00:00",
    "updated_at": "2025-11-29T12:56:09.240674+00:00"
  },
  {
    "id": "1267e34b-4ebb-40ad-a43f-9a07a3943d82",
    "question_text_en": "What is data consent in the context of AI and data handling?",
    "question_text_ko": "AI와 데이터 처리의 맥락에서 데이터 주권은 무엇입니까?",
    "options_en": [
      "Implicit agreement assumed from users when they use a service.",
      "Explicit permission from individuals to collect, use, and share their data.",
      "The right of companies to use data without informing users.",
      "The process of obtaining data from public sources."
    ],
    "options_ko": [
      "사용자가 서비스를 사용할 때 명목적으로 동일답다고 가정합니다.",
      "개인이 자신의 데이터를 수집, 사용, 공유하도록 의식적으로 허가합니다.",
      "사용자가 명시적 강요만으로 데이터를 사용할 수 있는 개인의 권리.",
      "공공 소스에서 데이터를 얻는 과정."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_1_e.png",
    "source_image_ko": "day15_1_h.png",
    "created_at": "2025-11-29T12:56:09.292357+00:00",
    "updated_at": "2025-11-29T12:56:09.292357+00:00"
  },
  {
    "id": "5a468436-85f7-43e3-9701-5fc9164ad6d4",
    "question_text_en": "What is the primary purpose of Nvidia’s NeMo Guardrails toolkit?",
    "question_text_ko": "Nvidia의 NeMo Guardrails를 통한 주요 목적은 무엇입니까?",
    "options_en": [
      "To accelerate the training of large language models",
      "To build safer and more controlled conversational AI models",
      "To improve the accuracy of image recognition models",
      "To optimize the performance of deep learning algorithms"
    ],
    "options_ko": [
      "대규모 언어 모델의 학습을 가속화설명력",
      "더욱 안전하고 통제 가능한 대화형 AI 모델을 구축하려면",
      "이미지 인식 모델의 정확도를 향상시키기 위해",
      "일반적 알고리즘의 성능을 최적화하려면"
    ],
    "correct_answer": 1,
    "category": "AI Safety",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_1_e.png",
    "source_image_ko": "day15_1_h.png",
    "created_at": "2025-11-29T12:56:09.340794+00:00",
    "updated_at": "2025-11-29T12:56:09.340794+00:00"
  },
  {
    "id": "797a2902-43d8-45b0-98df-a8542d1d2d76",
    "question_text_en": "What is the main goal of using the Omniverse Replicator in the context of AI fairness?",
    "question_text_ko": "AI 공정성 전략에서 Omniverse Replicator를 사용하는 주요 목표는 무엇입니까?",
    "options_en": [
      "To improve the accuracy of AI models on benchmark datasets.",
      "To generate synthetic data that enhances diversity and representation in training datasets",
      "To create explainable AI models",
      "To establish governance structures for AI development"
    ],
    "options_ko": [
      "복잡한 데이터 세트에서 AI 모델의 명확도를 개선합니다.",
      "훈련 데이터 세트의 다양성과 편견을 정량하는 합성 데이터를 생성합니다.",
      "설명 가능한 AI 모델을 연구하다",
      "AI 개발을 위한 가상현실 구조 구축"
    ],
    "correct_answer": 1,
    "category": "AI Fairness",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_1_e.png",
    "source_image_ko": "day15_1_h.png",
    "created_at": "2025-11-29T12:56:09.393832+00:00",
    "updated_at": "2025-11-29T12:56:09.393832+00:00"
  },
  {
    "id": "813d8cfb-cd19-49c4-94c8-6adcc480c2b5",
    "question_text_en": "What is the primary goal of Trustworthy AI in NVIDIA's generative AI and LLMs?",
    "question_text_ko": "1. NVIDIA의 생성 AI와 LLM에서 신뢰할 수 있는 AI의 주요 목표는 무엇입니까?",
    "options_en": [
      "A: To enhance AI performance without considering ethical implications",
      "B: To ensure AI systems are reliable, safe, fair, transparent, and accountable",
      "C: To make AI systems self-learning and fully autonomous",
      "D: To prioritize AI accuracy over ethical considerations"
    ],
    "options_ko": [
      "A. 문제의 모바일 경험에서 인지 성능 향상을시키고 있습니다.",
      "B. AI 시스템이 윤리적이고 안정적인 결정으로부터 책임이 있는지 확인하기 위해",
      "C. AI 시스템을 자체 학습하여 문제 해결하기 위해",
      "D. 문제의 고급사용자만의 사용자 정의를 우선시합니다."
    ],
    "correct_answer": 1,
    "category": "AI Ethics",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_2_e.png",
    "source_image_ko": "day15_2_h.png",
    "created_at": "2025-11-29T12:56:09.433059+00:00",
    "updated_at": "2025-11-29T12:56:09.433059+00:00"
  },
  {
    "id": "83a57057-8cb0-49b6-8faa-d6e1080ceee4",
    "question_text_en": "Why is data privacy crucial in artificial intelligence and large language model (LLM) development?",
    "question_text_ko": "2. 인공지능과 대규모 언어 모델(LLM) 개발에 있어서 데이터 개인정보 보호가 왜 중요한가요?",
    "options_en": [
      "A: Because it ensures AI models can collect unlimited data for better performance",
      "B: Because it builds trust, mitigates risks, ensures fairness, and complies with regulations",
      "C: Because AI models require personal data to function effectively",
      "D: Because it allows AI developers to bypass regulatory requirements"
    ],
    "options_ko": [
      "A. 사용자가 민감한 행동을 위해 개인정보를 습득할 수 있도록 장려하기 때문입니다.",
      "B. 신뢰 구축으로, 인류를 보호하며, 공정성을 보장하며, 규제를 준수하기 때문입니다.",
      "C. AI 모델이 교육자료를 추천하면 개인 데이터가 필요하기 때문입니다.",
      "D. 개발자가 국가 요구 사항을 무시할 수 있기 때문입니다."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_2_e.png",
    "source_image_ko": "day15_2_h.png",
    "created_at": "2025-11-29T12:56:09.469862+00:00",
    "updated_at": "2025-11-29T12:56:09.469862+00:00"
  },
  {
    "id": "96d3fc3b-542a-41d9-8a89-c46d09f6beee",
    "question_text_en": "Which of the following is a key approach used by NVIDIA to ensure data privacy in AI development?",
    "question_text_ko": "3. 다음 중 NVIDIA가 개발에서 데이터 개인 정보 보호를 보장하기 위해 사용하는 주요 접근 방식은 무엇입니까?",
    "options_en": [
      "A: Storing all collected data in centralized databases for easier access",
      "B: Using federated learning, confidential computing, and privacy-preserving techniques",
      "C: Collecting as much data as possible to improve AI accuracy",
      "D: Ignoring data privacy concerns if the AI system operates in a country without strict regulations"
    ],
    "options_ko": [
      "A. 수집된 모든 데이터를 중앙 데이터베이스에서 저장하여 더 쉽게 접근 가능",
      "B. 암호 학습, 커플 통계 및 개인 정보 보호 기술 사용",
      "C. 왜곡중립 정책을 지배하는 공개 데이터 사용",
      "D. 엄격한 규제가 없는 국가에서 시스템의 운용되는 경우 데이터 개인 정보 보호 문제를 무시합니다."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_2_e.png",
    "source_image_ko": "day15_2_h.png",
    "created_at": "2025-11-29T12:56:09.520839+00:00",
    "updated_at": "2025-11-29T12:56:09.520839+00:00"
  },
  {
    "id": "879b178a-6852-40b0-aa21-ff3277eebfe2",
    "question_text_en": "How does NVIDIA ensure AI trustworthiness in its solutions?",
    "question_text_ko": "4. NVIDIA는 어떻게 복구 시뮬레이션의 AI 신뢰성을 보장합니까?",
    "options_en": [
      "A: By embedding trustworthy AI principles at every stage of AI development",
      "B: By manually reviewing AI outputs to ensure ethical compliance",
      "C: By relying solely on third-party organizations to establish AI safety standards",
      "D: By restricting AI models to avoid real-world applications"
    ],
    "options_ko": [
      "A. 개발된 모든 데이터를 디지털 있는 시스템을 보관함으로써",
      "B. 문제의 고유 설정을 사용자 정보와 신뢰의 흐름을 보관합니다.",
      "C. 신뢰성을 문제에 적용하여 생산적인 방법으로",
      "D. 일반적인 응용 프로그램 및 일반적 규칙 기반 모델을 활용함으로써"
    ],
    "correct_answer": 0,
    "category": "AI Ethics",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_2_e.png",
    "source_image_ko": "day15_2_h.png",
    "created_at": "2025-11-29T12:56:09.574132+00:00",
    "updated_at": "2025-11-29T12:56:09.574132+00:00"
  },
  {
    "id": "72916fad-8370-487f-adc1-1f8c3456ed68",
    "question_text_en": "How does NVIDIA approach bias mitigation in AI systems?",
    "question_text_ko": "5. NVIDIA는 AI 시스템의 문제 해결에 어떤 접근 방식을 취합니까?",
    "options_en": [
      "A: By relying solely on human-curated datasets for training",
      "B: By completely eliminating bias through AI algorithms",
      "C: By using the Omniverse Replicator to generate synthetic data",
      "D: By avoiding transparency and explainability in AI models"
    ],
    "options_ko": [
      "A. 관련 통합 시뮬의 복구 방법을 데이터 AI에 포함하는 것은 잘못된 생각입니다. 따라서, 이는 강력한 설계 변경 및 디버깅이 심한 데이터를 AI로 통합합니다. NVIDIA는 대강연 데이터 통합 방식에 의해 발생 가능한 기능적 설계 강화를 제공합니다.",
      "B. 복구를 위해 확장된 통합이 개선된 문제 해결 방법입니다. NVIDIA는 검증절로 관한 AI 설계의 끝점인 고급화 정책을 사용하며 클라우드를 사용하는 것이 있습니다. 또한 문제의 정비 관리자를 최소화하고 다른 팀과의 상호작용과 조화를 통해 ‘NVIDIA AI 실내 버전’ 응용을 권장하고 있습니다.",
      "C. Omniverse Replicator 를 생산적 증명에서 해결하여 문제를 생성하기를 목표로 합니다. NVIDIA의 Omniverse Replicator를 사용하여 더 크고 다양한 데이터 문제를 제당하는 도구로, 스케일의 타임을 더 많이 얻어 봅니다. 자세한 내용은 'NVIDIA AI 문제 습관' 항목을 참조하십시오.",
      "D. 문제의 방지 작업과 최종 실행을 함께 보장함으로써 이루어지는 것입입니다. NVIDIA는 AI의 방지 계약 설멩 강화를 권장하며, CI/CD 생산 서비스와의 파트너쉽 관계를 통해 설복할 수 있도록 합니다. 자세한 내용은 'NVIDIA의 최적 AI 지원' 항목을 참조하십시오."
    ],
    "correct_answer": 2,
    "category": "Bias Mitigation",
    "difficulty": "medium",
    "source_day": 15,
    "source_image_en": "day15_2_e.png",
    "source_image_ko": "day15_2_h.png",
    "created_at": "2025-11-29T12:56:09.608357+00:00",
    "updated_at": "2025-11-29T12:56:09.608357+00:00"
  },
  {
    "id": "e0719431-43f8-43a9-a66e-19d6fb574a96",
    "question_text_en": "What is the primary goal of a regression algorithm in machine learning?",
    "question_text_ko": "머신 러닝에서 회귀 알고리즘의 주요 목표는 무엇인가요?",
    "options_en": [
      "To assign input data into predefined categories or classes.",
      "To predict a continuous numerical value based on input features.",
      "To group similar data points together based on their inherent patterns.",
      "To discover hidden structures in unlabeled data."
    ],
    "options_ko": [
      "입력 데이터로 미리 정의된 부분과 클래스에 할당합니다.",
      "입력 특징을 기반으로 연속적인 수치 값을 예측합니다.",
      "고유한 패턴을 기준으로 유사한 데이터 포인트를 그룹화합니다.",
      "레이블이 지정되지 않은 데이터에서 숨겨진 구조를 발견합니다."
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_1_e.png",
    "source_image_ko": "day2_1_h.png",
    "created_at": "2025-11-29T12:56:09.653405+00:00",
    "updated_at": "2025-11-29T12:56:09.653405+00:00"
  },
  {
    "id": "612c0b5c-556d-4205-8a21-60a8deec786e",
    "question_text_en": "What does LogisticRegression.coef_ represent in a logistic regression model?",
    "question_text_ko": "로지스틱 회귀 모델에서 LogisticRegression.coef_는 무엇을 나타내나요?",
    "options_en": [
      "The predicted probabilities for each class",
      "The weights or coefficients assigned to each feature in the model",
      "The accuracy of the model",
      "The log-odds of the positive class"
    ],
    "options_ko": [
      "각 클래스에 대한 예측 확률",
      "모델의 각 기능에 할당된 가중치 또는 계수",
      "모델의 정확도",
      "양의 클래스의 로그 오즈"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_1_e.png",
    "source_image_ko": "day2_1_h.png",
    "created_at": "2025-11-29T12:56:09.691871+00:00",
    "updated_at": "2025-11-29T12:56:09.691871+00:00"
  },
  {
    "id": "28cd1e92-b0d3-403a-871c-48d31579abb6",
    "question_text_en": "What does a high recall indicate about the model?",
    "question_text_ko": "높은 재현율은 모델에 대해 무엇을 나타내는가?",
    "options_en": [
      "The model has a low rate of false positives.",
      "The model is excellent at identifying all instances of a specific class.",
      "The model is good at predicting a specific class when it does predict it.",
      "The model is well-balanced in terms of precision and recall."
    ],
    "options_ko": [
      "해당 모델은 거짓 양성률이 높습니다.",
      "이 모델은 특정 클래스의 모든 인스턴스를 식별하는 데 매우 뛰어납니다.",
      "이 모델은 특정 클래스를 예측하는 데 효과적입니다.",
      "이 모델은 정밀도와 재현율 측면에서 균형이 잘 잡혀 있습니다."
    ],
    "correct_answer": 1,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_1_e.png",
    "source_image_ko": "day2_1_h.png",
    "created_at": "2025-11-29T12:56:09.731067+00:00",
    "updated_at": "2025-11-29T12:56:09.731067+00:00"
  },
  {
    "id": "e82b88cb-0807-46ac-8456-d5dec5b3c3dd",
    "question_text_en": "Which metric is best suited for imbalanced datasets?",
    "question_text_ko": "불균형 데이터 세트에 가장 적합한 지표는 무엇인가요?",
    "options_en": [
      "Accuracy",
      "Recall",
      "Precision",
      "F1 Score"
    ],
    "options_ko": [
      "정확성",
      "정기하다",
      "정도",
      "F1 점수"
    ],
    "correct_answer": 3,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_1_e.png",
    "source_image_ko": "day2_1_h.png",
    "created_at": "2025-11-29T12:56:09.772765+00:00",
    "updated_at": "2025-11-29T12:56:09.772765+00:00"
  },
  {
    "id": "9eccb266-6a80-4876-a32f-5f88b6da116a",
    "question_text_en": "Which of the following formulas represents precision?",
    "question_text_ko": "다음 중 어느 공식이 정밀도를 나타내나요?",
    "options_en": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "(TP + TN) / (TP + FP + FN + TN)",
      "2 X Precision X Recall / (Precision + Recall)"
    ],
    "options_ko": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TP + TN / (TP + FP + FN + TN)",
      "2 x 정밀도 x 재현율 / (정밀도 + 재현율)"
    ],
    "correct_answer": 1,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_1_e.png",
    "source_image_ko": "day2_1_h.png",
    "created_at": "2025-11-29T12:56:09.813467+00:00",
    "updated_at": "2025-11-29T12:56:09.813467+00:00"
  },
  {
    "id": "d3cc72ad-b759-4423-8029-0e555df4587d",
    "question_text_en": "What does an R-squared value of 0.85 indicate?",
    "question_text_ko": "1. R-제곱 값이 0.85는 무엇을 나타냅니까?",
    "options_en": [
      "85% of the variance in the target variable is explained by the model",
      "The model's predictions are 85% accurate",
      "The average error of the model is 0.85 units",
      "15% of the variance in the target variable is unexplained by the model"
    ],
    "options_ko": [
      "목표 변수의 분산의 85%는 모델에 의해 설명됩니다.",
      "모델의 예측 정확도는 85%입니다.",
      "모델의 평균 오차율은 0.85 단위입니다.",
      "목표 변수의 분산 중 15%는 모델에 의해 설명되지 않습니다."
    ],
    "correct_answer": 0,
    "category": "Regression Analysis",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:09.847502+00:00",
    "updated_at": "2025-11-29T12:56:09.847502+00:00"
  },
  {
    "id": "5e465f92-e59d-4692-b1cf-69dd5d96879f",
    "question_text_en": "In a confusion matrix, what does a high number of False Negatives indicate?",
    "question_text_ko": "4. 혼동 행렬에서 거짓 부정의 수가 많다는 것은 무엇을 의미합니까?",
    "options_en": [
      "The model is predicting many positive cases incorrectly.",
      "The model is failing to identify many actual positive cases.",
      "The model is performing well in identifying negative cases.",
      "The model has a high accuracy."
    ],
    "options_ko": [
      "해당 모델은 많은 양성 사례를 잘못 예측하고 있습니다.",
      "이 모델은 실제로 양성 환자 사례를 많이 식별하지 못하고 있습니다.",
      "해당 모델은 부정적인 사례를 식별하는 데 좋은 성과를 보이고 있습니다.",
      "해당 모델은 정확도가 높습니다."
    ],
    "correct_answer": 1,
    "category": "Classification Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:09.962981+00:00",
    "updated_at": "2025-11-29T12:56:09.962981+00:00"
  },
  {
    "id": "be78163f-b122-429b-9b30-047ad89afa27",
    "question_text_en": "Which of the following is an example of a classification problem?",
    "question_text_ko": "5. 다음 중 분류 문제의 예는 무엇입니까?",
    "options_en": [
      "Predicting the price of a house",
      "Identifying whether an email is spam or not",
      "Estimating the number of customers in a store",
      "Predicting the temperature of a city"
    ],
    "options_ko": [
      "주택 가격 예측",
      "이메일이 스팸인지 아닌지 식별하기",
      "매장의 고객 수 추산",
      "도시의 온도 예측"
    ],
    "correct_answer": 1,
    "category": "Classification Problems",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:10.002684+00:00",
    "updated_at": "2025-11-29T12:56:10.002684+00:00"
  },
  {
    "id": "3cb303e4-e136-491e-9b5e-aa5f4850c519",
    "question_text_en": "Which evaluation metric is NOT typically used for regression models?",
    "question_text_ko": "6. 어떤 평가 지표가 일반적으로 회귀 모델에 사용되지 않습니까?",
    "options_en": [
      "R-squared (R²)",
      "Mean Absolute Error (MAE)",
      "F1-score",
      "Root Mean Squared Error (RMSE)"
    ],
    "options_ko": [
      "R제곱(R²)",
      "평균 절대 오차(MAE)",
      "F1 점수",
      "평균 제곱근 오차(RMSE)"
    ],
    "correct_answer": 2,
    "category": "Regression Metrics",
    "difficulty": "medium",
    "source_day": 2,
    "source_image_en": "day2_2_e.png",
    "source_image_ko": "day2_2_h.png",
    "created_at": "2025-11-29T12:56:10.035179+00:00",
    "updated_at": "2025-11-29T12:56:10.035179+00:00"
  },
  {
    "id": "9897396b-e959-4707-a015-0b5b7ea4ad4a",
    "question_text_en": "Which of the following is NOT a typical application of hierarchical clustering?",
    "question_text_ko": "다음 중 계층적 클러스터링의 일반적인 적용 분야가 아닌 것은 무엇입니까?",
    "options_en": [
      "Image segmentation",
      "Customer segmentation",
      "Linear regression",
      "Anomaly detection"
    ],
    "options_ko": [
      "이미지 분할",
      "고객 세분화",
      "선형 회귀",
      "이상 감지"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_1_e.png",
    "source_image_ko": "day3_1_h.png",
    "created_at": "2025-11-29T12:56:10.077568+00:00",
    "updated_at": "2025-11-29T12:56:10.077568+00:00"
  },
  {
    "id": "6baf17b4-ff09-4a10-8675-61d14173baf2",
    "question_text_en": "Which of the following is the first step in the k-means algorithm?",
    "question_text_ko": "다음 중 k-평균 알고리즘의 첫 번째 단계는 무엇입니까?",
    "options_en": [
      "Assignment of data points to the nearest centroids",
      "Recalculation of centroids",
      "Random initialization of centroids",
      "Iteration until convergence"
    ],
    "options_ko": [
      "가장 가까운 중심에 데이터 포인트 할당",
      "중심점 재계산",
      "중심점의 무작위 초기화",
      "수렴할 때까지 반복"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_1_e.png",
    "source_image_ko": "day3_1_h.png",
    "created_at": "2025-11-29T12:56:10.112934+00:00",
    "updated_at": "2025-11-29T12:56:10.112934+00:00"
  },
  {
    "id": "a67be8fb-a2a7-4ab7-b5bb-0f7f8c06ed94",
    "question_text_en": "Which of the following methods helps assess how well each data point fits within its assigned cluster in k-means?",
    "question_text_ko": "다음 방법 중 어떤 것이 k-공간에서 각 데이터 포인트가 할당된 클러스터에 얼마나 잘 들어맞는지 평가하는 데 도움이 됩니까?",
    "options_en": [
      "Elbow Method",
      "Silhouette Analysis",
      "Domain Knowledge",
      "Grid Search"
    ],
    "options_ko": [
      "관측치 방법",
      "실루엣 분석",
      "도메인 지식",
      "그리드 검색"
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_1_e.png",
    "source_image_ko": "day3_1_h.png",
    "created_at": "2025-11-29T12:56:10.145685+00:00",
    "updated_at": "2025-11-29T12:56:10.145685+00:00"
  },
  {
    "id": "6f4db695-97ec-47d5-885f-30b3b9f090e4",
    "question_text_en": "What are we looking for in the plot generated by the Elbow Method?",
    "question_text_ko": "엘보우방법으로 생성된 플롯에서 우리는 무엇을 찾고 있는가?",
    "options_en": [
      "A sharp peak",
      "A gradual slope",
      "A bend or \"elbow\" point",
      "A straight line"
    ],
    "options_ko": [
      "낮아진 분점",
      "점진적인 감소",
      "균형 또는 '팔꿈치' 지점",
      "직선"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_1_e.png",
    "source_image_ko": "day3_1_h.png",
    "created_at": "2025-11-29T12:56:10.185733+00:00",
    "updated_at": "2025-11-29T12:56:10.185733+00:00"
  },
  {
    "id": "1ca6afa5-a309-400d-a041-7690bf57e17f",
    "question_text_en": "What is the visual representation of the hierarchical clustering process called?",
    "question_text_ko": "계층적 클러스터링 과정의 시각적 표현은 무엇이라고 하나요?",
    "options_en": [
      "Scatter plot",
      "Dendrogram",
      "Histogram",
      "Box plot"
    ],
    "options_ko": [
      "산포도",
      "덴드로그램",
      "히스토그램",
      "상자 그림"
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_1_e.png",
    "source_image_ko": "day3_1_h.png",
    "created_at": "2025-11-29T12:56:10.220391+00:00",
    "updated_at": "2025-11-29T12:56:10.220391+00:00"
  },
  {
    "id": "1ab76def-d6c2-4b0f-a7db-d25f7bc40ba5",
    "question_text_en": "Which of the following statements is true about agglomerative clustering?",
    "question_text_ko": "다음 중 응집적 클러스터링에 관해 사실인 진술은 무엇입니까?",
    "options_en": [
      "It's a top-down approach",
      "It starts with each data point as its own cluster",
      "It's computationally less expensive than divisive clustering for large datasets",
      "It doesn't require a distance metric"
    ],
    "options_ko": [
      "그것은 상향식 접근 방식입니다",
      "각 데이터 포인트로 자체 클러스터로 시작됩니다.",
      "대규모 데이터 세트의 경우 분할 클러스터링보다 계산 비용이 저렴합니다.",
      "거리 측정이 필요하지 않습니다."
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.253831+00:00",
    "updated_at": "2025-11-29T12:56:10.253831+00:00"
  },
  {
    "id": "65964041-b10c-488d-9121-bc2c49b586f0",
    "question_text_en": "Which Clustering method can help us to find clusters of arbitrary shapes?",
    "question_text_ko": "어떤 클러스터링 방법이 임의의 모양의 클러스터를 찾는 데 도움이 될 수 있습니까?",
    "options_en": [
      "K-Means Clustering",
      "Hierarchical Clustering",
      "DBScan Clustering",
      "K-Medoids Clustering"
    ],
    "options_ko": [
      "계층적 클러스터링",
      "계속적 클러스터링",
      "DBScan 클러스터링",
      "K-Medoids 클러스터링"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.302258+00:00",
    "updated_at": "2025-11-29T12:56:10.302258+00:00"
  },
  {
    "id": "b4edfd3c-36ff-4716-931d-9ad5bb5c06e4",
    "question_text_en": "What are the two key metrics used to evaluate the strength of an association rule?",
    "question_text_ko": "연관 규칙의 강도를 평가하는 데 사용되는 두 가지 주요 지표는 무엇입니까?",
    "options_en": [
      "Accuracy and Precision",
      "Support and Confidence",
      "Recall and F1-score",
      "Mean and Median"
    ],
    "options_ko": [
      "정확도와 정밀도",
      "지연과 신뢰",
      "리콜 및 F1 점수",
      "평균과 중앙값"
    ],
    "correct_answer": 1,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.348262+00:00",
    "updated_at": "2025-11-29T12:56:10.348262+00:00"
  },
  {
    "id": "7b5a79aa-6b2c-4357-ba53-a45fa174c2d2",
    "question_text_en": "Which metric quantifies the likelihood of item Y being purchased when item X is purchased, relative to the overall likelihood of Y being purchased?",
    "question_text_ko": "어떤 지표는 품목 X가 구매될 때 품목 Y가 구매될 가능성을 Y가 구매될 전체 가능성에 비해 정량화하는가?",
    "options_en": [
      "Support",
      "Confidence",
      "Lift",
      "Count"
    ],
    "options_ko": [
      "지지력",
      "신뢰",
      "승강기",
      "세다"
    ],
    "correct_answer": 2,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.38056+00:00",
    "updated_at": "2025-11-29T12:56:10.38056+00:00"
  },
  {
    "id": "67d74515-989e-488f-bdfc-2ce82bef8e05",
    "question_text_en": "Which of the following is NOT a step in the association rule mining process?",
    "question_text_ko": "다음 중 연관 규칙 마이닝 프로세스의 단계가 아닌 것은 무엇입니까?",
    "options_en": [
      "Generate Frequent Itemsets",
      "Generate Rules",
      "Evaluate Rules",
      "Cluster Analysis"
    ],
    "options_ko": [
      "빈발한 항목 집합 생성",
      "규칙 생성",
      "규칙 평가",
      "클러스터 분석"
    ],
    "correct_answer": 3,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.423546+00:00",
    "updated_at": "2025-11-29T12:56:10.423546+00:00"
  },
  {
    "id": "3020cd0e-4125-4560-914d-0288a8c61731",
    "question_text_en": "Which of the following is NOT a key feature of RAPIDS?",
    "question_text_ko": "다음 중 RAPIDS의 핵심이 아닌 것은 무엇입니까?",
    "options_en": [
      "Open-Source Software Library",
      "GPU Acceleration",
      "Drop-In Replacement for Existing Libraries",
      "Automatic Model Selection"
    ],
    "options_ko": [
      "오픈 소스 소프트웨어 라이브러리",
      "GPU 가속",
      "기존 도서관에 대한 드롭인 교체",
      "자동 모델 선택"
    ],
    "correct_answer": 3,
    "category": "RAPIDS",
    "difficulty": "medium",
    "source_day": 3,
    "source_image_en": "day3_2_e.png",
    "source_image_ko": "day3_2_h.png",
    "created_at": "2025-11-29T12:56:10.45836+00:00",
    "updated_at": "2025-11-29T12:56:10.45836+00:00"
  },
  {
    "id": "0738231d-a1f1-46a0-ab1b-e787f761e749",
    "question_text_en": "Which of the following is NOT a typical type of named entity recognized in NLP tasks?",
    "question_text_ko": "다음 중 NLP 작업에서 인식되는 일반적인 명명된 엔티티 유형이 아닌 것은 무엇입니까?",
    "options_en": [
      "Person",
      "Organization",
      "Location",
      "Adjective"
    ],
    "options_ko": [
      "사람",
      "조직",
      "위치",
      "형용사"
    ],
    "correct_answer": 3,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_1_e.png",
    "source_image_ko": "day6_1_h.png",
    "created_at": "2025-11-29T12:56:11.393646+00:00",
    "updated_at": "2025-11-29T12:56:11.393646+00:00"
  },
  {
    "id": "a8ef1988-bcd3-4ed1-b368-a51097dd2260",
    "question_text_en": "Which layer in a DNN is responsible for receiving the raw input data?",
    "question_text_ko": "DNN의 어느 계층이 원시 입력 데이터를 수신하는 역할을 합니까?",
    "options_en": [
      "Input Layer",
      "Hidden Layer",
      "It determines the accuracy of the model.",
      "It has no significant role in machine learning"
    ],
    "options_ko": [
      "입력 레이어",
      "숨겨진 레이어",
      "이는 정확성 정확도를 결정합니다.",
      "마지막에서 중요한 역할을 합니다."
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_1_e.png",
    "source_image_ko": "day4_1_h.png",
    "created_at": "2025-11-29T12:56:10.490127+00:00",
    "updated_at": "2025-11-29T12:56:10.490127+00:00"
  },
  {
    "id": "afa29436-1837-46e4-9745-ca86d82fa19a",
    "question_text_en": "Which type of Deep Neural Network is best suited for processing images and videos?",
    "question_text_ko": "이런 유형의 딥 신경망이 이미지와 비디오를 처리하는 데 가장 적합합니까?",
    "options_en": [
      "Multi-Layer Perceptron (MLP)",
      "Convolutional Neural Network (CNN)",
      "Recurrent Neural Network (RNN)",
      "Generative Adversarial Network (GAN)"
    ],
    "options_ko": [
      "다층 퍼셉트론(MLP)",
      "합성곱 신경망(CNN)",
      "순환 신경망(RNN)",
      "생성적 적대 신경망(GAN)"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_1_e.png",
    "source_image_ko": "day4_1_h.png",
    "created_at": "2025-11-29T12:56:10.52783+00:00",
    "updated_at": "2025-11-29T12:56:10.52783+00:00"
  },
  {
    "id": "1f4070a6-fb9d-439f-a161-37d3bb555915",
    "question_text_en": "What role do Weights play in an artificial neuron?",
    "question_text_ko": "인공 뉴런에서 가중치는 어떤 역할을 하나요?",
    "options_en": [
      "Introduce non-linearity",
      "Determine the importance of each input",
      "Provide a constant offset",
      "Receive the initial data"
    ],
    "options_ko": [
      "비선형성을 도입합니다",
      "각 입력의 중요성을 결정하세요",
      "큰 단일 값으로 계산",
      "초기 데이터 수신"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_1_e.png",
    "source_image_ko": "day4_1_h.png",
    "created_at": "2025-11-29T12:56:10.564599+00:00",
    "updated_at": "2025-11-29T12:56:10.564599+00:00"
  },
  {
    "id": "03ad6ccf-28a1-48c1-8cc0-ae0ab03805cd",
    "question_text_en": "What is the first step in the computation process of an artificial neuron?",
    "question_text_ko": "인공 뉴런의 계층 경계에서 첫 번째 단계는 무엇입니까?",
    "options_en": [
      "Apply the activation function",
      "Calculate the weighted sum",
      "Transmit the output signal",
      "Adjust the bias"
    ],
    "options_ko": [
      "활성화 함수를 적용합니다",
      "가중치를 계산합니다",
      "출력 신호를 전송합니다",
      "입력을 조정하다"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_1_e.png",
    "source_image_ko": "day4_1_h.png",
    "created_at": "2025-11-29T12:56:10.606346+00:00",
    "updated_at": "2025-11-29T12:56:10.606346+00:00"
  },
  {
    "id": "f6a94761-f2fc-410a-9e9b-d50da4621dfc",
    "question_text_en": "What is the initial step in the Gradient Descent algorithm?",
    "question_text_ko": "경사 하강 알고리즘의 초기 단계는 무엇입니까?",
    "options_en": [
      "Calculate the gradient of the loss function",
      "Update the model parameters",
      "Initialize the model parameters with random values",
      "Repeat steps until convergence"
    ],
    "options_ko": [
      "손실 함수의 기울기를 계산합니다",
      "모델 입력처리를 만듭니다",
      "알맞은 모듈로 모델 매개변수를 초기화합니다",
      "추출된 매개변수를 변형합니다"
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_1_e.png",
    "source_image_ko": "day4_1_h.png",
    "created_at": "2025-11-29T12:56:10.639296+00:00",
    "updated_at": "2025-11-29T12:56:10.639296+00:00"
  },
  {
    "id": "ec8711f4-1cd3-4a3c-8d01-dfac73fd3e1f",
    "question_text_en": "What is the mathematical formula for the ReLU activation function?",
    "question_text_ko": "ReLU 활성화 함수의 수학 공식은 무엇인가요?",
    "options_en": [
      "f(x) = max(0, x)",
      "f(x) = 1 / (1 + e^-x)",
      "f(x) = tanh(x)",
      "f(x) = x"
    ],
    "options_ko": [
      "f(x) = max(0, x)",
      "f(x) = 1 / (1 + e^-x)",
      "f(x) = tanh(x)",
      "f(x) = x"
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.669894+00:00",
    "updated_at": "2025-11-29T12:56:10.669894+00:00"
  },
  {
    "id": "eddaefd7-3a30-48c1-87ea-11f9ea192fe2",
    "question_text_en": "What is the purpose of applying an activation function in a neuron?",
    "question_text_ko": "뚜렷이 활성화 함수를 적용하는 목적은 무엇인가요?",
    "options_en": [
      "To normalize the input values",
      "To introduce non-linearity into the model",
      "To calculate the weighted sum of inputs",
      "To produce the final prediction"
    ],
    "options_ko": [
      "입력값을 규정화하기 위해",
      "모델의 비선형성을 도입하려면",
      "입력의 가중평균을 계산하려면",
      "새로운 예측을 생성하려면"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.703041+00:00",
    "updated_at": "2025-11-29T12:56:10.703041+00:00"
  },
  {
    "id": "2d1c8a1c-d810-497d-9aad-cd27febf7f9a",
    "question_text_en": "In the equation Z = W * X + b, what does Z represent?",
    "question_text_ko": "Z = W * x + b 방정식에서 Z는 무엇을 나타내나요?",
    "options_en": [
      "The weight matrix",
      "The input matrix",
      "The bias vector",
      "The matrix of weighted sums for all neurons in a layer"
    ],
    "options_ko": [
      "가중치 행렬",
      "편향 행렬",
      "하이퍼볼릭 탄젠트",
      "계층의 모든 뉴런에 대한 가중 합의 행렬"
    ],
    "correct_answer": 3,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.733823+00:00",
    "updated_at": "2025-11-29T12:56:10.733823+00:00"
  },
  {
    "id": "fa5d599a-12f7-4ff9-9902-4732471b02a7",
    "question_text_en": "What is the primary goal of backpropagation in neural networks?",
    "question_text_ko": "신경망에서 역전파 알고리즘의 주요 목적은 무엇인가요?",
    "options_en": [
      "To initialize the model's parameters",
      "To make predictions on new data",
      "To minimize the overall error and improve model accuracy",
      "To introduce non-linearity into the model"
    ],
    "options_ko": [
      "모델의 파라미터를 초기화하려면",
      "새로운 데이터에 대한 예측을 하려면",
      "성능을 최적화하고 모델의 정확도를 향상시키려면",
      "모델의 비선형성을 도입하려면"
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.766372+00:00",
    "updated_at": "2025-11-29T12:56:10.766372+00:00"
  },
  {
    "id": "dbc59cf3-d89f-4398-bdb1-b8b74a28fe37",
    "question_text_en": "Which step involves feeding the input data through the network to generate a prediction?",
    "question_text_ko": "예측을 생성하기 위해 딥러닝 네트워크에 공급하는 단계는 무엇인가?",
    "options_en": [
      "Forward Pass",
      "Loss Calculation",
      "Backward Pass",
      "Weight Initialization"
    ],
    "options_ko": [
      "프로토콜 분석",
      "손실 계산",
      "역전파",
      "가중치 초기화"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.799051+00:00",
    "updated_at": "2025-11-29T12:56:10.799051+00:00"
  },
  {
    "id": "6c67082a-ceab-4445-bddb-27f0c4138e6f",
    "question_text_en": "Given a categorical feature with values ['red', 'green', 'blue'], what would be the one-hot encoded representation of 'green'?",
    "question_text_ko": "'red', 'green', 'blue' ]라는 범주의 특성이 주어졌을 때, 'green'의 원핫 인코딩 표현은 무엇인가요?",
    "options_en": [
      "[1, 0, 0]",
      "[0, 1, 0]",
      "[0, 0, 1]",
      "[1, 1, 0]"
    ],
    "options_ko": [
      "[0, 1, 0]",
      "[1, 0, 0]",
      "[0, 0, 1]",
      "[1, 1, 0]"
    ],
    "correct_answer": 1,
    "category": "Data Preprocessing",
    "difficulty": "medium",
    "source_day": 4,
    "source_image_en": "day4_2_e.png",
    "source_image_ko": "day4_2_h.png",
    "created_at": "2025-11-29T12:56:10.833825+00:00",
    "updated_at": "2025-11-29T12:56:10.833825+00:00"
  },
  {
    "id": "7e98b2ee-1d35-4120-a0f1-472ced3bbd64",
    "question_text_en": "What type of data are Convolutional Neural Networks (CNNs) primarily designed to process?",
    "question_text_ko": "합성곱 신경망(CNN)은 주로 어떤 유형의 데이터를 처리하도록 설계되었습니까?",
    "options_en": [
      "Sequential data, such as text or time series",
      "Tabular data with structured features",
      "Grid-like data, such as images and video",
      "Audio data"
    ],
    "options_ko": [
      "텍스트나 시계열과 같은 순차적 데이터",
      "구조화된 값이 있는 표 형식 데이터",
      "이미지, 비디오 등 2 그리드 형탤 데이터",
      "오디오 데이터"
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_1_e.png",
    "source_image_ko": "day5_1_h.png",
    "created_at": "2025-11-29T12:56:10.87086+00:00",
    "updated_at": "2025-11-29T12:56:10.87086+00:00"
  },
  {
    "id": "478b35dd-cd2b-44b8-9aee-95761cfc2504",
    "question_text_en": "What is the primary purpose of Pooling Layers in a CNN?",
    "question_text_ko": "CNN에서 풀링 레이어의 주요 목적은 무엇입니까?",
    "options_en": [
      "To increase the spatial dimensions of the data",
      "To introduce non-linearity into the model",
      "To reduce the spatial dimensions of the data by downsampling",
      "To generate the final output predictions"
    ],
    "options_ko": [
      "데이터의 공간적 차원을 늘리려면",
      "모델의 반상성능을 도울하려면",
      "다운샘플링을 통해 데이터의 공간적 차원을 줄이려면",
      "최종 출력 예측을 생성하려면"
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_1_e.png",
    "source_image_ko": "day5_1_h.png",
    "created_at": "2025-11-29T12:56:10.914865+00:00",
    "updated_at": "2025-11-29T12:56:10.914865+00:00"
  },
  {
    "id": "66bacd41-8ef3-4017-88d6-f83ef0bbb1e1",
    "question_text_en": "What is the primary goal of Named Entity Recognition (NER)?",
    "question_text_ko": "명명된 개체 인식(NER)의 주요 목표는 무엇인가요?",
    "options_en": [
      "To identify and classify named entities in text, such as names of people, organizations, locations, etc.",
      "To translate text from one language to another",
      "To generate human-like text",
      "To summarize large documents"
    ],
    "options_ko": [
      "사람, 조직, 위치 등의 이름 등 텍스트에서 명명된 엔티티를 식별하고 분류합니다.",
      "한 언어에서 다른 언어로 텍스트를 번역하려면",
      "인간과 유사한 텍스트를 생성하려면",
      "대용량 문서를 요약하려면"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.431165+00:00",
    "updated_at": "2025-11-29T12:56:11.431165+00:00"
  },
  {
    "id": "20d6f1ea-0663-4af3-88fe-3b2fca0f6555",
    "question_text_en": "What is the core concept behind transfer learning?",
    "question_text_ko": "전이 학습의 핵심 개념은 무엇입니까?",
    "options_en": [
      "Training a model from scratch on a small dataset.",
      "Leveraging knowledge from a pre-trained model on a new but related task.",
      "Creating a completely new neural network architecture for every task.",
      "Only using labeled data for training."
    ],
    "options_ko": [
      "작은 데이터세트를 이용해 처음부터 모델을 학습합니다.",
      "사전 훈련된 모델의 지식을 새롭지만 관련된 작업에 활용합니다.",
      "모든 작업에 대해 완전히 새로운 신경망 아키텍처를 만듭니다.",
      "레이블이 지정된 데이터만 사용하여 학습합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_1_e.png",
    "source_image_ko": "day5_1_h.png",
    "created_at": "2025-11-29T12:56:10.952557+00:00",
    "updated_at": "2025-11-29T12:56:10.952557+00:00"
  },
  {
    "id": "59e776a2-f65d-4bda-93cf-b4a225c34ceb",
    "question_text_en": "In which scenario is transfer learning most likely to be beneficial?",
    "question_text_ko": "어떤 시나리오에서 전이 학습이 가장 유익할 가능성이 높습니까?",
    "options_en": [
      "You have abundant labeled data for your specific task.",
      "The pre-trained model was trained on a task completely unrelated to your target task.",
      "You have ample computational resources and a large dataset for your new task.",
      "You have a small dataset for your specific task and limited computational resources."
    ],
    "options_ko": [
      "다량의 특정 환경에 적합한 레이블이 지정된 데이터가 풍부합니다.",
      "사전 학습된 모델은 대상 작업과 전혀 관련이 없는 작업에 대해 학습되었습니다.",
      "새로운 작업을 수행하기에 충분한 컴퓨팅 리소스와 대규모 데이터 세트를 찾고 있습니다.",
      "다량의 특정 환경에 필요한 데이터 세트는 작고 컴퓨팅 리소스도 제한적입니다."
    ],
    "correct_answer": 3,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_1_e.png",
    "source_image_ko": "day5_1_h.png",
    "created_at": "2025-11-29T12:56:10.985035+00:00",
    "updated_at": "2025-11-29T12:56:10.985035+00:00"
  },
  {
    "id": "be9fb046-3d95-418f-a66b-f97ead3c9dda",
    "question_text_en": "When loading the VGG16 model, what does setting include_top=False signify?",
    "question_text_ko": "VGG16 모델을 로드할 때 include_top=False로 설정하는 것은 무엇을 의미합니까?",
    "options_en": [
      "It excludes the final fully connected classification layers of the model",
      "It excludes the convolutional base of the model",
      "It loads the model without pre-trained weights",
      "It disables transfer learning"
    ],
    "options_ko": [
      "모델의 최상 층에 있는 Dense 계층을 제외합니다.",
      "모델의 학습량 기반을 제외합니다.",
      "사전 훈련된 가중치 없이 모델을 로드합니다.",
      "같이 학습을 비활성화합니다."
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_2_e.png",
    "source_image_ko": "day5_2_h.png",
    "created_at": "2025-11-29T12:56:11.0198+00:00",
    "updated_at": "2025-11-29T12:56:11.0198+00:00"
  },
  {
    "id": "e197ca99-3ee3-41d7-bd4a-ada12758a9b3",
    "question_text_en": "What is the purpose of freezing layers in the VGG16 model during transfer learning?",
    "question_text_ko": "같이 학습 없이 VGG16 모델에서 레이어를 동결하는 '활용'은 무엇입니까?",
    "options_en": [
      "To prevent the pre-trained weights from being updated during training",
      "To slightly speed up the training process",
      "To ensure the model learns only from the new data",
      "To reduce the model’s complexity"
    ],
    "options_ko": [
      "사전 훈련된 가중치가 없는 모델에서는 정확성을 저하",
      "훈련 과정 맨 마지막부터 접근하려면",
      "모델에 새로운 데이터셋만 학습하도록 하려면",
      "모델의 복잡성을 줄이려면"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_2_e.png",
    "source_image_ko": "day5_2_h.png",
    "created_at": "2025-11-29T12:56:11.063463+00:00",
    "updated_at": "2025-11-29T12:56:11.063463+00:00"
  },
  {
    "id": "6e887b8f-aff7-4db8-85d2-a32a275608c9",
    "question_text_en": "Which activation function maps the input to a range between 0 and 1 and is historically popular but suffers from vanishing gradients?",
    "question_text_ko": "어떤 활성 함수가 입력을 0~1 사이의 범위에 매핑하며, 역사적으로 입력 값 자체가 기울기가 사라지는 문제가 있는가?",
    "options_en": [
      "Sigmoid",
      "Hyperbolic Tangent (tanh)",
      "Rectified Linear Unit (ReLU)",
      "Linear"
    ],
    "options_ko": [
      "시그모이드",
      "쌍곡탄젠트(tanh)",
      "정류 선형 유닛(ReLU)",
      "선형"
    ],
    "correct_answer": 0,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_2_e.png",
    "source_image_ko": "day5_2_h.png",
    "created_at": "2025-11-29T12:56:11.094215+00:00",
    "updated_at": "2025-11-29T12:56:11.094215+00:00"
  },
  {
    "id": "049e88b1-9a35-4430-bc92-bcfb3e2a5d3a",
    "question_text_en": "Which activation function is similar to sigmoid but maps the input to a range between -1 and 1?",
    "question_text_ko": "시그모이드와 유사하지만 입력을 -1과 1 사이의 범위로 매핑하는 활성화 함수는 무엇인가?",
    "options_en": [
      "Sigmoid",
      "Hyperbolic Tangent (tanh)",
      "Rectified Linear Unit (ReLU)",
      "Linear"
    ],
    "options_ko": [
      "시그모이드",
      "쌍곡탄젠트(tanh)",
      "정류 선형 유닛(ReLU)",
      "선형"
    ],
    "correct_answer": 1,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_2_e.png",
    "source_image_ko": "day5_2_h.png",
    "created_at": "2025-11-29T12:56:11.129835+00:00",
    "updated_at": "2025-11-29T12:56:11.129835+00:00"
  },
  {
    "id": "3ea8a494-4005-41c8-8488-44a1e747286d",
    "question_text_en": "Which of the following is a common approach in transfer learning?",
    "question_text_ko": "다음 중 같이 학습에서 일반적인 접근 방식은 무엇인가?",
    "options_en": [
      "Training a model from scratch with random weights",
      "Completely discarding pre-trained models in every training iteration",
      "Avoiding the use of neural networks",
      "Using a pre-trained model as a feature extractor and fine-tuning only specific layers"
    ],
    "options_ko": [
      "무작위 가중치를 사용하여 처음부터 모델 학습",
      "모든 훈련 반복에서 사전 훈련 모델을 무시합니다.",
      "신경망 사전 훈련",
      "가중치 변환에 생성적 기능 출력을 사용하는 특성 데이터에 페널티 적용"
    ],
    "correct_answer": 3,
    "category": "Transfer Learning",
    "difficulty": "medium",
    "source_day": 5,
    "source_image_en": "day5_2_e.png",
    "source_image_ko": "day5_2_h.png",
    "created_at": "2025-11-29T12:56:11.162678+00:00",
    "updated_at": "2025-11-29T12:56:11.162678+00:00"
  },
  {
    "id": "b12bc754-8130-4dd7-9ebd-1267401e2e90",
    "question_text_en": "What is the primary challenge that Natural Language Processing (NLP) aims to address?",
    "question_text_ko": "자연어 처리(NLP)가 해결하고자 하는 주요 과제는 무엇입니까?",
    "options_en": [
      "The complexity and ambiguity of human language.",
      "The speed at which humans can process information.",
      "The vast amount of data generated by machines.",
      "The difficulty of programming computers in binary code."
    ],
    "options_ko": [
      "인간 언어의 복잡성과 모호성.",
      "인간이 정보를 처리할 수 있는 속도.",
      "기계가 생성하는 양질의 데이터.",
      "이진 코드를 컴퓨터를 프로그래밍하는 것은 어렵다."
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_1_e.png",
    "source_image_ko": "day6_1_h.png",
    "created_at": "2025-11-29T12:56:11.232567+00:00",
    "updated_at": "2025-11-29T12:56:11.232567+00:00"
  },
  {
    "id": "a0f1177e-ad94-4774-aef7-ff0072a29834",
    "question_text_en": "Which NLP preprocessing technique involves breaking down a text into smaller units like words or subwords?",
    "question_text_ko": "어떤 NLP 전처리 기법이 텍스트를 단어나 하위 단어와 같은 더 작은 단위로 분해하는 것을 포함합니까?",
    "options_en": [
      "Tokenization",
      "Stopword Removal",
      "Stemming",
      "Lemmatization"
    ],
    "options_ko": [
      "토큰화",
      "불용어 제거",
      "어간 분석",
      "레마티제이션"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_1_e.png",
    "source_image_ko": "day6_1_h.png",
    "created_at": "2025-11-29T12:56:11.279411+00:00",
    "updated_at": "2025-11-29T12:56:11.279411+00:00"
  },
  {
    "id": "7638c447-7b12-4204-bb6b-bd6efe440755",
    "question_text_en": "Which text normalization technique aims to reduce words to their base or root form, often by removing suffixes?",
    "question_text_ko": "어떤 텍스트 정규화 기술이 접미사를 제거하여 단어를 기본 형태나 어근 형태로 줄이는 것을 목표로 합니까?",
    "options_en": [
      "Stemming",
      "Lemmatization",
      "Expanding contractions",
      "Tokenization"
    ],
    "options_ko": [
      "어간 분석",
      "레마티제이션",
      "추상 추출",
      "토큰화"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_1_e.png",
    "source_image_ko": "day6_1_h.png",
    "created_at": "2025-11-29T12:56:11.319366+00:00",
    "updated_at": "2025-11-29T12:56:11.319366+00:00"
  },
  {
    "id": "703edd1b-75ea-453a-829a-1f4c804e98f1",
    "question_text_en": "When building an NLP pipeline, how should you choose the specific components to include?",
    "question_text_ko": "NLP 파이프라인을 구축할 때 포함할 특정 구성 요소를 어떻게 선택해야 합니까?",
    "options_en": [
      "Randomly select components.",
      "Always use the same components for every task",
      "Base the selection on the specific NLP task you are trying to solve",
      "Only use pre-built pipelines, never customize"
    ],
    "options_ko": [
      "무작위로 구성요소를 선택합니다.",
      "모든 작업이 항상 동일한 구성 요소를 사용하십시오.",
      "해결하려는 특정 NLP 작업에 따라 선택을 기반으로 하세요.",
      "미리 구축된 파이프라인만 사용하고 사용자 정의하지 마십시오."
    ],
    "correct_answer": 2,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_1_e.png",
    "source_image_ko": "day6_1_h.png",
    "created_at": "2025-11-29T12:56:11.362435+00:00",
    "updated_at": "2025-11-29T12:56:11.362435+00:00"
  },
  {
    "id": "6dfa6c4c-13d6-4a20-94b3-030ef61120b3",
    "question_text_en": "What are word embeddings?",
    "question_text_ko": "워드 임베딩이란 무엇인가요?",
    "options_en": [
      "Sparse matrices representing the frequency of words in a document.",
      "Dense vector representations of words in a continuous vector space.",
      "One-hot encoded representations of words.",
      "Syntactic trees capturing the grammatical structure of sentences."
    ],
    "options_ko": [
      "문서에서 단어의 빈도를 나타내는 희소 행렬입니다.",
      "연속적인 벡터 공간에서 단어에 밀집 벡터 표현입니다.",
      "단어의 원작 인코딩 표현.",
      "문장의 문법적 구조를 포함하는 구문 트리."
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.46637+00:00",
    "updated_at": "2025-11-29T12:56:11.46637+00:00"
  },
  {
    "id": "b0856607-419a-4e75-9153-bb928b978f07",
    "question_text_en": "How are pre-trained word embeddings typically used in NLP models?",
    "question_text_ko": "사전 훈련된 단어 임베딩은 일반적으로 NLP 모델에서 어떻게 사용됩니까?",
    "options_en": [
      "They are directly fed into the final output layer of the model.",
      "They are used as input features to the model.",
      "They replace the need for any other feature engineering.",
      "They are only used for language generation tasks."
    ],
    "options_ko": [
      "이는 모델의 최종 출력 계층에 직접 입력됩니다.",
      "이는 모델의 입력 기능으로 사용됩니다.",
      "이는 다른 기능 엔지니어링 필요성을 대체합니다.",
      "이는 언어 생성 작업에만 사용됩니다."
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.499477+00:00",
    "updated_at": "2025-11-29T12:56:11.499477+00:00"
  },
  {
    "id": "dfe99f9f-37d0-4d5d-9021-1c7713b4bb14",
    "question_text_en": "Which of the following are the two main architectures used in Word2Vec?",
    "question_text_ko": "다음 중 Word2Vec에 사용되는 두 가지 주요 아키텍처는 무엇입니까?",
    "options_en": [
      "Continuous Bag-of-Words (CBOW) and Skip-gram",
      "Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)",
      "Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs)",
      "Transformer and BERT"
    ],
    "options_ko": [
      "연속 백 오브 워드(CBOW) 및 스킵그램",
      "합성곱 신경망(CNN)과 순환 신경망(RNN)",
      "장단기 기억(LSTM) 및 게이트형 순환 단위(GRU)",
      "트랜스포머와 BERT"
    ],
    "correct_answer": 0,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.531146+00:00",
    "updated_at": "2025-11-29T12:56:11.531146+00:00"
  },
  {
    "id": "a1605461-8ea4-4e18-bda1-090047b3e8be",
    "question_text_en": "In the Continuous Bag-of-Words (CBOW) architecture of Word2Vec, what is the model trying to predict?",
    "question_text_ko": "Word2Vec의 CBOW(Continuous Bag-of-Words) 아키텍처에서 모델은 무엇을 예측하려고 합니까?",
    "options_en": [
      "The next word in a sentence.",
      "The missing word in a sentence given its surrounding context.",
      "The surrounding context words given a target word",
      "The sentiment of a sentence"
    ],
    "options_ko": [
      "문장의 다음 단어.",
      "주변 맥락을 고려했을 때 문장에서 빠진 단어.",
      "입력 단어가 주어졌을 때 주변 맥락 단어",
      "문장의 감정"
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.569579+00:00",
    "updated_at": "2025-11-29T12:56:11.569579+00:00"
  },
  {
    "id": "5ad98945-387c-4b97-a7ed-8ca84bd67717",
    "question_text_en": "Which of the following best describes the nature of text data?",
    "question_text_ko": "다음 중 텍스트 데이터의 특성을 가장 잘 설명하는 것은 무엇입니까?",
    "options_en": [
      "Highly structured and uniform",
      "Unstructured and diverse",
      "Primarily numerical",
      "Limited to short sentences"
    ],
    "options_ko": [
      "고도로 구조화되고 규일함",
      "비구조적이고 다양함",
      "주로 숫자",
      "짧은 문장으로 제한됨"
    ],
    "correct_answer": 1,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 6,
    "source_image_en": "day6_2_e.png",
    "source_image_ko": "day6_2_h.png",
    "created_at": "2025-11-29T12:56:11.601153+00:00",
    "updated_at": "2025-11-29T12:56:11.601153+00:00"
  },
  {
    "id": "44a2ebf0-b354-4875-8f1d-1e755f6b1d0c",
    "question_text_en": "In an RNN, how is the input at each time step processed?",
    "question_text_ko": "RNN에서 각 시간 단계의 입력은 어떻게 처리되나요?",
    "options_en": [
      "It is directly fed into the output layer.",
      "It is combined with the previous hidden state.",
      "It is processed independently of the previous hidden state.",
      "It is first passed through a convolutional layer."
    ],
    "options_ko": [
      "이는 출력 계층에 직접 공급됩니다.",
      "이는 이전의 숨겨진 상태와 결합됩니다.",
      "이는 이전의 숨겨진 상태와 독립적으로 처리됩니다.",
      "먼저 함성곱 계층을 통과합니다."
    ],
    "correct_answer": 1,
    "category": "RNNs",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_1_e.png",
    "source_image_ko": "day7_1_h.png",
    "created_at": "2025-11-29T12:56:11.695369+00:00",
    "updated_at": "2025-11-29T12:56:11.695369+00:00"
  },
  {
    "id": "dce999f4-7924-4c93-bbc0-6d360d3a2f05",
    "question_text_en": "Which of the following is NOT an application of RNNs in Natural Language Processing (NLP)?",
    "question_text_ko": "다음 중 자연어 처리(NLP)에 RNN을 적용한 것이 아닌 것은 무엇입니까?",
    "options_en": [
      "Machine translation",
      "Sentiment analysis",
      "Image recognition",
      "Text generation"
    ],
    "options_ko": [
      "기계 번역",
      "감정 분석",
      "이미지 인식",
      "텍스트 생성"
    ],
    "correct_answer": 2,
    "category": "RNNs",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_1_e.png",
    "source_image_ko": "day7_1_h.png",
    "created_at": "2025-11-29T12:56:11.745175+00:00",
    "updated_at": "2025-11-29T12:56:11.745175+00:00"
  },
  {
    "id": "b1c6b68f-5461-478f-b41f-e51ef26dc629",
    "question_text_en": "What is the core issue in the vanishing gradient problem?",
    "question_text_ko": "사라지는 기울기 문제의 핵심 문제는 무엇입니까?",
    "options_en": [
      "Gradients become exponentially larger as they propagate backward through layers.",
      "Gradients become exponentially smaller as they propagate backward through layers.",
      "Gradients remain constant as they propagate backward through layers.",
      "Gradients fluctuate randomly as they propagate backward through layers."
    ],
    "options_ko": [
      "기울기는 레이어에 따라 뒤로 전달될수록 기하급수적으로 커집니다.",
      "기울기는 계층을 따라 뒤로 전달될수록 기하급수적으로 작아집니다.",
      "기울기는 레이어를 따라 뒤로 전달되면서도 일정하게 유지됩니다.",
      "기울기는 층을 따라 뒤로 전달되면서 무작위로 변동합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_1_e.png",
    "source_image_ko": "day7_1_h.png",
    "created_at": "2025-11-29T12:56:11.819102+00:00",
    "updated_at": "2025-11-29T12:56:11.819102+00:00"
  },
  {
    "id": "d4e41016-8f5d-48c7-9acb-21c4e6ec5d62",
    "question_text_en": "What is the key innovation introduced by the Transformer architecture?",
    "question_text_ko": "Transformer 아키텍처가 도입한 주요 혁신은 무엇입니까?",
    "options_en": [
      "Convolutional layers",
      "Recurrent neural networks",
      "Self-attention mechanisms",
      "Long short-term memory cells"
    ],
    "options_ko": [
      "합성곱 레이어",
      "순환 신경망",
      "자기 주의 메커니즘",
      "장기 단기 기억 셀"
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:11.853745+00:00",
    "updated_at": "2025-11-29T12:56:11.853745+00:00"
  },
  {
    "id": "387e5d49-f7d2-471f-ba29-4639e8f196ba",
    "question_text_en": "What is the purpose of having multiple attention heads in Transformers?",
    "question_text_ko": "트랜스포머에 여러 개의 어텐션 헤더가 있는 목적은 무엇입니까?",
    "options_en": [
      "To increase the model's computational complexity",
      "To allow the model to focus on different aspects of the input simultaneously",
      "To reduce the number of parameters in the model",
      "To enable the model to process images and text data together"
    ],
    "options_ko": [
      "모델의 계산 복잡성을 높이려면",
      "모델이 입력의 다양한 부분에 동시에 집중할 수 있도록 하려면",
      "모델의 매개변수 수를 줄이려면",
      "모델이 이미지와 텍스트 데이터를 함께 처리할 수 있도록 하려면"
    ],
    "correct_answer": 1,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:11.891934+00:00",
    "updated_at": "2025-11-29T12:56:11.891934+00:00"
  },
  {
    "id": "23310499-9f5d-4745-ac36-615d1a4adff9",
    "question_text_en": "What is the primary role of positional encoding in Transformers?",
    "question_text_ko": "트랜스포머에서 위치 인코딩의 주요 역할은 무엇입니까?",
    "options_en": [
      "To provide information about the absolute position of each word in the sequence.",
      "To enable the model to distinguish between different words in the vocabulary.",
      "To reduce the number of parameters in the model.",
      "To improve the model's ability to handle image data."
    ],
    "options_ko": [
      "시퀀스에서 각 단어의 절대 위치에 대한 정보를 제공합니다.",
      "모델이 입력의 순익 다양한 단어를 구별할 수 있도록 합니다.",
      "모델의 매개변수 수를 줄이려면.",
      "모델의 이미지 데이터 처리 능력을 향상시킵니다."
    ],
    "correct_answer": 0,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:11.930071+00:00",
    "updated_at": "2025-11-29T12:56:11.930071+00:00"
  },
  {
    "id": "7da55236-9def-4588-bc69-ad467482f634",
    "question_text_en": "",
    "question_text_ko": "머신 러닝에서 기능 스케일링의 주요 목적은 무엇입니까?",
    "options_en": [],
    "options_ko": [
      "반응형 데이터를 핵심적으로 향상시킵니다.",
      "이는 다른 규모의 연속 특징이 다른 기능과 기울기를 지배하는 것을 방지합니다.",
      "데이터의 세트에서 정확 복사를 피합니다.",
      "모델 검증의 필요성이 없습니다."
    ],
    "correct_answer": 1,
    "category": "Data Preprocessing",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "",
    "source_image_ko": "day_1_han.png",
    "created_at": "2025-11-29T12:56:13.051869+00:00",
    "updated_at": "2025-11-29T12:56:13.051869+00:00"
  },
  {
    "id": "d244852b-5c0c-4de4-9114-e04f635ec675",
    "question_text_en": "How is positional encoding typically incorporated into the model's input?",
    "question_text_ko": "위치 인코딩은 일반적으로 어떻게 모델의 입력에 통합됩니까?",
    "options_en": [
      "It is used to replace the word embeddings entirely.",
      "It is fed into a separate network that generates attention masks.",
      "It is concatenated with the word embeddings.",
      "It is used to initialize the model's weights."
    ],
    "options_ko": [
      "이는 단어 임베딩을 완전히 대체하는 데 사용됩니다.",
      "이는 주의 마스크를 생성하는 별도의 네트워크에 입력됩니다.",
      "이는 단어 임베딩과 연결됩니다.",
      "모델의 가중치를 초기화하는 데 사용됩니다."
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:11.968145+00:00",
    "updated_at": "2025-11-29T12:56:11.968145+00:00"
  },
  {
    "id": "1a53a47e-13f7-4091-8b75-dd6de0efa9f3",
    "question_text_en": "What is the primary challenge posed by the permutation-invariant nature of self-attention in Transformers when dealing with natural language?",
    "question_text_ko": "자연어를 다룰 때 트랜스포머에서 자기 주의의 순열 불변적 특성으로 인해 발생하는 주요 과제는 무엇입니까?",
    "options_en": [
      "It makes it difficult to capture long-range dependencies in a sentence.",
      "It prevents the model from distinguishing between synonyms.",
      "It makes it difficult to understand the relationships between words in a sentence.",
      "It leads to the model generating grammatically incorrect sentences."
    ],
    "options_ko": [
      "문맥이 장거리 종속성을 포함하기 어렵게 만듭니다.",
      "이로 인해 모델이 동일한 단어를 구별하지 못합니다.",
      "문장 속 단어 사이의 관계를 이해하는 것이 어렵습니다.",
      "이로 인해 모델이 문법적으로 잘못된 문장을 생성하게 됩니다."
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:12.008735+00:00",
    "updated_at": "2025-11-29T12:56:12.008735+00:00"
  },
  {
    "id": "0c4db75f-c010-419d-893d-0b9b52f8ecdf",
    "question_text_en": "What is the primary purpose of memory cells in LSTMs?",
    "question_text_ko": "LSTM에서 메모리 셀의 주요 목적은 무엇입니까?",
    "options_en": [
      "To process input sequences in parallel.",
      "To introduce non-linearity into the network.",
      "To maintain long-term information across time steps.",
      "To regulate the learning rate during training."
    ],
    "options_ko": [
      "입력 시퀀스를 병렬로 처리합니다.",
      "네트워크의 비선형성을 도입합니다.",
      "시간 단위에 걸쳐 장기 정보를 유지합니다.",
      "훈련 중 학습률을 조절합니다."
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_2_e.png",
    "source_image_ko": "day7_2_h.png",
    "created_at": "2025-11-29T12:56:12.042594+00:00",
    "updated_at": "2025-11-29T12:56:12.042594+00:00"
  },
  {
    "id": "430ebb3b-593b-4006-963c-1229458f2f56",
    "question_text_en": "What is the purpose of pre-training in LLM development?",
    "question_text_ko": "LLM 개발에서 사전 교육의 목적은 무엇입니까?",
    "options_en": [
      "To specialize the model for a specific task",
      "To teach the model general language patterns from diverse text sources",
      "To reduce the model's size",
      "To improve the model's inference speed"
    ],
    "options_ko": [
      "특정 작업에 맞게 모델을 전문화하려면",
      "다양한 텍스트 소스에서 모델 일반 언어 패턴을 가르치려면",
      "모델의 크기를 줄이려면",
      "모델의 추론 속도를 개선하려면"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_1_e.png",
    "source_image_ko": "day8_1_h.png",
    "created_at": "2025-11-29T12:56:12.078118+00:00",
    "updated_at": "2025-11-29T12:56:12.078118+00:00"
  },
  {
    "id": "d275d630-6f88-490e-8894-01af154acebd",
    "question_text_en": "What is the main purpose of a Transformer pipeline in Hugging Face's Transformers library?",
    "question_text_ko": "Hugging Face의 Transformers 라이브러리에서 Transformer 파이프라인의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train a Transformer model from scratch.",
      "To fine-tune a pre-trained Transformer model on a specific task",
      "To simplify the process of applying pre-trained Transformer models to various NLP tasks",
      "To visualize the internal workings of a Transformer model"
    ],
    "options_ko": [
      "Transformer 모델을 처음부터 학습합니다.",
      "특정 작업에 대해서 사전 훈련된 Transformer 모델을 미세 조정하려면",
      "다양한 NLP 작업에 사전 훈련된 Transformer 모델을 적용하는 프로세스를 단순화하려면",
      "Transformer 모델의 내부 작동을 시각화하려면"
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_1_e.png",
    "source_image_ko": "day8_1_h.png",
    "created_at": "2025-11-29T12:56:12.127378+00:00",
    "updated_at": "2025-11-29T12:56:12.127378+00:00"
  },
  {
    "id": "acb3a509-fb5d-4383-9f02-3f5726ee6e40",
    "question_text_en": "When using a Hugging Face pipeline for text classification, what is the typical input?",
    "question_text_ko": "텍스트 분류에 Hugging Face 파이프라인을 사용할 때 일반적인 입력은 무엇입니까?",
    "options_en": [
      "A pre-trained LLM",
      "A list of text samples to be classified",
      "The desired output labels",
      "The path to a dataset"
    ],
    "options_ko": [
      "사전 훈련된 LLM",
      "분류할 텍스트 샘플 목록",
      "원하는 출력 레이블",
      "데이터 세트 경로"
    ],
    "correct_answer": 1,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_1_e.png",
    "source_image_ko": "day8_1_h.png",
    "created_at": "2025-11-29T12:56:12.170419+00:00",
    "updated_at": "2025-11-29T12:56:12.170419+00:00"
  },
  {
    "id": "e57a26eb-bb21-4a19-b6ab-262391253d76",
    "question_text_en": "What is the core principle behind Generative Adversarial Networks (GANs)?",
    "question_text_ko": "생성적 적대 신경망(GAN)의 핵심 원리는 무엇입니까?",
    "options_en": [
      "Two neural networks collaborate to create realistic content.",
      "One neural network learns to compress data, while another decompresses it.",
      "Two neural networks compete against each other, one generating content and the other evaluating its realism.",
      "A single neural network learns to predict the next word in a sequence."
    ],
    "options_ko": [
      "두 개의 신경망이 협력하여 사실적인 콘텐츠를 만듭니다.",
      "한 신경망은 데이터를 압축하는 법을 배우고, 다른 신경망은 압축을 해제합니다.",
      "두 개의 신경망이 서로 경쟁하는데, 하나는 콘텐츠를 생성하고 다른 하나는 콘텐츠의 현실성을 평가합니다.",
      "단일 신경망은 시퀀스의 다음 단계를 예측하는 법을 학습합니다."
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_1_e.png",
    "source_image_ko": "day8_1_h.png",
    "created_at": "2025-11-29T12:56:12.201643+00:00",
    "updated_at": "2025-11-29T12:56:12.201643+00:00"
  },
  {
    "id": "15da9396-7ede-40d0-a9cb-5be4919d0cbd",
    "question_text_en": "Why is diversity crucial in the data used to train generative AI models?",
    "question_text_ko": "생성 시 모델을 훈련하는 데 사용되는 데이터에서 다양성이 왜 중요한가요?",
    "options_en": [
      "It helps the model avoid overfitting to specific patterns",
      "It makes the model more versatile and capable of generating a wider range of content",
      "It reduces the computational resources required for training",
      "It ensures the model's output is always factually accurate"
    ],
    "options_ko": [
      "이는 모델이 특정 패턴에 과도하게 맞춰지는 것을 방지하는 데 도움이 됩니다.",
      "이는 모델을 더욱 다재다능하게 만들고 더 광범위한 콘텐츠를 생성할 수 있게 해줍니다.",
      "훈련에 필요한 계산 리소스를 줄여줍니다.",
      "이는 모델의 출력이 항상 사실적으로 정확함을 보장합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_2_e.png",
    "source_image_ko": "day8_2_h.png",
    "created_at": "2025-11-29T12:56:12.237768+00:00",
    "updated_at": "2025-11-29T12:56:12.237768+00:00"
  },
  {
    "id": "e32137af-1045-4e67-9a22-75566a395ea8",
    "question_text_en": "What is the advantage of incorporating texts from specific fields like medicine, law, or finance into LLM training data?",
    "question_text_ko": "의학, 법률, 금융 등 특정 분야의 텍스트를 LLM 교육 데이터에 통합하는 이점은 무엇입니까?",
    "options_en": [
      "It allows the model to develop specialized knowledge in those domains",
      "It improves the model's overall language understanding",
      "It speeds up the training process",
      "It enhances the model's ability to generate poetry"
    ],
    "options_ko": [
      "이를 통해 모델은 해당 도메인에 대한 전문 지식을 개발할 수 있습니다.",
      "모델의 전반적인 언어 이해도가 향상됩니다.",
      "훈련 과정을 가속화합니다.",
      "이는 모델의 생성 능력을 향상시킵니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_2_e.png",
    "source_image_ko": "day8_2_h.png",
    "created_at": "2025-11-29T12:56:12.278832+00:00",
    "updated_at": "2025-11-29T12:56:12.278832+00:00"
  },
  {
    "id": "6e8a50d1-28b6-49dc-a88b-543f3785f53a",
    "question_text_en": "",
    "question_text_ko": "sklearn.preprocessing에서 StandardScaler()의 목적은 무엇입니까?",
    "options_en": [],
    "options_ko": [
      "반응형 변수를 숫자 값으로 변환합니다.",
      "0과 1 사이의 스케일링으로 기능을 정규화합니다.",
      "평균과 표준편차로 입력 변수를 스케일링하여 기능을 표준화합니다.",
      "데이터 세트에서 누락된 값을 대체합니다."
    ],
    "correct_answer": 2,
    "category": "Data Preprocessing",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "",
    "source_image_ko": "day_1_han.png",
    "created_at": "2025-11-29T12:56:13.085688+00:00",
    "updated_at": "2025-11-29T12:56:13.085688+00:00"
  },
  {
    "id": "971cfb57-0a59-4287-965f-000fd038ef40",
    "question_text_en": "What is a direct consequence of training Large Language Models (LLMs) on poor-quality data?",
    "question_text_ko": "품질이 낮은 데이터로 대규모 언어 모델(LLM)을 훈련하면 직접적인 결과는 무엇입니까?",
    "options_en": [
      "Improved accuracy and reliability.",
      "Increased generalization to new information.",
      "Inaccurate outputs and biased responses.",
      "Faster training times and reduced computational costs."
    ],
    "options_ko": [
      "정확도와 신뢰성이 향상되었습니다.",
      "새로운 정보에 대한 일반화가 강해졌습니다.",
      "부정확한 출력과 편향된 응답.",
      "훈련 시간과 단축되고 계산 비용이 절감됩니다."
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_2_e.png",
    "source_image_ko": "day8_2_h.png",
    "created_at": "2025-11-29T12:56:12.311441+00:00",
    "updated_at": "2025-11-29T12:56:12.311441+00:00"
  },
  {
    "id": "8f4a209e-d363-4584-a2e6-60d6355e904b",
    "question_text_en": "How does NVIDIA contribute to the data pipeline for AI tasks?",
    "question_text_ko": "NVIDIA 사 작업을 위한 데이터 파이프라인이 어떻게 기여합니까?",
    "options_en": [
      "By manually curating training datasets for AI models",
      "By enabling GPU acceleration and distributed computing for data processing",
      "By replacing the need for diverse training data through AI simulations",
      "By focusing only on hardware and not on AI data pipelines"
    ],
    "options_ko": [
      "AI 모델 훈련을 위한 데이터 세트를 수동으로 큐레이팅하여",
      "데이터 처리를 위한 GPU 가속 및 분산 컴퓨팅을 활성화함으로써",
      "AI 시뮬레이션을 통해 다양한 효과의 데이터의 필요성을 대체함으로써",
      "AI 데이터 파이프라인이 아닌 하드웨어에만 집중함으로써"
    ],
    "correct_answer": 1,
    "category": "AI Infrastructure",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_2_e.png",
    "source_image_ko": "day8_2_h.png",
    "created_at": "2025-11-29T12:56:12.34463+00:00",
    "updated_at": "2025-11-29T12:56:12.34463+00:00"
  },
  {
    "id": "822d630a-215e-4bfd-b248-81c131796d42",
    "question_text_en": "What are the key challenges of feeding poor-quality data to large language models (LLMs)?",
    "question_text_ko": "품질이 낮은 데이터를 대규모 언어 모델(LLM)에 공급하는 데 있어 주요 과제는 무엇입니까?",
    "options_en": [
      "It improves the model’s ability to generalize new information.",
      "It results in inaccurate outputs, biased responses, and unreliable predictions.",
      "It has no impact on the performance of LLMs.",
      "It speeds up the training process of LLMs."
    ],
    "options_ko": [
      "이는 새로운 정보에 대한 모델의 능력을 향상시킵니다.",
      "그 결과 편향된 출력, 편향된 응답, 신뢰할 수 없는 예측이 발생합니다.",
      "이는 LLM의 성능에 영향을 미치지 않습니다.",
      "LLM의 교육 과정이 빨라집니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 8,
    "source_image_en": "day8_2_e.png",
    "source_image_ko": "day8_2_h.png",
    "created_at": "2025-11-29T12:56:12.378803+00:00",
    "updated_at": "2025-11-29T12:56:12.378803+00:00"
  },
  {
    "id": "6cdb7397-b0ad-4416-85d7-35f5ce56dd90",
    "question_text_en": "What does \"zero-shot learning\" refer to in the context of LLMs?",
    "question_text_ko": "1. LLM에서 '제로샷 러닝'이란 무엇을 의미합니까?",
    "options_en": [
      "The model's ability to learn new tasks without any prior examples or training.",
      "The model's ability to perform tasks with zero errors.",
      "The initial stage of training where the model has no knowledge.",
      "The process of fine-tuning the model on a specific task."
    ],
    "options_ko": [
      "① 모델은 사전 지식나 훈련 없이도 새로운 작업을 학습할 수 있는 능력을 갖추고 있습니다.",
      "② 모델이 오류 없이 작업을 수행할 수 있는 능력입니다.",
      "③ 모델이 아무런 지식도 가지고 있지 않은 환경의 초기 단계입니다.",
      "④ 특정 작업에 맞게 모델을 미세 조정하는 과정입니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_1_e.png",
    "source_image_ko": "day9_1_H.png",
    "created_at": "2025-11-29T12:56:12.413826+00:00",
    "updated_at": "2025-11-29T12:56:12.413826+00:00"
  },
  {
    "id": "0a75437e-49ca-462b-81e3-b4c342b031cb",
    "question_text_en": "What is the core principle behind few-shot learning in Large Language Models (LLMs)?",
    "question_text_ko": "2. 대규모 언어 모델(LLM)에서 퓨샷 학습의 핵심 원리는 무엇입니까?",
    "options_en": [
      "LLMs require massive amounts of labeled data to learn any task.",
      "LLMs can learn to perform tasks by observing only a few examples or demonstrations.",
      "LLMs can only generate text, not understand or classify it.",
      "LLMs are incapable of adapting to new tasks without extensive retraining."
    ],
    "options_ko": [
      "① LLM은 어떤 작업을 학습하기 위해 엄청난 양의 레이블이 지정된 데이터가 필요합니다.",
      "② LLM은 몇 가지 예시만 관찰해도 작업을 수행하는 방법을 배울 수 있습니다.",
      "③ LLM은 텍스트를 생성할 수만 있고 이해하거나 분류할 수는 없습니다.",
      "④ LLM은 광범위한 재교육 없이는 새로운 업무에 적용할 수 없습니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_1_e.png",
    "source_image_ko": "day9_1_H.png",
    "created_at": "2025-11-29T12:56:12.444117+00:00",
    "updated_at": "2025-11-29T12:56:12.444117+00:00"
  },
  {
    "id": "1fe9d3e9-ac9e-452c-8fd5-ef05bb5cb80e",
    "question_text_en": "How does instruction fine-tuning improve the performance of LLMs?",
    "question_text_ko": "3. 교육 세부 조정을 통해 LLM의 성과가 어떻게 향상됩니까?",
    "options_en": [
      "It increases the model's size and complexity",
      "It enables the model to understand and follow instructions more accurately.",
      "It makes the model more creative and capable of generating diverse outputs.",
      "It reduces the need for large-scale pre-training"
    ],
    "options_ko": [
      "① 모델의 크기와 복잡성이 증가합니다.",
      "② 이를 통해 모델의 지식을 더 정확하게 이해하고 따를 수 있습니다.",
      "③ 이를 통해 모델은 더욱 창의적이 되고 다양한 결과물을 생성할 수 있습니다.",
      "④ 대규모 사전 훈련의 필요성이 줄어듭니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_1_e.png",
    "source_image_ko": "day9_1_H.png",
    "created_at": "2025-11-29T12:56:12.476194+00:00",
    "updated_at": "2025-11-29T12:56:12.476194+00:00"
  },
  {
    "id": "10b1868f-282d-4555-a4ce-8e0bb6e42e29",
    "question_text_en": "What does cross-entropy loss measure in the context of LLMs?",
    "question_text_ko": "4. LLM 맥락에서 교차 엔트로피 손실은 무엇을 측정합니까?",
    "options_en": [
      "The difference between predicted and actual numerical values.",
      "The dissimilarity between the predicted probability distribution of words and the actual distribution in the training data",
      "The margin between correct and incorrect classifications.",
      "The distance between two probability distributions."
    ],
    "options_ko": [
      "① 예측된 수치와 실제 수치의 차이.",
      "② 예측된 단어의 확률 분포와 훈련 데이터에서의 실제 분포의 차이",
      "③ 올바른 분류와 잘못된 분류 사이의 차이.",
      "④ 두 확률 분포 사이의 거리."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_1_e.png",
    "source_image_ko": "day9_1_H.png",
    "created_at": "2025-11-29T12:56:12.510805+00:00",
    "updated_at": "2025-11-29T12:56:12.510805+00:00"
  },
  {
    "id": "e8849b55-e296-4c19-a4b6-7a7d971783a1",
    "question_text_en": "What is the primary goal of LLM alignment?",
    "question_text_ko": "LLM 정의의 주요 목표는 무엇입니까?",
    "options_en": [
      "Maximizing the accuracy of language models on benchmark datasets.",
      "Making sure LLMs generate the most creative and entertaining responses possible.",
      "Ensuring that the behavior and outputs of LLMs are in line with human values, preferences, and ethical principles",
      "Reducing the computational resources required to train LLMs."
    ],
    "options_ko": [
      "벤치마크 데이터 세트에서 얻어진 모델의 정확도를 극대화합니다.",
      "LLM이 가능한 한 가장 창의적이고 재미있는 답변을 낼 수 있도록 보장합니다.",
      "LLM 행동의 결과가 인간의 가치, 신뢰도 및 윤리 원칙에 부합하는지 확인합니다.",
      "LLM을 훈련하는 데 필요한 컴퓨팅 리소스를 줄입니다."
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_2_e.png",
    "source_image_ko": "day9_2_H.png",
    "created_at": "2025-11-29T12:56:12.55124+00:00",
    "updated_at": "2025-11-29T12:56:12.55124+00:00"
  },
  {
    "id": "90dd15f9-7ac5-4c94-83ca-cc949eb2aa5b",
    "question_text_en": "Which aspect of LLM output evaluation focuses on the grammatical correctness and natural flow of the generated text?",
    "question_text_ko": "LLM 결과를 평가할 어떤 측정이 생성된 텍스트의 문법적 정확성과 자연스러운 흐름에 초점을 맞춥니까?",
    "options_en": [
      "Accuracy",
      "Fluency",
      "Relevance",
      "Coherence"
    ],
    "options_ko": [
      "정확성",
      "유창성",
      "관련성",
      "통일"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_2_e.png",
    "source_image_ko": "day9_2_H.png",
    "created_at": "2025-11-29T12:56:12.590286+00:00",
    "updated_at": "2025-11-29T12:56:12.590286+00:00"
  },
  {
    "id": "1f6fedfc-87b7-45ac-9301-864e5c6e01bc",
    "question_text_en": "What is a primary expectation from learning the fundamentals of machine learning?",
    "question_text_ko": "",
    "options_en": [
      "Understanding different machine learning algorithms and their applications",
      "Writing low-level assembly code for GPUs",
      "Developing new operating systems for AI workloads",
      "Designing hardware components for deep learning models"
    ],
    "options_ko": [],
    "correct_answer": 0,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_eng.png",
    "source_image_ko": "",
    "created_at": "2025-11-29T12:56:13.118452+00:00",
    "updated_at": "2025-11-29T12:56:13.118452+00:00"
  },
  {
    "id": "d3fb719e-fc83-4842-80f1-091def5ad6e2",
    "question_text_en": "A lower perplexity score indicates:",
    "question_text_ko": "낮은 등차도 점수는 다음을 나타냅니다.",
    "options_en": [
      "The model is less confident in its predictions.",
      "The model is more likely to produce grammatically incorrect sentences.",
      "The model is better at predicting the next word in a sequence.",
      "The model is less suitable for language generation tasks."
    ],
    "options_ko": [
      "해당 모델은 예측에 대한 신뢰도가 낮습니다.",
      "이 모델은 문맥적으로 관련성 있는 문장을 생성할 가능성이 더 높습니다.",
      "이 모델은 시퀀스의 다음 단어를 예측하는 데 더 뛰어납니다.",
      "이 모델은 언어 생성 작업에 적합하지 않습니다."
    ],
    "correct_answer": 2,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_2_e.png",
    "source_image_ko": "day9_2_H.png",
    "created_at": "2025-11-29T12:56:12.629315+00:00",
    "updated_at": "2025-11-29T12:56:12.629315+00:00"
  },
  {
    "id": "4f39ffc0-54d1-4df7-8d69-3e78f929ed71",
    "question_text_en": "Why is human feedback crucial in identifying biases in LLM outputs?",
    "question_text_ko": "LLM 결과문의 함량을 파악하는 데 인간의 피드백이 왜 중요한가요?",
    "options_en": [
      "Humans are better at detecting subtle biases and nuances in language than automated systems.",
      "Humans can provide large amounts of labeled data for retraining LLMs.",
      "Humans are immune to biases and can therefore provide perfectly objective feedback.",
      "Human feedback is the only way to evaluate the performance of LLMs."
    ],
    "options_ko": [
      "언어를 자동화된 시스템보다 언어 속의 미묘한 편차와 차 nuance를 더 잘 감지합니다.",
      "인간은 LLM을 추적하여 학습의 레이블이 지정된 데이터피드백을 제공할 수 있습니다.",
      "인간은 환경에 맞게 있음으로 존엄함하면서 객관적인 피드백을 제공할 수 있습니다.",
      "LLM의 성과를 평가할 수 있는 유일한 방법은 인간의 피드백입니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_2_e.png",
    "source_image_ko": "day9_2_H.png",
    "created_at": "2025-11-29T12:56:12.661893+00:00",
    "updated_at": "2025-11-29T12:56:12.661893+00:00"
  },
  {
    "id": "74835406-4a22-4fee-81f8-ef30bb5163a5",
    "question_text_en": "GPUs possess dedicated high-bandwidth memory. What benefit does this provide during LLM training?",
    "question_text_ko": "GPU는 적은 그래픽 메모리를 가지고 있습니다. 이는 LLM 학습 중에 어떤 이점을 제공합니까?",
    "options_en": [
      "Enables faster data transfer between the CPU and GPU",
      "Allows for the storage of larger LLM models",
      "Reduces the overall power consumption of the system",
      "Facilitates quick access and processing of vast amounts of training data"
    ],
    "options_ko": [
      "CPU와 GPU 간의 더 빠른 데이터 전송을 가능하게 합니다.",
      "더 큰 LLM 모델을 저장할 수 있습니다.",
      "시스템의 전체 전력을 절감할 수 있습니다.",
      "대량의 입력 교육 데이터에 대한 빠른 검색 및 처리를 용이하게 합니다."
    ],
    "correct_answer": 3,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 9,
    "source_image_en": "day9_2_e.png",
    "source_image_ko": "day9_2_H.png",
    "created_at": "2025-11-29T12:56:12.696515+00:00",
    "updated_at": "2025-11-29T12:56:12.696515+00:00"
  },
  {
    "id": "2bb93614-134d-44fc-88f0-a57d42e88e54",
    "question_text_en": "What is the role of 'Data' in machine learning?",
    "question_text_ko": "머신러닝에서 '데이터'의 역할은 무엇인가요?",
    "options_en": [
      "It provides the examples and patterns the model learns from.",
      "It acts as the brain of the model.",
      "It determines the accuracy of the model.",
      "It has no significant role in machine learning."
    ],
    "options_ko": [
      "모델이 학습할 예제와 패턴을 제공합니다.",
      "이는 모델의 틀이나 역할을 합니다.",
      "이는 모델의 정체성을 결정합니다.",
      "머신러닝에서는 중요한 역할이 없습니다."
    ],
    "correct_answer": 0,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_2_e.png",
    "source_image_ko": "day_1_2_h.png",
    "created_at": "2025-11-29T12:56:12.733127+00:00",
    "updated_at": "2025-11-29T12:56:12.733127+00:00"
  },
  {
    "id": "49e683aa-d550-49f0-8332-e03e6d2a4b8c",
    "question_text_en": "In the context of predicting house sale prices, what is the role of the 'Algorithm'?",
    "question_text_ko": "주택 매매 가격을 예측하는 머신러닝에서 '출력값(목표)'의 역할은 무엇인가요?",
    "options_en": [
      "It represents the final predicted sale price of the house.",
      "It is the data used to train the model, such as square footage and number of bedrooms.",
      "It is the specific machine learning model (e.g., linear regression, decision tree) that learns the relationship between features like square footage and the sale price.",
      "It refers to the process of selecting and transforming features, such as creating a new feature that combines square footage and a number of bedrooms."
    ],
    "options_ko": [
      "이는 주택의 실제 매매 가격을 나타냅니다.",
      "모델을 훈련하는 데 사용되는 데이터로, 입력값 될 수 없이 있습니다.",
      "이는 현재의 판매 가격 및 동의 환경을 예측하는 특정 머신 러닝 모델(예: 선형 회귀, 의사결정 트리)입니다.",
      "이는 현재의 정보 수끌 결합된 새로운 특징을 만드는 것과 같이 특징을 선택하고 변형하는 과정을 말합니다."
    ],
    "correct_answer": 2,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_2_e.png",
    "source_image_ko": "day_1_2_h.png",
    "created_at": "2025-11-29T12:56:12.766663+00:00",
    "updated_at": "2025-11-29T12:56:12.766663+00:00"
  },
  {
    "id": "51483397-9051-4689-8513-e5314106399d",
    "question_text_en": "Which of the following utilizes artificial neural networks with multiple layers to learn complex patterns in data?",
    "question_text_ko": "다음 중 여러 층으로 구성된 인공 신경망을 활용하여 데이터의 복잡한 패턴을 학습하는 것은 무엇입니까?",
    "options_en": [
      "Deep Learning",
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics"
    ],
    "options_ko": [
      "딥러닝",
      "인공지능",
      "C-머신 러닝",
      "초보자 학습"
    ],
    "correct_answer": 0,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_2_e.png",
    "source_image_ko": "day_1_2_h.png",
    "created_at": "2025-11-29T12:56:12.803393+00:00",
    "updated_at": "2025-11-29T12:56:12.803393+00:00"
  },
  {
    "id": "f51f8b21-4b2d-4f51-8ee5-b1f2d21a4b84",
    "question_text_en": "In which type of machine learning does the algorithm learn from labeled data, where the correct output is provided for each input example?",
    "question_text_ko": "각 입력 데이터에 대해 올바른 출력이 레이블이 지정된 데이터에서 알고리즘이 학습하는 머신 러닝 유형은 무엇입니까?",
    "options_en": [
      "Unsupervised Learning",
      "Supervised Learning",
      "Reinforcement Learning",
      "Transfer Learning"
    ],
    "options_ko": [
      "비지도 학습",
      "지도 학습",
      "C-강화 학습",
      "전이 학습"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_2_e.png",
    "source_image_ko": "day_1_2_h.png",
    "created_at": "2025-11-29T12:56:12.852686+00:00",
    "updated_at": "2025-11-29T12:56:12.852686+00:00"
  },
  {
    "id": "0e0a53c5-e43f-46a5-987d-2a33006296e5",
    "question_text_en": "When selecting a machine learning model, what is a common trade-off that practitioners need to consider?",
    "question_text_ko": "머신 러닝 모델을 선택할 때 실무자가 고려해야 할 일반적인 균형점은 무엇인가요?",
    "options_en": [
      "Accuracy vs. Speed",
      "Complexity vs. Interpretability",
      "Data Size vs. Model Size",
      "Supervised vs. Unsupervised Learning"
    ],
    "options_ko": [
      "정확도 대 속도",
      "복잡성 대 해석 가능성",
      "C-데이터 필요량 대 모델 크기",
      "지도 학습 vs. 비지도 학습"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_2_e.png",
    "source_image_ko": "day_1_2_h.png",
    "created_at": "2025-11-29T12:56:12.885021+00:00",
    "updated_at": "2025-11-29T12:56:12.885021+00:00"
  },
  {
    "id": "5671ebc6-08ae-40e0-b61a-6e6b47a864b4",
    "question_text_en": "",
    "question_text_ko": "머신 러닝의 기본을 배우는 데 있어 가장 기대되는 것은 무엇입니까?",
    "options_en": [],
    "options_ko": [
      "다양한 머신 러닝 알고리즘과 그 응용 프로그램의 이해",
      "GPU와 최적화 연관성을 빠르게 적기",
      "새 워크로드를 위한 새로운 운영 체제 개발",
      "머신 러닝 모델을 위한 하드웨어 구성 요소 설계"
    ],
    "correct_answer": 0,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "",
    "source_image_ko": "day_1_han.png",
    "created_at": "2025-11-29T12:56:12.934956+00:00",
    "updated_at": "2025-11-29T12:56:12.934956+00:00"
  },
  {
    "id": "58d52634-18f5-44ab-935b-fe50df9f1efe",
    "question_text_en": "",
    "question_text_ko": "다음 중 AI, 머신러닝, 딥러닝의 관계를 가장 잘 설명하는 것은 무엇입니까?",
    "options_en": [],
    "options_ko": [
      "AI는 머신 러닝에 의해 완전히 구현된 기술입니다.",
      "머신 러닝은 AI의 하위 집합이고 딥 러닝은 머신 러닝의 하위 집합입니다.",
      "머신러닝과 딥러닝은 AI와 완전히 별개입니다.",
      "딥러닝은 AI와 머신러닝을 모두 포함하는 더 광범위한 개념입니다."
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "",
    "source_image_ko": "day_1_han.png",
    "created_at": "2025-11-29T12:56:12.975271+00:00",
    "updated_at": "2025-11-29T12:56:12.975271+00:00"
  },
  {
    "id": "16bd7dd3-accd-46c4-a80d-5859451657db",
    "question_text_en": "",
    "question_text_ko": "강화 학습은 에이전트가 환경과 상호 작용하고 보상이나 페널티를 받아 학습하는 것을 포함합니다. 참 또는 거짓을 나타냅니다.",
    "options_en": [],
    "options_ko": [
      "진실",
      "거짓"
    ],
    "correct_answer": 0,
    "category": "Reinforcement Learning",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "",
    "source_image_ko": "day_1_han.png",
    "created_at": "2025-11-29T12:56:13.014577+00:00",
    "updated_at": "2025-11-29T12:56:13.014577+00:00"
  },
  {
    "id": "76d6a929-ab52-46ad-b0de-a9a92a18e64f",
    "question_text_en": "Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?",
    "question_text_ko": "",
    "options_en": [
      "AI is a subset of Deep Learning, which is a subset of Machine Learning",
      "Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning",
      "Machine Learning and Deep Learning are completely separate from AI",
      "Deep Learning is a broader concept that includes both AI and Machine Learning"
    ],
    "options_ko": [],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_eng.png",
    "source_image_ko": "",
    "created_at": "2025-11-29T12:56:13.158228+00:00",
    "updated_at": "2025-11-29T12:56:13.158228+00:00"
  },
  {
    "id": "3fbea2dd-42dd-457a-b9bd-ebec5c43f2d5",
    "question_text_en": "Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False",
    "question_text_ko": "",
    "options_en": [
      "True",
      "False"
    ],
    "options_ko": [],
    "correct_answer": 0,
    "category": "Reinforcement Learning",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_eng.png",
    "source_image_ko": "",
    "created_at": "2025-11-29T12:56:13.192287+00:00",
    "updated_at": "2025-11-29T12:56:13.192287+00:00"
  },
  {
    "id": "ceb07ea9-567d-4e21-ac55-651e02158408",
    "question_text_en": "What is the primary purpose of feature scaling in machine learning?",
    "question_text_ko": "",
    "options_en": [
      "It improves the interpretability of categorical data",
      "It prevents certain features from dominating others due to different scales",
      "It removes duplicate rows from the dataset",
      "It eliminates the need for model validation"
    ],
    "options_ko": [],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_eng.png",
    "source_image_ko": "",
    "created_at": "2025-11-29T12:56:13.234043+00:00",
    "updated_at": "2025-11-29T12:56:13.234043+00:00"
  },
  {
    "id": "4e94f041-c130-4d9d-937d-c65416d618fa",
    "question_text_en": "What is the purpose of StandardScaler() in sklearn.preprocessing?",
    "question_text_ko": "",
    "options_en": [
      "It converts categorical variables into numerical values",
      "It normalizes features by scaling them between 0 and 1",
      "It standardizes features by removing the mean and scaling to unit variance",
      "It replaces missing values in a dataset"
    ],
    "options_ko": [],
    "correct_answer": 2,
    "category": "Preprocessing",
    "difficulty": "medium",
    "source_day": 0,
    "source_image_en": "day_1_eng.png",
    "source_image_ko": "",
    "created_at": "2025-11-29T12:56:13.271235+00:00",
    "updated_at": "2025-11-29T12:56:13.271235+00:00"
  },
  {
    "id": "d5a74307-cc14-4bcf-9e57-b7cb0e1c34d6",
    "question_text_en": "Which key feature of sequence models enables them to excel at natural language processing tasks like machine translation, where understanding the context of words in a sentence is crucial?",
    "question_text_ko": "시퀀스 모델의 어떤 주요 특징이 기계 번역과 같은 자연어 처리 작업에서 탁월한 성과를 낼 수 있게 해주는가? 이 작업에서 문장 속 단어의 맥락을 이해하는 것이 중요하다.",
    "options_en": [
      "Capture Dependencies",
      "Handle Variable Length",
      "Predict Future Values",
      "Generate New Sequences"
    ],
    "options_ko": [
      "중축성 편차",
      "가변 길이 처리",
      "미래 가치 예측",
      "새로운 시퀀스 생성"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_1_e.png",
    "source_image_ko": "day7_1_h.png",
    "created_at": "2025-11-29T13:09:49.285356+00:00",
    "updated_at": "2025-11-29T13:09:49.285356+00:00"
  },
  {
    "id": "360f36c7-c2dd-4d42-8019-9bdf0e323b5d",
    "question_text_en": "Which of the following architectures are designed to mitigate the vanishing gradient problem? (Choose 2 Correct Answers)",
    "question_text_ko": "다음 아키텍처 중 어느 것이 그래디언트 소실 문제를 완화하도록 설계되었습니까? (정답 2개 선택)",
    "options_en": [
      "Convolutional Neural Networks (CNNs)",
      "Long Short-Term Memory (LSTM) networks",
      "Gated Recurrent Units (GRUs)",
      "Generative Adversarial Networks (GANs)",
      "Multilayer Perceptrons (MLPs)"
    ],
    "options_ko": [
      "합성곱 신경망(CNN)",
      "장단기 메모리(LSTM) 네트워크",
      "게이트형 순환 회로(GRU)",
      "생성적 적대 신경망(GAN)",
      "다층 퍼셉트론(MLP)"
    ],
    "correct_answer": 1,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": 7,
    "source_image_en": "day7_1_e.png",
    "source_image_ko": "day7_1_h.png",
    "created_at": "2025-11-29T13:09:49.446458+00:00",
    "updated_at": "2025-11-29T13:09:49.446458+00:00"
  },
  {
    "id": "b4a48155-3ba4-4a48-a549-e658fc82eb0d",
    "question_text_en": "Which technique involves reducing the precision of model parameters to achieve a smaller model size and faster inference?",
    "question_text_ko": "어떤 기술이 모델 매개변수의 정밀도를 낮춰 더 작은 모델 크기와 더 빠른 추론을 달성하는 것일까요?",
    "options_en": [
      "Pruning",
      "Quantization",
      "Knowledge Distillation",
      "Transfer Learning"
    ],
    "options_ko": [
      "전정",
      "양자화",
      "지식 증류",
      "전이 학습"
    ],
    "correct_answer": 1,
    "category": "Model Optimization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.409752+00:00",
    "updated_at": "2025-11-29T14:15:26.409752+00:00"
  },
  {
    "id": "abcc5d9d-6845-40dd-88f3-c61adea5c9f4",
    "question_text_en": "How does ONNX act as an \"interoperability bridge\"?",
    "question_text_ko": "ONNX는 어떻게 '상호운용성 브리지' 역할을 하나요?",
    "options_en": [
      "It translates code between different programming languages used in machine learning.",
      "It enables seamless exchange and deployment of models across various frameworks and hardware platforms.",
      "It creates a standardized API for interacting with all machine learning models.",
      "It provides a cloud-based platform for storing and sharing machine learning models."
    ],
    "options_ko": [
      "머신 러닝에 사용되는 다양한 프로그래밍 언어 간의 코드를 번역합니다.",
      "다양한 프레임워크와 하드웨어 플랫폼에서 모델을 원활하게 교환하고 배포할 수 있습니다.",
      "모든 머신 러닝 모델과 상호작용하기 위한 표준화된 API를 만듭니다.",
      "머신 러닝 모델을 저장하고 공유하기 위한 클라우드 기반 플랫폼을 제공합니다."
    ],
    "correct_answer": 1,
    "category": "ONNX",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.48394+00:00",
    "updated_at": "2025-11-29T14:15:26.48394+00:00"
  },
  {
    "id": "7b11d081-a7be-4508-a3a5-e151b87ff6ba",
    "question_text_en": "What is the key benefit of using ONNX Runtime?",
    "question_text_ko": "ONNX 런타임을 사용하는 주요 이점은 무엇입니까?",
    "options_en": [
      "It simplifies the process of training machine learning models.",
      "It optimizes model execution for improved performance across diverse platforms.",
      "It automatically generates synthetic data for training models.",
      "It ensures that all models achieve the same level of accuracy."
    ],
    "options_ko": [
      "머신 러닝 모델을 실행하는 과정을 간소화합니다.",
      "다양한 플랫폼에서 성능을 향상시키기 위해 모델 실행을 최적화합니다.",
      "모델을 훈련하기 위한 합성 데이터를 자동으로 생성합니다.",
      "이를 통해 모든 모델이 동일한 수준의 정확도를 달성할 수 있습니다."
    ],
    "correct_answer": 1,
    "category": "ONNX",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.522152+00:00",
    "updated_at": "2025-11-29T14:15:26.522152+00:00"
  },
  {
    "id": "5f063b47-a610-4270-b35b-2787b7872db8",
    "question_text_en": "What is meant by \"model drift\" in the context of large language models (LLMs)?",
    "question_text_ko": "대규모 언어 모델(LLM)의 맥락에서 '모델 드리프트'란 무엇을 의미합니까?",
    "options_en": [
      "The model's ability to adapt to new language patterns over time.",
      "The gradual decrease in a model's accuracy and effectiveness due to changes in data distribution",
      "The tendency of a model to generate biased or harmful content",
      "The process of fine-tuning a pre-trained model on a specific task."
    ],
    "options_ko": [
      "시간이 지남에 따라 새로운 언어 패턴에 적응할 수 있는 모델의 능력.",
      "데이터의 분포가 변화로 인해 모델의 정확도와 효과성이 점차 감소하는 현상",
      "모델이 편향적이거나 유해한 콘텐츠를 생성하는 경향",
      "특정 작업에 맞춰 사전 학습된 모델을 미세 조정하는 과정입니다."
    ],
    "correct_answer": 1,
    "category": "Model Evaluation",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.571901+00:00",
    "updated_at": "2025-11-29T14:15:26.571901+00:00"
  },
  {
    "id": "627f495c-cd2a-43c1-855e-52e4f497c893",
    "question_text_en": "The F1 Score is calculated as the:",
    "question_text_ko": "F1 점수는 다음과 같이 계산됩니다.",
    "options_en": [
      "Arithmetic mean of precision and recall",
      "Harmonic mean of precision and recall",
      "Product of precision and recall",
      "Difference between precision and recall"
    ],
    "options_ko": [
      "정밀도와 재현율의 산술 평균",
      "정밀도와 재현율의 조화 평균",
      "정밀도와 재현율의 차이",
      "정밀도와 재현율의 곱"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.634795+00:00",
    "updated_at": "2025-11-29T14:15:26.634795+00:00"
  },
  {
    "id": "e28d94f6-94c0-4de3-8592-5a155a1a3ba1",
    "question_text_en": "What is the primary focus of NVIDIA AI Enterprise?",
    "question_text_ko": "NVIDIA AI Enterprise의 주요 초점은 무엇입니까?",
    "options_en": [
      "Developing cutting-edge hardware for AI research.",
      "Providing a comprehensive platform for the entire AI model lifecycle.",
      "Exclusively focusing on large language model (LLM) development.",
      "Creating open-source AI frameworks and libraries."
    ],
    "options_ko": [
      "AI 연구를 위한 최첨단 하드웨어 개발",
      "AI 모델 수명 주기 전반에 대한 포괄적인 플랫폼을 제공합니다.",
      "대규모 언어 모델(LLM) 개발에만 집중합니다.",
      "오픈소스 프레임워크와 라이브러리를 만듭니다."
    ],
    "correct_answer": 1,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.684574+00:00",
    "updated_at": "2025-11-29T14:15:26.684574+00:00"
  },
  {
    "id": "c1b7e684-1d46-460c-aa07-a7ab0c737824",
    "question_text_en": "Which of the following is a common deployment strategy for Large Language Models (LLMs)?",
    "question_text_ko": "다음 중 대규모 언어 모델(LLM)에 대한 일반적인 배포 전략은 무엇입니까?",
    "options_en": [
      "Deploying the model as a cloud-based API",
      "Running the model only on local machines without any networking",
      "Avoiding scaling considerations for inference",
      "Using only on-premises hardware with no updates"
    ],
    "options_ko": [
      "모델을 클라우드 기반 API로 배포",
      "네트워크 없이 로컬 머신에서 모델 실행",
      "추론을 위한 스케일링 고려 사항 피하기",
      "업데이트 없이 온프레미스 하드웨어만 사용"
    ],
    "correct_answer": 0,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.736458+00:00",
    "updated_at": "2025-11-29T14:15:26.736458+00:00"
  },
  {
    "id": "582ad001-bd9f-4a64-9b4f-f0c34d48b2ff",
    "question_text_en": "Which of the following is a common metric used to monitor LLMs in production?",
    "question_text_ko": "다음 중 프로덕션에서 LLM을 모니터링하는 데 사용되는 일반적인 지표는 무엇입니까?",
    "options_en": [
      "Number of training epochs",
      "Response latency",
      "Model parameter count",
      "Number of layers in the neural network"
    ],
    "options_ko": [
      "훈련 에포크 수",
      "응답 지연 시간",
      "모델 매개변수 개수",
      "신경망의 계층 수"
    ],
    "correct_answer": 1,
    "category": "Monitoring and Evaluation",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.796311+00:00",
    "updated_at": "2025-11-29T14:15:26.796311+00:00"
  },
  {
    "id": "101f569e-58e5-4fd7-9635-9938f582db8e",
    "question_text_en": "What is the primary benefit of using NVIDIA’s ecosystem for LLM deployment?",
    "question_text_ko": "LLM 배포에 NVIDIA의 생태계를 사용하는 주요 이점은 무엇입니까?",
    "options_en": [
      "Hardware-accelerated inference and training for high-efficiency",
      "Completely replacing deep learning frameworks like PyTorch and TensorFlow",
      "Eliminating the need for cloud-based deployments",
      "Avoiding AI model fine-tuning"
    ],
    "options_ko": [
      "고효율을 위한 하드웨어 가속을 통한 학습",
      "PyTorch나 TensorFlow와 같은 딥러닝 프레임워크를 완전히 대체",
      "클라우드 기반 배포의 필요성 제거",
      "AI 모델 미세 조정 방지"
    ],
    "correct_answer": 0,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.841036+00:00",
    "updated_at": "2025-11-29T14:15:26.841036+00:00"
  },
  {
    "id": "776a17a9-25d9-4b73-9983-1825e6c54e98",
    "question_text_en": "What is the primary purpose of prompt engineering?",
    "question_text_ko": "신속한 엔지니어링의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train an AI language model from scratch",
      "To unlock the full potential of an AI language model and get the best possible results",
      "To replace human writers with AI",
      "To limit the capabilities of an AI language model"
    ],
    "options_ko": [
      "AI 언어 모델을 처음부터 훈련하려면",
      "AI 언어 모델의 잠재력을 최대한 활용하여 최상의 결과를 얻으려면",
      "인간 작가를 새로 대체하기 위해",
      "AI 언어 모델의 기능을 제한하려면"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.879947+00:00",
    "updated_at": "2025-11-29T14:15:26.879947+00:00"
  },
  {
    "id": "75f94711-cbc4-4deb-8566-d2bcaf2749eb",
    "question_text_en": "What is prompt design in the context of AI language models?",
    "question_text_ko": "AI 언어 모델의 맥락에서 신속한 디자인이란 무엇인가?",
    "options_en": [
      "A random process of generating input for the model",
      "The art of crafting clear and specific instructions to guide the AI's output",
      "A complex coding language used to program AI models",
      "A method for limiting the AI's capabilities"
    ],
    "options_ko": [
      "모델에 대한 입력을 생성하는 무작위 프로세스",
      "AI의 출력을 안내하기 위한 명확하고 구체적인 지침을 작성하는 기술",
      "AI 모델을 프로그래밍하는 데 사용되는 복잡한 코딩 언어",
      "AI의 역할을 제한하는 방법"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.918494+00:00",
    "updated_at": "2025-11-29T14:15:26.918494+00:00"
  },
  {
    "id": "dc6b8296-0513-4d05-a946-1efe7d1ce2be",
    "question_text_en": "What is the primary purpose of providing context in prompts for AI language models?",
    "question_text_ko": "AI 언어 모델의 프롬프트에서 맥락을 제공하는 주된 목적은 무엇입니까?",
    "options_en": [
      "To confuse the AI and test its capabilities",
      "To guide the AI's understanding and steer its output in the desired direction",
      "To make the prompt longer and more complex",
      "To provide the AI with irrelevant information"
    ],
    "options_ko": [
      "AI를 훈련스럽게 하고 그 능력을 테스트하기 위해",
      "AI의 이해를 안내하고 원하는 방향으로 출력을 조정합니다.",
      "프롬프트를 더 길고 복잡하게 만들려면",
      "AI에게 관련 없는 정보를 제공하기 위해"
    ],
    "correct_answer": 1,
    "category": "Prompt Engineering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:26.961397+00:00",
    "updated_at": "2025-11-29T14:15:26.961397+00:00"
  },
  {
    "id": "69b257a0-8253-4a8e-b465-30f2b39f0784",
    "question_text_en": "What is the primary goal of PEFT in the context of large language models (LLMs)?",
    "question_text_ko": "대규모 언어 모델(LLM)의 맥락에서 PET의 주요 목표는 무엇입니까?",
    "options_en": [
      "To train a new LLM from scratch",
      "To efficiently adapt pre-trained LLMs to specific tasks",
      "To reduce the size of pre-trained LLMs",
      "To improve the general language understanding of LLMs"
    ],
    "options_ko": [
      "새로운 LLM을 처음부터 교육하려면",
      "사전 훈련된 LLM을 특정 작업에 효율적으로 적용하려면",
      "사전 훈련된 LLM의 크기를 줄이려면",
      "LLM의 일반적인 언어 이해력을 향상시키기 위해"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.000751+00:00",
    "updated_at": "2025-11-29T14:15:27.000751+00:00"
  },
  {
    "id": "662fea83-6a21-4693-8307-50cef0adc347",
    "question_text_en": "What is the primary focus of prompt learning in natural language processing?",
    "question_text_ko": "자연어 처리에서 신속한 학습의 주요 초점은 무엇입니까?",
    "options_en": [
      "Training language models from scratch on massive datasets",
      "Improving the general language understanding capabilities of language models",
      "Teaching language models to better understand and respond to instructions or prompts",
      "Reducing the size of pre-trained language models"
    ],
    "options_ko": [
      "대규모 데이터 세트를 기반으로 처음부터 언어 모델 학습",
      "언어 모델의 일반 언어 이해 능력 향상",
      "지나친 프로프트를 더 잘 이해하고 이에 대응하기 위한 언어 모델 교육",
      "사전 학습된 언어 모델의 크기 줄이기"
    ],
    "correct_answer": 2,
    "category": "Natural Language Processing",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.0605+00:00",
    "updated_at": "2025-11-29T14:15:27.0605+00:00"
  },
  {
    "id": "2cc41a61-b7bc-463a-898a-094b1706e856",
    "question_text_en": "What is the primary purpose of NVIDIA NeMo?",
    "question_text_ko": "NVIDIA NeMo의 주요 목적은 무엇입니까?",
    "options_en": [
      "To create realistic images and videos",
      "To simplify and accelerate the development and deployment of conversational AI models",
      "To analyze large datasets for business insights",
      "To translate text between different languages"
    ],
    "options_ko": [
      "사실적인 이미지와 비디오를 만들려면",
      "대화형 AI 모델의 개발 및 배포를 단순화하고 가속화하기 위해",
      "비즈니스 통찰력을 위해 대규모 데이터 세트를 분석하려면",
      "다양한 언어 간의 텍스트를 번역하려면"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.126551+00:00",
    "updated_at": "2025-11-29T14:15:27.126551+00:00"
  },
  {
    "id": "f917621b-ed0a-47bc-ba72-ff01cd0c8990",
    "question_text_en": "Why is it important to experiment with various prompts when working with AI language models?",
    "question_text_ko": "AI 언어 모델을 사용할 때 다양한 프롬프트를 실행하는 것이 왜 중요한가요?",
    "options_en": [
      "To keep the AI entertained and prevent boredom.",
      "To discover the most effective prompts for achieving desired outcomes.",
      "To trick the AI into revealing its hidden capabilities.",
      "To generate random and unpredictable responses."
    ],
    "options_ko": [
      "AI를 즐겁게 해주고 지루함을 방지하기 위해서입니다.",
      "원하는 결과를 얻기 위한 효과적인 프롬프트를 발견하세요.",
      "AI를 속여 숨겨진 능력을 드러내게 하는 것입니다.",
      "무작위적이고 예측할 수 없는 반응을 생성합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.168838+00:00",
    "updated_at": "2025-11-29T14:15:27.168838+00:00"
  },
  {
    "id": "23c36909-341c-44af-b227-2a6abf5996b1",
    "question_text_en": "What is the primary purpose of Retrieval Augmented Generation (RAG)?",
    "question_text_ko": "검색 증강 생성(RAG)의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train large language models (LLMs) from scratch",
      "To enhance the capabilities of LLMs by combining them with external knowledge sources",
      "To reduce the size of LLMs",
      "To replace human knowledge with AI"
    ],
    "options_ko": [
      "대규모 언어 모델(LLM)을 처음부터 훈련하려면",
      "외부 지식 소스와 결합하여 LLM의 역량을 강화합니다.",
      "LLM의 크기를 줄이려면",
      "인간의 지식을 AI로 대체하기 위해"
    ],
    "correct_answer": 1,
    "category": "Retrieval-Augmented Generation",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.213487+00:00",
    "updated_at": "2025-11-29T14:15:27.213487+00:00"
  },
  {
    "id": "a606b91f-3902-4096-87df-09eb2d10af31",
    "question_text_en": "Which type of database is commonly used in RAG for efficient document retrieval?",
    "question_text_ko": "RAG에서는 효율적인 문서 검색을 위해 일반적으로 어떤 유형의 데이터베이스를 사용합니까?",
    "options_en": [
      "Relational databases (SQL)",
      "Blockchain databases",
      "Flat file storage",
      "Vector databases"
    ],
    "options_ko": [
      "관계형 데이터베이스(SQL)",
      "블록체인 데이터베이스",
      "클라우드 파일 저장",
      "벡터 데이터베이스"
    ],
    "correct_answer": 3,
    "category": "Retrieval-Augmented Generation",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.253168+00:00",
    "updated_at": "2025-11-29T14:15:27.253168+00:00"
  },
  {
    "id": "f4167bf6-039b-4253-83ab-c7d98c0aa03d",
    "question_text_en": "Which of the following visualization techniques is best suited for displaying the frequency of different categories or items?",
    "question_text_ko": "다음 시각화 기술 중에서 다양한 범주나 항목의 빈도를 표시하는 데 가장 적합한 것은 무엇인가요?",
    "options_en": [
      "Heatmap",
      "Bar chart",
      "Scattertext",
      "Network graph"
    ],
    "options_ko": [
      "히트맵",
      "막대형 차트",
      "산점도",
      "네트워크 그래프"
    ],
    "correct_answer": 1,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.301455+00:00",
    "updated_at": "2025-11-29T14:15:27.301455+00:00"
  },
  {
    "id": "4d5b6979-04b4-423a-a956-58ff11c5c034",
    "question_text_en": "What is the primary goal of text data visualization?",
    "question_text_ko": "텍스트 데이터 시각화의 주요 목표는 무엇인가요?",
    "options_en": [
      "To make text data more aesthetically pleasing",
      "To transform unstructured text into visual representations for easier understanding and analysis",
      "To replace the need for reading and interpreting text",
      "To create complex and intricate visual displays"
    ],
    "options_ko": [
      "텍스트 데이터를 대용 미적으로 만들기 위해",
      "구조화되지 않은 텍스트를 시각적 표현으로 변환하여 더 쉽게 이해하고 분석할 수 있도록 합니다.",
      "텍스트를 읽고 해석할 필요성을 대체하기 위해",
      "복잡하고 정교한 시각적 디스플레이를 만들려면"
    ],
    "correct_answer": 1,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.344651+00:00",
    "updated_at": "2025-11-29T14:15:27.344651+00:00"
  },
  {
    "id": "c8d807ec-1ca7-4e52-b225-4244ea7dfef8",
    "question_text_en": "Word clouds are particularly effective for:",
    "question_text_ko": "워드 클라우드는 다음과 같은 경우에 특히 효과적입니다.",
    "options_en": [
      "Showing the exact frequency of each word in a text",
      "Displaying the relationships between different words or concepts",
      "Highlighting the most prominent or frequent words in a text",
      "Visualizing the sentiment or emotional tone of a text"
    ],
    "options_ko": [
      "텍스트에서 각 단어의 정확한 빈도 표시",
      "다양한 단어나 개념 간의 관계 표시",
      "텍스트에서 가장 눈에 띄거나 자주 등장하는 단어 강조하기",
      "텍스트의 감정이나 감정적 톤을 시각화합니다."
    ],
    "correct_answer": 2,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.390384+00:00",
    "updated_at": "2025-11-29T14:15:27.390384+00:00"
  },
  {
    "id": "f332fc2c-c8cd-467b-92c9-cd0d5bfda3f6",
    "question_text_en": "Which visualization technique is best suited for revealing relationships between two numerical variables?",
    "question_text_ko": "두 수치 변수 간의 관계를 밝히는 데 가장 적합한 시각화 기술은 무엇인가요?",
    "options_en": [
      "Bar chart",
      "Pie chart",
      "Scatter plot",
      "Heatmap"
    ],
    "options_ko": [
      "막대형 차트",
      "파이 차트",
      "산점도",
      "히트맵"
    ],
    "correct_answer": 2,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.43176+00:00",
    "updated_at": "2025-11-29T14:15:27.43176+00:00"
  },
  {
    "id": "42da0f1c-3b3f-40ed-a3e4-0b9b0cf82f39",
    "question_text_en": "Line charts are commonly used to:",
    "question_text_ko": "선형 차트는 일반적으로 다음과 같은 경우에 사용됩니다.",
    "options_en": [
      "Show trends or changes in data over time",
      "Compare the frequencies of different categories",
      "Display the distribution of values across two dimensions",
      "Visualize the hierarchical structure of data"
    ],
    "options_ko": [
      "시간 경과에 따라 데이터의 증분 또는 변화를 표시",
      "다양한 카테고리의 범주를 비교하려고 함",
      "두 숫자의 절대 값 비교 표시",
      "데이터의 계층 구조를 시각화합니다"
    ],
    "correct_answer": 0,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.470838+00:00",
    "updated_at": "2025-11-29T14:15:27.470838+00:00"
  },
  {
    "id": "c1bae435-4621-49a9-bf0b-3c0f53ec40bb",
    "question_text_en": "What is the primary purpose of CuDF in the context of data analysis?",
    "question_text_ko": "데이터 분석 영역에서 CuDF의 주요 목적은 무엇입니까?",
    "options_en": [
      "To visualize large datasets",
      "To provide a GPU-accelerated DataFrame library for data manipulation and analysis",
      "To build machine learning models",
      "To manage database connections"
    ],
    "options_ko": [
      "대규모 데이터 세트를 시각화하려면",
      "데이터 조작 및 처리을 위한 GPU 가속 DataFrame 라이브러리 제공",
      "머신 러닝 모델을 교육하려면",
      "데이터베이스 연결을 관리하려면"
    ],
    "correct_answer": 1,
    "category": "Data Analysis Tools",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.5088+00:00",
    "updated_at": "2025-11-29T14:15:27.5088+00:00"
  },
  {
    "id": "658c42a1-a985-4fe1-bb26-eda335195520",
    "question_text_en": "Which type of plot is ideal for showing correlations between two continuous variables?",
    "question_text_ko": "두 연속 변수 간의 상관관계를 보여주는 데 가장 적합한 차트 유형은 무엇입니까?",
    "options_en": [
      "Scatter Plot",
      "Pie Chart",
      "Bar Chart",
      "Box Plot"
    ],
    "options_ko": [
      "산점도",
      "바이올린 차트",
      "매트릭스 차트",
      "상자 그림"
    ],
    "correct_answer": 0,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.546175+00:00",
    "updated_at": "2025-11-29T14:15:27.546175+00:00"
  },
  {
    "id": "d78d685c-598c-4ff6-a410-85901741d52e",
    "question_text_en": "Which of the following tasks can be accelerated using Dask-cuDF?",
    "question_text_ko": "다음 중 Dask-cuDF를 사용하여 가능하게 할 수 있는 작업은 무엇입니까?",
    "options_en": [
      "Creating deep learning models",
      "Running web applications",
      "Distributed DataFrame operations across multiple GPUs",
      "Building NoSQL databases"
    ],
    "options_ko": [
      "데이터 프레임 생성",
      "연 애플리케이션의 실행",
      "여러 GPU에 걸친 분산 DataFrame 작업",
      "NoSQL 데이터베이스 구성"
    ],
    "correct_answer": 2,
    "category": "Data Analysis Tools",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.584046+00:00",
    "updated_at": "2025-11-29T14:15:27.584046+00:00"
  },
  {
    "id": "9291d9ce-891b-4757-833e-c11ca34f93a2",
    "question_text_en": "Which visualization method is most effective for analyzing the distribution of text lengths in a dataset?",
    "question_text_ko": "데이터 세트에서 텍스트의 깊이 분류를 분석하는 데 가장 효과적인 시간절약 방법은 무엇입니까?",
    "options_en": [
      "Line Chart",
      "Heatmap",
      "Box Plot",
      "Histogram"
    ],
    "options_ko": [
      "선형 서치",
      "히프를 사용",
      "상자 스키밍",
      "워크스루 활용"
    ],
    "correct_answer": 3,
    "category": "Data Visualization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.626946+00:00",
    "updated_at": "2025-11-29T14:15:27.626946+00:00"
  },
  {
    "id": "3491789f-cae5-4abf-b35b-bec489855ba9",
    "question_text_en": "How do LLMs learn to generate human-like text?",
    "question_text_ko": "1. LLM은 어떻게 인간과 유사한 텍스트를 생성하는 방법을 택하나요?",
    "options_en": [
      "By interacting with human users in real-time conversations",
      "By leveraging massive datasets and algorithms to learn patterns in language",
      "By being explicitly programmed with grammar and vocabulary rules",
      "By observing human behavior in various settings"
    ],
    "options_ko": [
      "실시간 대화에서 인간 사용자와 상호 작용하여",
      "대규모 데이터 세트와 알고리즘을 활용하여 언어 패턴을 학습합니다.",
      "완벽한 이해 구체의 인식적으로 프로그래밍되어 있음",
      "다양한 환경에서 인간의 행동을 관찰함으로써"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.668043+00:00",
    "updated_at": "2025-11-29T14:15:27.668043+00:00"
  },
  {
    "id": "ab2a9a50-8620-44f9-a567-1c04f909de73",
    "question_text_en": "What is a key concern when developing and deploying large language models (LLMs)?",
    "question_text_ko": "2. 대규모 언어 모델(LLM)을 개발할 때 목표할 때 가장 중요한 고려 사항은 무엇인가요?",
    "options_en": [
      "Ensuring they can generate creative and entertaining text.",
      "Minimizing their computational requirements.",
      "Identifying and mitigating potential biases in their output.",
      "Maximizing their ability to generate code."
    ],
    "options_ko": [
      "창의적이고 재미있는 텍스트를 생성할 수 있도록 보장합니다.",
      "개선 요구 사항을 최소화합니다.",
      "훈습하면서 정확한 문법과 철자를 완성합니다.",
      "모델 생성 비용을 극대화합니다."
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.718176+00:00",
    "updated_at": "2025-11-29T14:15:27.718176+00:00"
  },
  {
    "id": "d91a2251-7466-4680-9ee5-7a9c483b5fde",
    "question_text_en": "Which hyperparameter tuning method systematically explores all possible combinations from a predefined set of values?",
    "question_text_ko": "3. 여러 정렬의 각 집합에 모든 가능한 조합을 체계적으로 탐색하는 하이퍼파라미터 튜닝 방법은 무엇인가요?",
    "options_en": [
      "Grid Search",
      "Random Search",
      "Bayesian Optimization",
      "Genetic Algorithms"
    ],
    "options_ko": [
      "그리드 검색",
      "무작위 검색",
      "베이지안 최적화",
      "유전 알고리즘"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.764275+00:00",
    "updated_at": "2025-11-29T14:15:27.764275+00:00"
  },
  {
    "id": "e77b014f-d98f-4d67-8748-3947eaae9397",
    "question_text_en": "What are hyperparameters in the context of large language models (LLMs)?",
    "question_text_ko": "4. 대규모 언어 모델(LLM)에서 일반적인 하이퍼파라미터는 무엇인가요?",
    "options_en": [
      "The words and phrases used to train the model.",
      "The internal settings that govern the model's architecture, learning rate, batch size, etc.",
      "The output generated by the model in response to a prompt.",
      "The evaluation metrics used to assess the model's performance."
    ],
    "options_ko": [
      "모델을 운영하는 핵심적인 하드웨어 구문입니다.",
      "모델의 아키텍처, 학습률, 배치 크기 등을 결정하는 내부 설정입니다.",
      "프로젝트에 대한 향후 모델의 성장을 측정합니다.",
      "모델의 성능을 평가하는 데 사용되는 평가 지표입니다."
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.817893+00:00",
    "updated_at": "2025-11-29T14:15:27.817893+00:00"
  },
  {
    "id": "9de6166d-5bb3-4a0e-aec0-875be5c979e7",
    "question_text_en": "What is the primary purpose of A/B testing in the context of LLMs?",
    "question_text_ko": "1. LLM에서 A/B 테스트의 주요 목적은 무엇입니까?",
    "options_en": [
      "To randomly deploy different LLM versions without any evaluation.",
      "To systematically evaluate different versions of LLMs and their impact on user experience and key metrics",
      "To compare the performance of LLMs against traditional rule-based systems",
      "To measure the computational efficiency of different LLM architectures"
    ],
    "options_ko": [
      "평가 없이 다양한 LLM 버전을 무작위로 배포합니다.",
      "실험을 진행하여 변경된 사양과 특정 목표 지표에 미치는 영향을 체계적으로 평가합니다.",
      "LLM의 성능을 기존 규제 시스템과 비교하면서",
      "다양한 LLM 아키텍처의 계산 효율성을 측정하면서"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.861776+00:00",
    "updated_at": "2025-11-29T14:15:27.861776+00:00"
  },
  {
    "id": "c99045f3-56a7-459c-a11c-88d8fcb6353f",
    "question_text_en": "What is the primary benefit of using a Version Control System (VCS) in LLM development regarding reproducibility?",
    "question_text_ko": "2. 재현성과 관련하여 LLM 개발에서 버전 제어 시스템(VCS)을 사용하는 주요 이유는 무엇입니까?",
    "options_en": [
      "It automatically improves the model’s accuracy.",
      "It prevents any changes from being made to the code or data.",
      "It allows for easy tracking of changes, enabling reversion to previous versions and replication of experiments.",
      "It generates new versions of the model automatically."
    ],
    "options_ko": [
      "모델의 정확도가 자동으로 향상됩니다.",
      "코드나 데이터가 전환되는 것을 방지합니다.",
      "모델 개발 과정을 사양과 다른 버전으로 되돌리고 실험을 재현할 수 있습니다.",
      "모델의 새로운 버전을 자동으로 생성합니다."
    ],
    "correct_answer": 2,
    "category": "Development Practices",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.904722+00:00",
    "updated_at": "2025-11-29T14:15:27.904722+00:00"
  },
  {
    "id": "75ec94fa-6775-4f85-9d1c-804c488b3d64",
    "question_text_en": "Why is version control important for large language model (LLM) projects?",
    "question_text_ko": "3. 대규모 언어 모델(LLM) 프로젝트에 버전 제어가 중요한 이유는 무엇입니까?",
    "options_en": [
      "It allows for faster training of LLMs by optimizing computational resources.",
      "It enables reproducibility, collaboration, and efficient management of LLM projects.",
      "It prevents LLMs from making errors during text generation.",
      "It automates hyperparameter tuning for better model performance."
    ],
    "options_ko": [
      "이를 통해 개인 리소스를 최적화하여 LLM의 학습 속도를 높일 수 있습니다.",
      "LLM 프로젝트의 개선과, 협업 및 효율적인 관리가 가능합니다.",
      "이를 통해 LLM의 레벨과 성능 등에 오류를 찾는 과정을 실행할 수 있습니다.",
      "더 나은 모델 성능을 위해 하이퍼파라미터 튜닝을 재정립합니다."
    ],
    "correct_answer": 1,
    "category": "Development Practices",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.951001+00:00",
    "updated_at": "2025-11-29T14:15:27.951001+00:00"
  },
  {
    "id": "da8a1494-c466-443e-9390-f2f584592730",
    "question_text_en": "Why is the BioNeMo LLM service particularly suitable for the biomedical and pharmaceutical industries?",
    "question_text_ko": "4. BioNeMo LLM 서비스가 생물의학 및 헬스 산업에 특히 적합한 이유는 무엇입니까?",
    "options_en": [
      "Because it generates medical content based on general language models",
      "Because it is pre-trained on massive biomedical datasets and allows customization for specific tasks",
      "Because it replaces the need for human expertise in healthcare decision-making",
      "Because it primarily focuses on real-time conversations with healthcare professionals"
    ],
    "options_ko": [
      "평가 없이 모델을 기반으로 의료 컨텐츠를 생성하기 때문이며",
      "대규모 의료 데이터세트에 대한 사전 학습 없이도 특정 질병에 대한 사용자의 정의가 가능하기 때문입니다.",
      "이는 의료 원격진료에 있어 인간의 질병 예측이 좀 더 용이 하기 때문입니다.",
      "주요 의료 과정에서의 실시간 데이터의 흐름을 유지기 때문입니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:27.996281+00:00",
    "updated_at": "2025-11-29T14:15:27.996281+00:00"
  },
  {
    "id": "b76d16d9-425a-40a6-bb9a-f98d83571bd0",
    "question_text_en": "How do NVIDIA AI Agents perceive and interact with their environment?",
    "question_text_ko": "5. NVIDIA AI 엔터프라이즈 솔루션은 이렇게 변환된 인식을 어떻게 향상하고 신속 적용합니까?",
    "options_en": [
      "By following pre-programmed scripts for user interactions",
      "By processing visual and auditory inputs using computer vision and natural language models",
      "By only responding to text-based user commands",
      "By relying solely on predefined responses without real-time reasoning"
    ],
    "options_ko": [
      "사용자 속성을 위한 새로운 사전 프로그램과의 스크립트를 만들고",
      "현재의 비전과 작업의 다양한 사용이 시각적 및 관심적 인식을 제공함으로써",
      "텍스트로부터 사용자의 정밀한 단평을 모으고",
      "실시간 추천 없이 미리 정의된 응답만을 일관함으로써"
    ],
    "correct_answer": 1,
    "category": "AI Agents",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.033846+00:00",
    "updated_at": "2025-11-29T14:15:28.033846+00:00"
  },
  {
    "id": "8091345b-a016-4c3b-8b83-bf1ea9cae007",
    "question_text_en": "What is the primary purpose of Kernel Auto-Tuning?",
    "question_text_ko": "커널 자동 튜닝의 주요 목적은 무엇입니까?",
    "options_en": [
      "To minimize memory usage during model execution",
      "To enable parallel processing of multiple input streams",
      "To select the most efficient kernels for a given GPU architecture",
      "To optimize models for mixed-precision computation"
    ],
    "options_ko": [
      "같은 성능 중 메모리 사용을 최소화하려면",
      "여러 알고리즘의 병렬 처리를 활성화하려면",
      "주어진 GPU 아키텍처에 가장 적절한 커널을 선택하려면",
      "초밥 정도 계산을 위한 모델 최적화"
    ],
    "correct_answer": 2,
    "category": "Model Optimization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.073288+00:00",
    "updated_at": "2025-11-29T14:15:28.073288+00:00"
  },
  {
    "id": "94d9d525-ed43-4225-9b86-e7c91da3e029",
    "question_text_en": "What is the primary focus of the NVIDIA BioNeMo LLM Service?",
    "question_text_ko": "NVIDIA BioNeMo LLM 서비스의 주요 초점은 무엇입니까?",
    "options_en": [
      "General-purpose language tasks",
      "Financial analysis and predictions",
      "Biomedical and pharmaceutical applications",
      "Image and video processing"
    ],
    "options_ko": [
      "일반 언어 작업",
      "재무 분석 및 예측",
      "생물학적 및 화학 응용 분야",
      "이미지 및 비디오 처리"
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.115039+00:00",
    "updated_at": "2025-11-29T14:15:28.115039+00:00"
  },
  {
    "id": "d1a88762-5f59-4e36-ae1f-766104d94591",
    "question_text_en": "Which of the following capabilities falls under the “Perception” aspect of NVIDIA AI Agents?",
    "question_text_ko": "다음 기능 중 NVIDIA AI Agents의 “지각” 측면에 속하는 것은 무엇입니까?",
    "options_en": [
      "Generating creative text responses",
      "Processing visual and auditory input to understand the environment",
      "Making complex decisions based on internal knowledge",
      "Planning a sequence of actions to achieve a goal"
    ],
    "options_ko": [
      "정확한 테스트 로봇 생성",
      "주변 환경을 이해하기 위해 시각적, 청각적 입력을 처리합니다.",
      "내부 자신이 기계적 발전과 심화 연결",
      "목표를 중심하기 위한 일반의 행동 계획"
    ],
    "correct_answer": 1,
    "category": "AI Agents",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.162059+00:00",
    "updated_at": "2025-11-29T14:15:28.162059+00:00"
  },
  {
    "id": "ded61079-1079-46cc-a7ab-e90c6e629029",
    "question_text_en": "What is the core idea behind the Mixture of Experts (MoE) architectural paradigm?",
    "question_text_ko": "전문가 혼합(MoE) 모델 패러다임의 핵심 아이디어는 무엇입니까?",
    "options_en": [
      "Training multiple smaller models and combining their outputs.",
      "Dividing the model into multiple specialized experts, each focusing on a specific task or domain",
      "Reducing the size of the model by removing unnecessary parameters",
      "Fine-tuning the model on a large dataset of diverse tasks"
    ],
    "options_ko": [
      "여러 개의 작은 모델을 훈련하고 각각의 출력을 결합합니다.",
      "모델을 특정 작업이나 도메인에 연공하는 여러 전문가를 분할",
      "집중적으로 예방처리를 피하면서 모델 크기 줄이기",
      "다양한 작업의 대규모 데이터셋에 대한 모델 미세 조정"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.200185+00:00",
    "updated_at": "2025-11-29T14:15:28.200185+00:00"
  },
  {
    "id": "ac98b6d6-7c7a-42eb-8229-95279cc2f10f",
    "question_text_en": "What is the primary purpose of NVIDIA Triton Inference Server?",
    "question_text_ko": "1. NVIDIA Triton 추론 서버의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train large language models (LLMs) from scratch.",
      "To simplify the deployment of AI models at scale in production.",
      "To collect and preprocess data for model training.",
      "To design and optimize model architectures."
    ],
    "options_ko": [
      "연구실 없이 딥러닝을 처음부터 훈련합니다.",
      "생산 환경에서 AI 모델을 대규모로 배포하는 기본 구조합니다.",
      "모델 학습을 위해 데이터를 수집하고 정제합니다.",
      "모델 연구개발을 수행하기 최적화합니다."
    ],
    "correct_answer": 1,
    "category": "Model Deployment",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.240452+00:00",
    "updated_at": "2025-11-29T14:15:28.240452+00:00"
  },
  {
    "id": "aff1299b-ee34-4ce7-8a7a-40e165c1cd9e",
    "question_text_en": "What is the main purpose of NVIDIA AI Workflows?",
    "question_text_ko": "2. NVIDIA AI 솔루션의 주요 목적은 무엇입니까?",
    "options_en": [
      "To provide a marketplace for buying and selling AI models.",
      "To focus solely on data collection and preprocessing.",
      "To streamline and accelerate the entire AI development process.",
      "To automate the deployment of AI models in production."
    ],
    "options_ko": [
      "AI 모델을 할당할 수 있는 시장을 제공합니다.",
      "데이터 신뢰성 강화를 보장합니다.",
      "AI 개발 프로세스 전반의 효율성을 가속화합니다.",
      "프로덕션에서 모델의 빠른 작업을 지원합니다."
    ],
    "correct_answer": 2,
    "category": "AI Development",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.280363+00:00",
    "updated_at": "2025-11-29T14:15:28.280363+00:00"
  },
  {
    "id": "ca46664a-06e1-4d0f-886c-d3cb19598cda",
    "question_text_en": "What is NVIDIA cuOpt?",
    "question_text_ko": "3. NVIDIA cuOpt란 무엇입니까?",
    "options_en": [
      "A cloud-based platform for managing logistics operations",
      "A GPU-accelerated optimization library",
      "A deep learning framework for image recognition",
      "A programming language for developing logistics software"
    ],
    "options_ko": [
      "유류 운영 문제를 위한 솔루션의 기본 플랫폼",
      "GPU 가속 최적화 라이브러리",
      "이미지 인식을 위한 고급 라이브러리",
      "효율적 프로그램 개발을 위한 프로그래밍 언어"
    ],
    "correct_answer": 1,
    "category": "Optimization",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.318546+00:00",
    "updated_at": "2025-11-29T14:15:28.318546+00:00"
  },
  {
    "id": "c10d0a5f-008d-45ff-9624-3efbe0a06c6a",
    "question_text_en": "What is the primary purpose of NVIDIA RIVA?",
    "question_text_ko": "4. NVIDIA Riva의 주요 목적은 무엇입니까?",
    "options_en": [
      "To generate realistic images",
      "To enable developers to build and deploy real-time, highly accurate conversational AI applications",
      "To analyze large datasets for business insights",
      "To translate text between different languages"
    ],
    "options_ko": [
      "사전과 이미지 생성하기",
      "개발자가 실시간으로 음성 인식이 높은 대화형 AI 애플리케이션을 구축하고 배포할 수 있도록 지원",
      "비디오나 음성으로부터 대규모 데이터 세트를 분석하고 해석",
      "다양한 언어 간에 텍스트를 변환하기"
    ],
    "correct_answer": 1,
    "category": "Conversational AI",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.356854+00:00",
    "updated_at": "2025-11-29T14:15:28.356854+00:00"
  },
  {
    "id": "5d7acb9d-a87f-4e0c-85b6-a94c3e8b532c",
    "question_text_en": "What is NVIDIA Merlin?",
    "question_text_ko": "5. NVIDIA Merlin이란 무엇입니까?",
    "options_en": [
      "A cloud-based platform for managing customer relationships",
      "A deep learning framework for image recognition",
      "An open-source framework for building and deploying recommender systems",
      "A programming language for developing e-commerce websites"
    ],
    "options_ko": [
      "고객 관계 관리를 위한 솔루션의 기본 플랫폼",
      "이미지 인식을 위한 라이브러리입니다",
      "추천 시스템 구성 및 배포를 위한 오픈 소스 프레임워크",
      "정보처리 형식에서 제품을 위한 프로그래밍 언어"
    ],
    "correct_answer": 2,
    "category": "Recommender Systems",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.393151+00:00",
    "updated_at": "2025-11-29T14:15:28.393151+00:00"
  },
  {
    "id": "90c47d20-eb01-4a7a-ba54-6ad0b6c0274b",
    "question_text_en": "The concept of Explainable AI (XAI) is most closely associated with which pillar of responsible AI?",
    "question_text_ko": "설명 가능한 AI(XAI) 개념은 책임 있는 AI의 기둥 중 가장 밀접하게 연관되어 있습니까?",
    "options_en": [
      "Fairness",
      "Transparency & Explainability",
      "Accountability",
      "Privacy"
    ],
    "options_ko": [
      "공정성",
      "투명성 및 설명 가능성",
      "책임",
      "존중"
    ],
    "correct_answer": 1,
    "category": "Explainable AI",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.435366+00:00",
    "updated_at": "2025-11-29T14:15:28.435366+00:00"
  },
  {
    "id": "2ce636e2-1539-42e2-bbe4-b034a9879b00",
    "question_text_en": "What is data consent in the context of AI and data handling?",
    "question_text_ko": "AI와 데이터 처리의 맥락에서 데이터 주권은 무엇입니까?",
    "options_en": [
      "Implicit agreement assumed from users when they use a service.",
      "Explicit permission from individuals to collect, use, and share their data.",
      "The right of companies to use data without informing users.",
      "The process of obtaining data from public sources."
    ],
    "options_ko": [
      "사용자가 서비스를 사용할 때 명목적으로 동일답다고 가정합니다.",
      "개인이 자신의 데이터를 수집, 사용, 공유하도록 의식적으로 허가합니다.",
      "사용자가 명시적 강요만으로 데이터를 사용할 수 있는 개인의 권리.",
      "공공 소스에서 데이터를 얻는 과정."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.472373+00:00",
    "updated_at": "2025-11-29T14:15:28.472373+00:00"
  },
  {
    "id": "3b638a49-ef0c-4538-b0d9-5b93bb8a3450",
    "question_text_en": "What is the primary purpose of Nvidia’s NeMo Guardrails toolkit?",
    "question_text_ko": "Nvidia의 NeMo Guardrails를 통한 주요 목적은 무엇입니까?",
    "options_en": [
      "To accelerate the training of large language models",
      "To build safer and more controlled conversational AI models",
      "To improve the accuracy of image recognition models",
      "To optimize the performance of deep learning algorithms"
    ],
    "options_ko": [
      "대규모 언어 모델의 학습을 가속화설명력",
      "더욱 안전하고 통제 가능한 대화형 AI 모델을 구축하려면",
      "이미지 인식 모델의 정확도를 향상시키기 위해",
      "일반적 알고리즘의 성능을 최적화하려면"
    ],
    "correct_answer": 1,
    "category": "AI Safety",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.52793+00:00",
    "updated_at": "2025-11-29T14:15:28.52793+00:00"
  },
  {
    "id": "8b287691-67c4-4411-806f-1c150f271689",
    "question_text_en": "What is the main goal of using the Omniverse Replicator in the context of AI fairness?",
    "question_text_ko": "AI 공정성 전략에서 Omniverse Replicator를 사용하는 주요 목표는 무엇입니까?",
    "options_en": [
      "To improve the accuracy of AI models on benchmark datasets.",
      "To generate synthetic data that enhances diversity and representation in training datasets",
      "To create explainable AI models",
      "To establish governance structures for AI development"
    ],
    "options_ko": [
      "복잡한 데이터 세트에서 AI 모델의 명확도를 개선합니다.",
      "훈련 데이터 세트의 다양성과 편견을 정량하는 합성 데이터를 생성합니다.",
      "설명 가능한 AI 모델을 연구하다",
      "AI 개발을 위한 가상현실 구조 구축"
    ],
    "correct_answer": 1,
    "category": "AI Fairness",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.583557+00:00",
    "updated_at": "2025-11-29T14:15:28.583557+00:00"
  },
  {
    "id": "8c249468-8b5a-4cba-b323-a8b9361b46ad",
    "question_text_en": "Which of the following statements is true about agglomerative clustering?",
    "question_text_ko": "다음 중 응집적 클러스터링에 관해 사실인 진술은 무엇입니까?",
    "options_en": [
      "It's a top-down approach",
      "It starts with each data point as its own cluster",
      "It's computationally less expensive than divisive clustering for large datasets",
      "It doesn't require a distance metric"
    ],
    "options_ko": [
      "그것은 상향식 접근 방식입니다",
      "각 데이터 포인트로 자체 클러스터로 시작됩니다.",
      "대규모 데이터 세트의 경우 분할 클러스터링보다 계산 비용이 저렴합니다.",
      "거리 측정이 필요하지 않습니다."
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.543929+00:00",
    "updated_at": "2025-11-29T14:15:29.543929+00:00"
  },
  {
    "id": "fa0bc219-e5f4-4d8f-8596-22fcf8c30dcb",
    "question_text_en": "What is the primary goal of Trustworthy AI in NVIDIA's generative AI and LLMs?",
    "question_text_ko": "1. NVIDIA의 생성 AI와 LLM에서 신뢰할 수 있는 AI의 주요 목표는 무엇입니까?",
    "options_en": [
      "A: To enhance AI performance without considering ethical implications",
      "B: To ensure AI systems are reliable, safe, fair, transparent, and accountable",
      "C: To make AI systems self-learning and fully autonomous",
      "D: To prioritize AI accuracy over ethical considerations"
    ],
    "options_ko": [
      "A. 문제의 모바일 경험에서 인지 성능 향상을시키고 있습니다.",
      "B. AI 시스템이 윤리적이고 안정적인 결정으로부터 책임이 있는지 확인하기 위해",
      "C. AI 시스템을 자체 학습하여 문제 해결하기 위해",
      "D. 문제의 고급사용자만의 사용자 정의를 우선시합니다."
    ],
    "correct_answer": 1,
    "category": "AI Ethics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.635841+00:00",
    "updated_at": "2025-11-29T14:15:28.635841+00:00"
  },
  {
    "id": "aaadff72-0f39-48bb-bf5d-56179d454df0",
    "question_text_en": "Why is data privacy crucial in artificial intelligence and large language model (LLM) development?",
    "question_text_ko": "2. 인공지능과 대규모 언어 모델(LLM) 개발에 있어서 데이터 개인정보 보호가 왜 중요한가요?",
    "options_en": [
      "A: Because it ensures AI models can collect unlimited data for better performance",
      "B: Because it builds trust, mitigates risks, ensures fairness, and complies with regulations",
      "C: Because AI models require personal data to function effectively",
      "D: Because it allows AI developers to bypass regulatory requirements"
    ],
    "options_ko": [
      "A. 사용자가 민감한 행동을 위해 개인정보를 습득할 수 있도록 장려하기 때문입니다.",
      "B. 신뢰 구축으로, 인류를 보호하며, 공정성을 보장하며, 규제를 준수하기 때문입니다.",
      "C. AI 모델이 교육자료를 추천하면 개인 데이터가 필요하기 때문입니다.",
      "D. 개발자가 국가 요구 사항을 무시할 수 있기 때문입니다."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.680782+00:00",
    "updated_at": "2025-11-29T14:15:28.680782+00:00"
  },
  {
    "id": "7023975c-0e7b-4363-b710-b76bd8f0d758",
    "question_text_en": "Which of the following is a key approach used by NVIDIA to ensure data privacy in AI development?",
    "question_text_ko": "3. 다음 중 NVIDIA가 개발에서 데이터 개인 정보 보호를 보장하기 위해 사용하는 주요 접근 방식은 무엇입니까?",
    "options_en": [
      "A: Storing all collected data in centralized databases for easier access",
      "B: Using federated learning, confidential computing, and privacy-preserving techniques",
      "C: Collecting as much data as possible to improve AI accuracy",
      "D: Ignoring data privacy concerns if the AI system operates in a country without strict regulations"
    ],
    "options_ko": [
      "A. 수집된 모든 데이터를 중앙 데이터베이스에서 저장하여 더 쉽게 접근 가능",
      "B. 암호 학습, 커플 통계 및 개인 정보 보호 기술 사용",
      "C. 왜곡중립 정책을 지배하는 공개 데이터 사용",
      "D. 엄격한 규제가 없는 국가에서 시스템의 운용되는 경우 데이터 개인 정보 보호 문제를 무시합니다."
    ],
    "correct_answer": 1,
    "category": "Data Privacy",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.718839+00:00",
    "updated_at": "2025-11-29T14:15:28.718839+00:00"
  },
  {
    "id": "7d7d6db9-2287-4d7a-86c8-df89ba6339c5",
    "question_text_en": "How does NVIDIA ensure AI trustworthiness in its solutions?",
    "question_text_ko": "4. NVIDIA는 어떻게 복구 시뮬레이션의 AI 신뢰성을 보장합니까?",
    "options_en": [
      "A: By embedding trustworthy AI principles at every stage of AI development",
      "B: By manually reviewing AI outputs to ensure ethical compliance",
      "C: By relying solely on third-party organizations to establish AI safety standards",
      "D: By restricting AI models to avoid real-world applications"
    ],
    "options_ko": [
      "A. 개발된 모든 데이터를 디지털 있는 시스템을 보관함으로써",
      "B. 문제의 고유 설정을 사용자 정보와 신뢰의 흐름을 보관합니다.",
      "C. 신뢰성을 문제에 적용하여 생산적인 방법으로",
      "D. 일반적인 응용 프로그램 및 일반적 규칙 기반 모델을 활용함으로써"
    ],
    "correct_answer": 0,
    "category": "AI Ethics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.759946+00:00",
    "updated_at": "2025-11-29T14:15:28.759946+00:00"
  },
  {
    "id": "4886da75-c31d-4814-a580-d75a5b3bde39",
    "question_text_en": "How does NVIDIA approach bias mitigation in AI systems?",
    "question_text_ko": "5. NVIDIA는 AI 시스템의 문제 해결에 어떤 접근 방식을 취합니까?",
    "options_en": [
      "A: By relying solely on human-curated datasets for training",
      "B: By completely eliminating bias through AI algorithms",
      "C: By using the Omniverse Replicator to generate synthetic data",
      "D: By avoiding transparency and explainability in AI models"
    ],
    "options_ko": [
      "A. 관련 통합 시뮬의 복구 방법을 데이터 AI에 포함하는 것은 잘못된 생각입니다. 따라서, 이는 강력한 설계 변경 및 디버깅이 심한 데이터를 AI로 통합합니다. NVIDIA는 대강연 데이터 통합 방식에 의해 발생 가능한 기능적 설계 강화를 제공합니다.",
      "B. 복구를 위해 확장된 통합이 개선된 문제 해결 방법입니다. NVIDIA는 검증절로 관한 AI 설계의 끝점인 고급화 정책을 사용하며 클라우드를 사용하는 것이 있습니다. 또한 문제의 정비 관리자를 최소화하고 다른 팀과의 상호작용과 조화를 통해 ‘NVIDIA AI 실내 버전’ 응용을 권장하고 있습니다.",
      "C. Omniverse Replicator 를 생산적 증명에서 해결하여 문제를 생성하기를 목표로 합니다. NVIDIA의 Omniverse Replicator를 사용하여 더 크고 다양한 데이터 문제를 제당하는 도구로, 스케일의 타임을 더 많이 얻어 봅니다. 자세한 내용은 'NVIDIA AI 문제 습관' 항목을 참조하십시오.",
      "D. 문제의 방지 작업과 최종 실행을 함께 보장함으로써 이루어지는 것입입니다. NVIDIA는 AI의 방지 계약 설멩 강화를 권장하며, CI/CD 생산 서비스와의 파트너쉽 관계를 통해 설복할 수 있도록 합니다. 자세한 내용은 'NVIDIA의 최적 AI 지원' 항목을 참조하십시오."
    ],
    "correct_answer": 2,
    "category": "Bias Mitigation",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.813168+00:00",
    "updated_at": "2025-11-29T14:15:28.813168+00:00"
  },
  {
    "id": "1250277d-a578-4606-9d48-74c8a0c6b6a7",
    "question_text_en": "What is the primary goal of a regression algorithm in machine learning?",
    "question_text_ko": "머신 러닝에서 회귀 알고리즘의 주요 목표는 무엇인가요?",
    "options_en": [
      "To assign input data into predefined categories or classes.",
      "To predict a continuous numerical value based on input features.",
      "To group similar data points together based on their inherent patterns.",
      "To discover hidden structures in unlabeled data."
    ],
    "options_ko": [
      "입력 데이터로 미리 정의된 부분과 클래스에 할당합니다.",
      "입력 특징을 기반으로 연속적인 수치 값을 예측합니다.",
      "고유한 패턴을 기준으로 유사한 데이터 포인트를 그룹화합니다.",
      "레이블이 지정되지 않은 데이터에서 숨겨진 구조를 발견합니다."
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.865388+00:00",
    "updated_at": "2025-11-29T14:15:28.865388+00:00"
  },
  {
    "id": "d966d67a-36a0-45d0-b050-25c920592bea",
    "question_text_en": "What does LogisticRegression.coef_ represent in a logistic regression model?",
    "question_text_ko": "로지스틱 회귀 모델에서 LogisticRegression.coef_는 무엇을 나타내나요?",
    "options_en": [
      "The predicted probabilities for each class",
      "The weights or coefficients assigned to each feature in the model",
      "The accuracy of the model",
      "The log-odds of the positive class"
    ],
    "options_ko": [
      "각 클래스에 대한 예측 확률",
      "모델의 각 기능에 할당된 가중치 또는 계수",
      "모델의 정확도",
      "양의 클래스의 로그 오즈"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.917601+00:00",
    "updated_at": "2025-11-29T14:15:28.917601+00:00"
  },
  {
    "id": "31f72606-1083-4fc3-9496-969278e35c27",
    "question_text_en": "Which Clustering method can help us to find clusters of arbitrary shapes?",
    "question_text_ko": "어떤 클러스터링 방법이 임의의 모양의 클러스터를 찾는 데 도움이 될 수 있습니까?",
    "options_en": [
      "K-Means Clustering",
      "Hierarchical Clustering",
      "DBScan Clustering",
      "K-Medoids Clustering"
    ],
    "options_ko": [
      "계층적 클러스터링",
      "계속적 클러스터링",
      "DBScan 클러스터링",
      "K-Medoids 클러스터링"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.581001+00:00",
    "updated_at": "2025-11-29T14:15:29.581001+00:00"
  },
  {
    "id": "a8f551e3-21bf-41cb-968a-ede7d4fa7f3d",
    "question_text_en": "What does a high recall indicate about the model?",
    "question_text_ko": "높은 재현율은 모델에 대해 무엇을 나타내는가?",
    "options_en": [
      "The model has a low rate of false positives.",
      "The model is excellent at identifying all instances of a specific class.",
      "The model is good at predicting a specific class when it does predict it.",
      "The model is well-balanced in terms of precision and recall."
    ],
    "options_ko": [
      "해당 모델은 거짓 양성률이 높습니다.",
      "이 모델은 특정 클래스의 모든 인스턴스를 식별하는 데 매우 뛰어납니다.",
      "이 모델은 특정 클래스를 예측하는 데 효과적입니다.",
      "이 모델은 정밀도와 재현율 측면에서 균형이 잘 잡혀 있습니다."
    ],
    "correct_answer": 1,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:28.966113+00:00",
    "updated_at": "2025-11-29T14:15:28.966113+00:00"
  },
  {
    "id": "a4a297f5-8e95-4acf-b9ec-8005dcdeccb6",
    "question_text_en": "Which metric is best suited for imbalanced datasets?",
    "question_text_ko": "불균형 데이터 세트에 가장 적합한 지표는 무엇인가요?",
    "options_en": [
      "Accuracy",
      "Recall",
      "Precision",
      "F1 Score"
    ],
    "options_ko": [
      "정확성",
      "정기하다",
      "정도",
      "F1 점수"
    ],
    "correct_answer": 3,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.009922+00:00",
    "updated_at": "2025-11-29T14:15:29.009922+00:00"
  },
  {
    "id": "9374a483-de32-4659-9bc5-98b127da16aa",
    "question_text_en": "Which of the following formulas represents precision?",
    "question_text_ko": "다음 중 어느 공식이 정밀도를 나타내나요?",
    "options_en": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "(TP + TN) / (TP + FP + FN + TN)",
      "2 X Precision X Recall / (Precision + Recall)"
    ],
    "options_ko": [
      "TP / (TP + FN)",
      "TP / (TP + FP)",
      "TP + TN / (TP + FP + FN + TN)",
      "2 x 정밀도 x 재현율 / (정밀도 + 재현율)"
    ],
    "correct_answer": 1,
    "category": "Evaluation Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.046133+00:00",
    "updated_at": "2025-11-29T14:15:29.046133+00:00"
  },
  {
    "id": "f85eb0da-b104-4c68-a158-f219d2998ff0",
    "question_text_en": "What does an R-squared value of 0.85 indicate?",
    "question_text_ko": "1. R-제곱 값이 0.85는 무엇을 나타냅니까?",
    "options_en": [
      "85% of the variance in the target variable is explained by the model",
      "The model's predictions are 85% accurate",
      "The average error of the model is 0.85 units",
      "15% of the variance in the target variable is unexplained by the model"
    ],
    "options_ko": [
      "목표 변수의 분산의 85%는 모델에 의해 설명됩니다.",
      "모델의 예측 정확도는 85%입니다.",
      "모델의 평균 오차율은 0.85 단위입니다.",
      "목표 변수의 분산 중 15%는 모델에 의해 설명되지 않습니다."
    ],
    "correct_answer": 0,
    "category": "Regression Analysis",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.082708+00:00",
    "updated_at": "2025-11-29T14:15:29.082708+00:00"
  },
  {
    "id": "ecbd4cb4-5420-420a-9fff-d48de66325c6",
    "question_text_en": "In a scenario where even small errors can have significant consequences, which metric would you pay more attention to?",
    "question_text_ko": "2. 아무리 작은 오류라도 중대한 결과를 초래할 수 있는 상황에서 어떤 지표에 더 많은 주의를 기울여야 할까요?",
    "options_en": [
      "MAE",
      "RMSE",
      "R-squared",
      "It depends on the specific context."
    ],
    "options_ko": [
      "정확도",
      "RMSE",
      "R제곱",
      "이는 구체적인 상황에 따라 달라집니다."
    ],
    "correct_answer": 0,
    "category": "Model Evaluation Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.130723+00:00",
    "updated_at": "2025-11-29T14:15:29.130723+00:00"
  },
  {
    "id": "20c1f539-d67b-44b6-b0b8-1f0978e6ab45",
    "question_text_en": "Which of the following is NOT a metric directly derived from a confusion matrix?",
    "question_text_ko": "3. 다음 중 혼동 행렬에서 직접 파생된 지표가 아닌 것은 무엇입니까?",
    "options_en": [
      "Accuracy",
      "Precision",
      "Recall",
      "Mean Squared Error (MSE)"
    ],
    "options_ko": [
      "정확성",
      "정도",
      "상기력",
      "평균 제곱 오차(MSE)"
    ],
    "correct_answer": 3,
    "category": "Classification Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.166534+00:00",
    "updated_at": "2025-11-29T14:15:29.166534+00:00"
  },
  {
    "id": "1062cc44-2330-4644-9c25-70a9572171eb",
    "question_text_en": "In a confusion matrix, what does a high number of False Negatives indicate?",
    "question_text_ko": "4. 혼동 행렬에서 거짓 부정의 수가 많다는 것은 무엇을 의미합니까?",
    "options_en": [
      "The model is predicting many positive cases incorrectly.",
      "The model is failing to identify many actual positive cases.",
      "The model is performing well in identifying negative cases.",
      "The model has a high accuracy."
    ],
    "options_ko": [
      "해당 모델은 많은 양성 사례를 잘못 예측하고 있습니다.",
      "이 모델은 실제로 양성 환자 사례를 많이 식별하지 못하고 있습니다.",
      "해당 모델은 부정적인 사례를 식별하는 데 좋은 성과를 보이고 있습니다.",
      "해당 모델은 정확도가 높습니다."
    ],
    "correct_answer": 1,
    "category": "Classification Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.206562+00:00",
    "updated_at": "2025-11-29T14:15:29.206562+00:00"
  },
  {
    "id": "f34929d9-e76a-42bd-8cdb-47c72683999d",
    "question_text_en": "Which of the following is an example of a classification problem?",
    "question_text_ko": "5. 다음 중 분류 문제의 예는 무엇입니까?",
    "options_en": [
      "Predicting the price of a house",
      "Identifying whether an email is spam or not",
      "Estimating the number of customers in a store",
      "Predicting the temperature of a city"
    ],
    "options_ko": [
      "주택 가격 예측",
      "이메일이 스팸인지 아닌지 식별하기",
      "매장의 고객 수 추산",
      "도시의 온도 예측"
    ],
    "correct_answer": 1,
    "category": "Classification Problems",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.253289+00:00",
    "updated_at": "2025-11-29T14:15:29.253289+00:00"
  },
  {
    "id": "5a963a1a-a5d5-453b-be91-6238c33e1abd",
    "question_text_en": "Which evaluation metric is NOT typically used for regression models?",
    "question_text_ko": "6. 어떤 평가 지표가 일반적으로 회귀 모델에 사용되지 않습니까?",
    "options_en": [
      "R-squared (R²)",
      "Mean Absolute Error (MAE)",
      "F1-score",
      "Root Mean Squared Error (RMSE)"
    ],
    "options_ko": [
      "R제곱(R²)",
      "평균 절대 오차(MAE)",
      "F1 점수",
      "평균 제곱근 오차(RMSE)"
    ],
    "correct_answer": 2,
    "category": "Regression Metrics",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.306941+00:00",
    "updated_at": "2025-11-29T14:15:29.306941+00:00"
  },
  {
    "id": "74e3f5e2-e2a8-46db-b9e2-3abe4ad0cccf",
    "question_text_en": "Which of the following is NOT a typical application of hierarchical clustering?",
    "question_text_ko": "다음 중 계층적 클러스터링의 일반적인 적용 분야가 아닌 것은 무엇입니까?",
    "options_en": [
      "Image segmentation",
      "Customer segmentation",
      "Linear regression",
      "Anomaly detection"
    ],
    "options_ko": [
      "이미지 분할",
      "고객 세분화",
      "선형 회귀",
      "이상 감지"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.350017+00:00",
    "updated_at": "2025-11-29T14:15:29.350017+00:00"
  },
  {
    "id": "9296613a-b027-44b9-a186-791912be75da",
    "question_text_en": "Which of the following is the first step in the k-means algorithm?",
    "question_text_ko": "다음 중 k-평균 알고리즘의 첫 번째 단계는 무엇입니까?",
    "options_en": [
      "Assignment of data points to the nearest centroids",
      "Recalculation of centroids",
      "Random initialization of centroids",
      "Iteration until convergence"
    ],
    "options_ko": [
      "가장 가까운 중심에 데이터 포인트 할당",
      "중심점 재계산",
      "중심점의 무작위 초기화",
      "수렴할 때까지 반복"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.385779+00:00",
    "updated_at": "2025-11-29T14:15:29.385779+00:00"
  },
  {
    "id": "003dab38-07af-4bad-8625-9c9956296815",
    "question_text_en": "Which of the following methods helps assess how well each data point fits within its assigned cluster in k-means?",
    "question_text_ko": "다음 방법 중 어떤 것이 k-공간에서 각 데이터 포인트가 할당된 클러스터에 얼마나 잘 들어맞는지 평가하는 데 도움이 됩니까?",
    "options_en": [
      "Elbow Method",
      "Silhouette Analysis",
      "Domain Knowledge",
      "Grid Search"
    ],
    "options_ko": [
      "관측치 방법",
      "실루엣 분석",
      "도메인 지식",
      "그리드 검색"
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.425625+00:00",
    "updated_at": "2025-11-29T14:15:29.425625+00:00"
  },
  {
    "id": "39392743-b739-4112-83d2-3205d0d9b659",
    "question_text_en": "What are we looking for in the plot generated by the Elbow Method?",
    "question_text_ko": "엘보우방법으로 생성된 플롯에서 우리는 무엇을 찾고 있는가?",
    "options_en": [
      "A sharp peak",
      "A gradual slope",
      "A bend or \"elbow\" point",
      "A straight line"
    ],
    "options_ko": [
      "낮아진 분점",
      "점진적인 감소",
      "균형 또는 '팔꿈치' 지점",
      "직선"
    ],
    "correct_answer": 2,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.461241+00:00",
    "updated_at": "2025-11-29T14:15:29.461241+00:00"
  },
  {
    "id": "0c22346b-f1ff-41a2-bb59-d270169e895c",
    "question_text_en": "What is the visual representation of the hierarchical clustering process called?",
    "question_text_ko": "계층적 클러스터링 과정의 시각적 표현은 무엇이라고 하나요?",
    "options_en": [
      "Scatter plot",
      "Dendrogram",
      "Histogram",
      "Box plot"
    ],
    "options_ko": [
      "산포도",
      "덴드로그램",
      "히스토그램",
      "상자 그림"
    ],
    "correct_answer": 1,
    "category": "Clustering",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.505192+00:00",
    "updated_at": "2025-11-29T14:15:29.505192+00:00"
  },
  {
    "id": "c9dd080c-fee3-48a9-823a-1a04f1a09802",
    "question_text_en": "What are the two key metrics used to evaluate the strength of an association rule?",
    "question_text_ko": "연관 규칙의 강도를 평가하는 데 사용되는 두 가지 주요 지표는 무엇입니까?",
    "options_en": [
      "Accuracy and Precision",
      "Support and Confidence",
      "Recall and F1-score",
      "Mean and Median"
    ],
    "options_ko": [
      "정확도와 정밀도",
      "지연과 신뢰",
      "리콜 및 F1 점수",
      "평균과 중앙값"
    ],
    "correct_answer": 1,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.62217+00:00",
    "updated_at": "2025-11-29T14:15:29.62217+00:00"
  },
  {
    "id": "8d146524-869e-498a-a328-71d8b7b67a5f",
    "question_text_en": "Which metric quantifies the likelihood of item Y being purchased when item X is purchased, relative to the overall likelihood of Y being purchased?",
    "question_text_ko": "어떤 지표는 품목 X가 구매될 때 품목 Y가 구매될 가능성을 Y가 구매될 전체 가능성에 비해 정량화하는가?",
    "options_en": [
      "Support",
      "Confidence",
      "Lift",
      "Count"
    ],
    "options_ko": [
      "지지력",
      "신뢰",
      "승강기",
      "세다"
    ],
    "correct_answer": 2,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.669595+00:00",
    "updated_at": "2025-11-29T14:15:29.669595+00:00"
  },
  {
    "id": "4130b67a-fb39-4ce5-a666-02b4d121264c",
    "question_text_en": "Which of the following is NOT a step in the association rule mining process?",
    "question_text_ko": "다음 중 연관 규칙 마이닝 프로세스의 단계가 아닌 것은 무엇입니까?",
    "options_en": [
      "Generate Frequent Itemsets",
      "Generate Rules",
      "Evaluate Rules",
      "Cluster Analysis"
    ],
    "options_ko": [
      "빈발한 항목 집합 생성",
      "규칙 생성",
      "규칙 평가",
      "클러스터 분석"
    ],
    "correct_answer": 3,
    "category": "Association Rule Mining",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.714019+00:00",
    "updated_at": "2025-11-29T14:15:29.714019+00:00"
  },
  {
    "id": "e96ebcff-5858-428d-99a7-f7ead518e7d2",
    "question_text_en": "Which of the following is NOT a key feature of RAPIDS?",
    "question_text_ko": "다음 중 RAPIDS의 핵심이 아닌 것은 무엇입니까?",
    "options_en": [
      "Open-Source Software Library",
      "GPU Acceleration",
      "Drop-In Replacement for Existing Libraries",
      "Automatic Model Selection"
    ],
    "options_ko": [
      "오픈 소스 소프트웨어 라이브러리",
      "GPU 가속",
      "기존 도서관에 대한 드롭인 교체",
      "자동 모델 선택"
    ],
    "correct_answer": 3,
    "category": "RAPIDS",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.754615+00:00",
    "updated_at": "2025-11-29T14:15:29.754615+00:00"
  },
  {
    "id": "32df5fc9-2ece-40dc-a254-2c93d2ff8554",
    "question_text_en": "Which layer in a DNN is responsible for receiving the raw input data?",
    "question_text_ko": "DNN의 어느 계층이 원시 입력 데이터를 수신하는 역할을 합니까?",
    "options_en": [
      "Input Layer",
      "Hidden Layer",
      "It determines the accuracy of the model.",
      "It has no significant role in machine learning"
    ],
    "options_ko": [
      "입력 레이어",
      "숨겨진 레이어",
      "이는 정확성 정확도를 결정합니다.",
      "마지막에서 중요한 역할을 합니다."
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.801642+00:00",
    "updated_at": "2025-11-29T14:15:29.801642+00:00"
  },
  {
    "id": "ecdc6782-b5be-40ce-8840-67f1ea0bab5b",
    "question_text_en": "Which type of Deep Neural Network is best suited for processing images and videos?",
    "question_text_ko": "이런 유형의 딥 신경망이 이미지와 비디오를 처리하는 데 가장 적합합니까?",
    "options_en": [
      "Multi-Layer Perceptron (MLP)",
      "Convolutional Neural Network (CNN)",
      "Recurrent Neural Network (RNN)",
      "Generative Adversarial Network (GAN)"
    ],
    "options_ko": [
      "다층 퍼셉트론(MLP)",
      "합성곱 신경망(CNN)",
      "순환 신경망(RNN)",
      "생성적 적대 신경망(GAN)"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.849899+00:00",
    "updated_at": "2025-11-29T14:15:29.849899+00:00"
  },
  {
    "id": "dda183f7-7953-4dda-9fc9-d69bdb53c696",
    "question_text_en": "What role do Weights play in an artificial neuron?",
    "question_text_ko": "인공 뉴런에서 가중치는 어떤 역할을 하나요?",
    "options_en": [
      "Introduce non-linearity",
      "Determine the importance of each input",
      "Provide a constant offset",
      "Receive the initial data"
    ],
    "options_ko": [
      "비선형성을 도입합니다",
      "각 입력의 중요성을 결정하세요",
      "큰 단일 값으로 계산",
      "초기 데이터 수신"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.890385+00:00",
    "updated_at": "2025-11-29T14:15:29.890385+00:00"
  },
  {
    "id": "0c483af3-1abc-447d-8a36-28b906306db4",
    "question_text_en": "What is the first step in the computation process of an artificial neuron?",
    "question_text_ko": "인공 뉴런의 계층 경계에서 첫 번째 단계는 무엇입니까?",
    "options_en": [
      "Apply the activation function",
      "Calculate the weighted sum",
      "Transmit the output signal",
      "Adjust the bias"
    ],
    "options_ko": [
      "활성화 함수를 적용합니다",
      "가중치를 계산합니다",
      "출력 신호를 전송합니다",
      "입력을 조정하다"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.929444+00:00",
    "updated_at": "2025-11-29T14:15:29.929444+00:00"
  },
  {
    "id": "cbd710f3-ded7-4482-884f-6bc511ae87ad",
    "question_text_en": "What is the initial step in the Gradient Descent algorithm?",
    "question_text_ko": "경사 하강 알고리즘의 초기 단계는 무엇입니까?",
    "options_en": [
      "Calculate the gradient of the loss function",
      "Update the model parameters",
      "Initialize the model parameters with random values",
      "Repeat steps until convergence"
    ],
    "options_ko": [
      "손실 함수의 기울기를 계산합니다",
      "모델 입력처리를 만듭니다",
      "알맞은 모듈로 모델 매개변수를 초기화합니다",
      "추출된 매개변수를 변형합니다"
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:29.971148+00:00",
    "updated_at": "2025-11-29T14:15:29.971148+00:00"
  },
  {
    "id": "51d7f33f-535a-451b-916c-eaf6024c3f61",
    "question_text_en": "What is the mathematical formula for the ReLU activation function?",
    "question_text_ko": "ReLU 활성화 함수의 수학 공식은 무엇인가요?",
    "options_en": [
      "f(x) = max(0, x)",
      "f(x) = 1 / (1 + e^-x)",
      "f(x) = tanh(x)",
      "f(x) = x"
    ],
    "options_ko": [
      "f(x) = max(0, x)",
      "f(x) = 1 / (1 + e^-x)",
      "f(x) = tanh(x)",
      "f(x) = x"
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.007574+00:00",
    "updated_at": "2025-11-29T14:15:30.007574+00:00"
  },
  {
    "id": "2bba3f5f-241d-450c-bf41-0b2dfc4c5974",
    "question_text_en": "What is the purpose of applying an activation function in a neuron?",
    "question_text_ko": "뚜렷이 활성화 함수를 적용하는 목적은 무엇인가요?",
    "options_en": [
      "To normalize the input values",
      "To introduce non-linearity into the model",
      "To calculate the weighted sum of inputs",
      "To produce the final prediction"
    ],
    "options_ko": [
      "입력값을 규정화하기 위해",
      "모델의 비선형성을 도입하려면",
      "입력의 가중평균을 계산하려면",
      "새로운 예측을 생성하려면"
    ],
    "correct_answer": 1,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.051763+00:00",
    "updated_at": "2025-11-29T14:15:30.051763+00:00"
  },
  {
    "id": "ce84017e-5d73-4a54-ad00-969da756af5b",
    "question_text_en": "In the equation Z = W * X + b, what does Z represent?",
    "question_text_ko": "Z = W * x + b 방정식에서 Z는 무엇을 나타내나요?",
    "options_en": [
      "The weight matrix",
      "The input matrix",
      "The bias vector",
      "The matrix of weighted sums for all neurons in a layer"
    ],
    "options_ko": [
      "가중치 행렬",
      "편향 행렬",
      "하이퍼볼릭 탄젠트",
      "계층의 모든 뉴런에 대한 가중 합의 행렬"
    ],
    "correct_answer": 3,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.091449+00:00",
    "updated_at": "2025-11-29T14:15:30.091449+00:00"
  },
  {
    "id": "b4967124-e56e-484e-a90f-c9000851b03d",
    "question_text_en": "What is the primary goal of backpropagation in neural networks?",
    "question_text_ko": "신경망에서 역전파 알고리즘의 주요 목적은 무엇인가요?",
    "options_en": [
      "To initialize the model's parameters",
      "To make predictions on new data",
      "To minimize the overall error and improve model accuracy",
      "To introduce non-linearity into the model"
    ],
    "options_ko": [
      "모델의 파라미터를 초기화하려면",
      "새로운 데이터에 대한 예측을 하려면",
      "성능을 최적화하고 모델의 정확도를 향상시키려면",
      "모델의 비선형성을 도입하려면"
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.134015+00:00",
    "updated_at": "2025-11-29T14:15:30.134015+00:00"
  },
  {
    "id": "a35235a5-9317-4519-8adf-191fc92f174c",
    "question_text_en": "Which step involves feeding the input data through the network to generate a prediction?",
    "question_text_ko": "예측을 생성하기 위해 딥러닝 네트워크에 공급하는 단계는 무엇인가?",
    "options_en": [
      "Forward Pass",
      "Loss Calculation",
      "Backward Pass",
      "Weight Initialization"
    ],
    "options_ko": [
      "프로토콜 분석",
      "손실 계산",
      "역전파",
      "가중치 초기화"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.169236+00:00",
    "updated_at": "2025-11-29T14:15:30.169236+00:00"
  },
  {
    "id": "ab84e65d-e17b-4f56-8cd1-d59d99817b18",
    "question_text_en": "Given a categorical feature with values ['red', 'green', 'blue'], what would be the one-hot encoded representation of 'green'?",
    "question_text_ko": "'red', 'green', 'blue' ]라는 범주의 특성이 주어졌을 때, 'green'의 원핫 인코딩 표현은 무엇인가요?",
    "options_en": [
      "[1, 0, 0]",
      "[0, 1, 0]",
      "[0, 0, 1]",
      "[1, 1, 0]"
    ],
    "options_ko": [
      "[0, 1, 0]",
      "[1, 0, 0]",
      "[0, 0, 1]",
      "[1, 1, 0]"
    ],
    "correct_answer": 1,
    "category": "Data Preprocessing",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.208516+00:00",
    "updated_at": "2025-11-29T14:15:30.208516+00:00"
  },
  {
    "id": "ae83a059-f871-49c7-a964-2dad7f7b61a4",
    "question_text_en": "What type of data are Convolutional Neural Networks (CNNs) primarily designed to process?",
    "question_text_ko": "합성곱 신경망(CNN)은 주로 어떤 유형의 데이터를 처리하도록 설계되었습니까?",
    "options_en": [
      "Sequential data, such as text or time series",
      "Tabular data with structured features",
      "Grid-like data, such as images and video",
      "Audio data"
    ],
    "options_ko": [
      "텍스트나 시계열과 같은 순차적 데이터",
      "구조화된 값이 있는 표 형식 데이터",
      "이미지, 비디오 등 2 그리드 형탤 데이터",
      "오디오 데이터"
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.24712+00:00",
    "updated_at": "2025-11-29T14:15:30.24712+00:00"
  },
  {
    "id": "ed980815-58e2-44c7-ad3b-90ba3989ba5e",
    "question_text_en": "What is the primary purpose of Pooling Layers in a CNN?",
    "question_text_ko": "CNN에서 풀링 레이어의 주요 목적은 무엇입니까?",
    "options_en": [
      "To increase the spatial dimensions of the data",
      "To introduce non-linearity into the model",
      "To reduce the spatial dimensions of the data by downsampling",
      "To generate the final output predictions"
    ],
    "options_ko": [
      "데이터의 공간적 차원을 늘리려면",
      "모델의 반상성능을 도울하려면",
      "다운샘플링을 통해 데이터의 공간적 차원을 줄이려면",
      "최종 출력 예측을 생성하려면"
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.286597+00:00",
    "updated_at": "2025-11-29T14:15:30.286597+00:00"
  },
  {
    "id": "3ed1c63f-1444-4d0b-b421-8af594572161",
    "question_text_en": "What is the core concept behind transfer learning?",
    "question_text_ko": "전이 학습의 핵심 개념은 무엇입니까?",
    "options_en": [
      "Training a model from scratch on a small dataset.",
      "Leveraging knowledge from a pre-trained model on a new but related task.",
      "Creating a completely new neural network architecture for every task.",
      "Only using labeled data for training."
    ],
    "options_ko": [
      "작은 데이터세트를 이용해 처음부터 모델을 학습합니다.",
      "사전 훈련된 모델의 지식을 새롭지만 관련된 작업에 활용합니다.",
      "모든 작업에 대해 완전히 새로운 신경망 아키텍처를 만듭니다.",
      "레이블이 지정된 데이터만 사용하여 학습합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.322051+00:00",
    "updated_at": "2025-11-29T14:15:30.322051+00:00"
  },
  {
    "id": "f52e46bb-cfbd-4aef-b232-51d7552f1bda",
    "question_text_en": "In which scenario is transfer learning most likely to be beneficial?",
    "question_text_ko": "어떤 시나리오에서 전이 학습이 가장 유익할 가능성이 높습니까?",
    "options_en": [
      "You have abundant labeled data for your specific task.",
      "The pre-trained model was trained on a task completely unrelated to your target task.",
      "You have ample computational resources and a large dataset for your new task.",
      "You have a small dataset for your specific task and limited computational resources."
    ],
    "options_ko": [
      "다량의 특정 환경에 적합한 레이블이 지정된 데이터가 풍부합니다.",
      "사전 학습된 모델은 대상 작업과 전혀 관련이 없는 작업에 대해 학습되었습니다.",
      "새로운 작업을 수행하기에 충분한 컴퓨팅 리소스와 대규모 데이터 세트를 찾고 있습니다.",
      "다량의 특정 환경에 필요한 데이터 세트는 작고 컴퓨팅 리소스도 제한적입니다."
    ],
    "correct_answer": 3,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.360336+00:00",
    "updated_at": "2025-11-29T14:15:30.360336+00:00"
  },
  {
    "id": "2b203053-4d38-4283-a74d-d6c6a52827ff",
    "question_text_en": "When loading the VGG16 model, what does setting include_top=False signify?",
    "question_text_ko": "VGG16 모델을 로드할 때 include_top=False로 설정하는 것은 무엇을 의미합니까?",
    "options_en": [
      "It excludes the final fully connected classification layers of the model",
      "It excludes the convolutional base of the model",
      "It loads the model without pre-trained weights",
      "It disables transfer learning"
    ],
    "options_ko": [
      "모델의 최상 층에 있는 Dense 계층을 제외합니다.",
      "모델의 학습량 기반을 제외합니다.",
      "사전 훈련된 가중치 없이 모델을 로드합니다.",
      "같이 학습을 비활성화합니다."
    ],
    "correct_answer": 0,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.398127+00:00",
    "updated_at": "2025-11-29T14:15:30.398127+00:00"
  },
  {
    "id": "e8baf985-ffaa-4f2c-8624-a64b869a5532",
    "question_text_en": "What is the purpose of freezing layers in the VGG16 model during transfer learning?",
    "question_text_ko": "같이 학습 없이 VGG16 모델에서 레이어를 동결하는 '활용'은 무엇입니까?",
    "options_en": [
      "To prevent the pre-trained weights from being updated during training",
      "To slightly speed up the training process",
      "To ensure the model learns only from the new data",
      "To reduce the model’s complexity"
    ],
    "options_ko": [
      "사전 훈련된 가중치가 없는 모델에서는 정확성을 저하",
      "훈련 과정 맨 마지막부터 접근하려면",
      "모델에 새로운 데이터셋만 학습하도록 하려면",
      "모델의 복잡성을 줄이려면"
    ],
    "correct_answer": 0,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.433965+00:00",
    "updated_at": "2025-11-29T14:15:30.433965+00:00"
  },
  {
    "id": "3a50fd87-1461-4d5e-ae2e-e99ced5fc5f7",
    "question_text_en": "Which activation function maps the input to a range between 0 and 1 and is historically popular but suffers from vanishing gradients?",
    "question_text_ko": "어떤 활성 함수가 입력을 0~1 사이의 범위에 매핑하며, 역사적으로 입력 값 자체가 기울기가 사라지는 문제가 있는가?",
    "options_en": [
      "Sigmoid",
      "Hyperbolic Tangent (tanh)",
      "Rectified Linear Unit (ReLU)",
      "Linear"
    ],
    "options_ko": [
      "시그모이드",
      "쌍곡탄젠트(tanh)",
      "정류 선형 유닛(ReLU)",
      "선형"
    ],
    "correct_answer": 0,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.477797+00:00",
    "updated_at": "2025-11-29T14:15:30.477797+00:00"
  },
  {
    "id": "85b1c1e1-bfd5-41c1-8df3-6cddfbd34356",
    "question_text_en": "Which activation function is similar to sigmoid but maps the input to a range between -1 and 1?",
    "question_text_ko": "시그모이드와 유사하지만 입력을 -1과 1 사이의 범위로 매핑하는 활성화 함수는 무엇인가?",
    "options_en": [
      "Sigmoid",
      "Hyperbolic Tangent (tanh)",
      "Rectified Linear Unit (ReLU)",
      "Linear"
    ],
    "options_ko": [
      "시그모이드",
      "쌍곡탄젠트(tanh)",
      "정류 선형 유닛(ReLU)",
      "선형"
    ],
    "correct_answer": 1,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.518517+00:00",
    "updated_at": "2025-11-29T14:15:30.518517+00:00"
  },
  {
    "id": "52428bd4-da60-4927-91e8-c059a6540c7a",
    "question_text_en": "Which of the following is a common approach in transfer learning?",
    "question_text_ko": "다음 중 같이 학습에서 일반적인 접근 방식은 무엇인가?",
    "options_en": [
      "Training a model from scratch with random weights",
      "Completely discarding pre-trained models in every training iteration",
      "Avoiding the use of neural networks",
      "Using a pre-trained model as a feature extractor and fine-tuning only specific layers"
    ],
    "options_ko": [
      "무작위 가중치를 사용하여 처음부터 모델 학습",
      "모든 훈련 반복에서 사전 훈련 모델을 무시합니다.",
      "신경망 사전 훈련",
      "가중치 변환에 생성적 기능 출력을 사용하는 특성 데이터에 페널티 적용"
    ],
    "correct_answer": 3,
    "category": "Transfer Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.5643+00:00",
    "updated_at": "2025-11-29T14:15:30.5643+00:00"
  },
  {
    "id": "0143cf7b-b37f-4982-8359-f7cdfcadd726",
    "question_text_en": "What is the primary challenge that Natural Language Processing (NLP) aims to address?",
    "question_text_ko": "자연어 처리(NLP)가 해결하고자 하는 주요 과제는 무엇입니까?",
    "options_en": [
      "The complexity and ambiguity of human language.",
      "The speed at which humans can process information.",
      "The vast amount of data generated by machines.",
      "The difficulty of programming computers in binary code."
    ],
    "options_ko": [
      "인간 언어의 복잡성과 모호성.",
      "인간이 정보를 처리할 수 있는 속도.",
      "기계가 생성하는 양질의 데이터.",
      "이진 코드를 컴퓨터를 프로그래밍하는 것은 어렵다."
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.60824+00:00",
    "updated_at": "2025-11-29T14:15:30.60824+00:00"
  },
  {
    "id": "f048dd9e-1762-4cd8-a5a1-318a033d25ef",
    "question_text_en": "Which NLP preprocessing technique involves breaking down a text into smaller units like words or subwords?",
    "question_text_ko": "어떤 NLP 전처리 기법이 텍스트를 단어나 하위 단어와 같은 더 작은 단위로 분해하는 것을 포함합니까?",
    "options_en": [
      "Tokenization",
      "Stopword Removal",
      "Stemming",
      "Lemmatization"
    ],
    "options_ko": [
      "토큰화",
      "불용어 제거",
      "어간 분석",
      "레마티제이션"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.646404+00:00",
    "updated_at": "2025-11-29T14:15:30.646404+00:00"
  },
  {
    "id": "ef6fe9f4-ac16-4d53-97a1-e0c06f47b8bd",
    "question_text_en": "Which text normalization technique aims to reduce words to their base or root form, often by removing suffixes?",
    "question_text_ko": "어떤 텍스트 정규화 기술이 접미사를 제거하여 단어를 기본 형태나 어근 형태로 줄이는 것을 목표로 합니까?",
    "options_en": [
      "Stemming",
      "Lemmatization",
      "Expanding contractions",
      "Tokenization"
    ],
    "options_ko": [
      "어간 분석",
      "레마티제이션",
      "추상 추출",
      "토큰화"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.689567+00:00",
    "updated_at": "2025-11-29T14:15:30.689567+00:00"
  },
  {
    "id": "a7e5f6b8-74ac-454c-b415-f8afd8cd6dac",
    "question_text_en": "When selecting a machine learning model, what is a common trade-off that practitioners need to consider?",
    "question_text_ko": "머신 러닝 모델을 선택할 때 실무자가 고려해야 할 일반적인 균형점은 무엇인가요?",
    "options_en": [
      "Accuracy vs. Speed",
      "Complexity vs. Interpretability",
      "Data Size vs. Model Size",
      "Supervised vs. Unsupervised Learning"
    ],
    "options_ko": [
      "정확도 대 속도",
      "복잡성 대 해석 가능성",
      "C-데이터 필요량 대 모델 크기",
      "지도 학습 vs. 비지도 학습"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.579449+00:00",
    "updated_at": "2025-11-29T14:15:32.579449+00:00"
  },
  {
    "id": "8dad574d-df2b-4806-acbf-49f54804bfb4",
    "question_text_en": "When building an NLP pipeline, how should you choose the specific components to include?",
    "question_text_ko": "NLP 파이프라인을 구축할 때 포함할 특정 구성 요소를 어떻게 선택해야 합니까?",
    "options_en": [
      "Randomly select components.",
      "Always use the same components for every task",
      "Base the selection on the specific NLP task you are trying to solve",
      "Only use pre-built pipelines, never customize"
    ],
    "options_ko": [
      "무작위로 구성요소를 선택합니다.",
      "모든 작업이 항상 동일한 구성 요소를 사용하십시오.",
      "해결하려는 특정 NLP 작업에 따라 선택을 기반으로 하세요.",
      "미리 구축된 파이프라인만 사용하고 사용자 정의하지 마십시오."
    ],
    "correct_answer": 2,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.725929+00:00",
    "updated_at": "2025-11-29T14:15:30.725929+00:00"
  },
  {
    "id": "c928120b-2165-4d2a-80f7-d781c338e331",
    "question_text_en": "Which of the following is NOT a typical type of named entity recognized in NLP tasks?",
    "question_text_ko": "다음 중 NLP 작업에서 인식되는 일반적인 명명된 엔티티 유형이 아닌 것은 무엇입니까?",
    "options_en": [
      "Person",
      "Organization",
      "Location",
      "Adjective"
    ],
    "options_ko": [
      "사람",
      "조직",
      "위치",
      "형용사"
    ],
    "correct_answer": 3,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.770902+00:00",
    "updated_at": "2025-11-29T14:15:30.770902+00:00"
  },
  {
    "id": "cc6ada54-3587-4abb-89af-3abebf457c54",
    "question_text_en": "What is the primary goal of Named Entity Recognition (NER)?",
    "question_text_ko": "명명된 개체 인식(NER)의 주요 목표는 무엇인가요?",
    "options_en": [
      "To identify and classify named entities in text, such as names of people, organizations, locations, etc.",
      "To translate text from one language to another",
      "To generate human-like text",
      "To summarize large documents"
    ],
    "options_ko": [
      "사람, 조직, 위치 등의 이름 등 텍스트에서 명명된 엔티티를 식별하고 분류합니다.",
      "한 언어에서 다른 언어로 텍스트를 번역하려면",
      "인간과 유사한 텍스트를 생성하려면",
      "대용량 문서를 요약하려면"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.815664+00:00",
    "updated_at": "2025-11-29T14:15:30.815664+00:00"
  },
  {
    "id": "9410bee9-fe93-40d0-ae3b-efdefc67f6a3",
    "question_text_en": "What are word embeddings?",
    "question_text_ko": "워드 임베딩이란 무엇인가요?",
    "options_en": [
      "Sparse matrices representing the frequency of words in a document.",
      "Dense vector representations of words in a continuous vector space.",
      "One-hot encoded representations of words.",
      "Syntactic trees capturing the grammatical structure of sentences."
    ],
    "options_ko": [
      "문서에서 단어의 빈도를 나타내는 희소 행렬입니다.",
      "연속적인 벡터 공간에서 단어에 밀집 벡터 표현입니다.",
      "단어의 원작 인코딩 표현.",
      "문장의 문법적 구조를 포함하는 구문 트리."
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.857545+00:00",
    "updated_at": "2025-11-29T14:15:30.857545+00:00"
  },
  {
    "id": "94008cb1-0efc-4a27-b1f5-defc28570a02",
    "question_text_en": "How are pre-trained word embeddings typically used in NLP models?",
    "question_text_ko": "사전 훈련된 단어 임베딩은 일반적으로 NLP 모델에서 어떻게 사용됩니까?",
    "options_en": [
      "They are directly fed into the final output layer of the model.",
      "They are used as input features to the model.",
      "They replace the need for any other feature engineering.",
      "They are only used for language generation tasks."
    ],
    "options_ko": [
      "이는 모델의 최종 출력 계층에 직접 입력됩니다.",
      "이는 모델의 입력 기능으로 사용됩니다.",
      "이는 다른 기능 엔지니어링 필요성을 대체합니다.",
      "이는 언어 생성 작업에만 사용됩니다."
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.903784+00:00",
    "updated_at": "2025-11-29T14:15:30.903784+00:00"
  },
  {
    "id": "105e2721-f959-470d-aaf0-195b49ac4cc5",
    "question_text_en": "Which of the following are the two main architectures used in Word2Vec?",
    "question_text_ko": "다음 중 Word2Vec에 사용되는 두 가지 주요 아키텍처는 무엇입니까?",
    "options_en": [
      "Continuous Bag-of-Words (CBOW) and Skip-gram",
      "Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)",
      "Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs)",
      "Transformer and BERT"
    ],
    "options_ko": [
      "연속 백 오브 워드(CBOW) 및 스킵그램",
      "합성곱 신경망(CNN)과 순환 신경망(RNN)",
      "장단기 기억(LSTM) 및 게이트형 순환 단위(GRU)",
      "트랜스포머와 BERT"
    ],
    "correct_answer": 0,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.950442+00:00",
    "updated_at": "2025-11-29T14:15:30.950442+00:00"
  },
  {
    "id": "0f6a6817-6ce8-4bf4-baa8-63bb12670ca1",
    "question_text_en": "In the Continuous Bag-of-Words (CBOW) architecture of Word2Vec, what is the model trying to predict?",
    "question_text_ko": "Word2Vec의 CBOW(Continuous Bag-of-Words) 아키텍처에서 모델은 무엇을 예측하려고 합니까?",
    "options_en": [
      "The next word in a sentence.",
      "The missing word in a sentence given its surrounding context.",
      "The surrounding context words given a target word",
      "The sentiment of a sentence"
    ],
    "options_ko": [
      "문장의 다음 단어.",
      "주변 맥락을 고려했을 때 문장에서 빠진 단어.",
      "입력 단어가 주어졌을 때 주변 맥락 단어",
      "문장의 감정"
    ],
    "correct_answer": 1,
    "category": "Word Embeddings",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:30.984757+00:00",
    "updated_at": "2025-11-29T14:15:30.984757+00:00"
  },
  {
    "id": "7b6a7644-fd33-47bf-acfe-71ad4583a015",
    "question_text_en": "Which of the following best describes the nature of text data?",
    "question_text_ko": "다음 중 텍스트 데이터의 특성을 가장 잘 설명하는 것은 무엇입니까?",
    "options_en": [
      "Highly structured and uniform",
      "Unstructured and diverse",
      "Primarily numerical",
      "Limited to short sentences"
    ],
    "options_ko": [
      "고도로 구조화되고 규일함",
      "비구조적이고 다양함",
      "주로 숫자",
      "짧은 문장으로 제한됨"
    ],
    "correct_answer": 1,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.027704+00:00",
    "updated_at": "2025-11-29T14:15:31.027704+00:00"
  },
  {
    "id": "81c90433-1ce4-4a2e-ac60-b61165c1b2ff",
    "question_text_en": "Which key feature of sequence models enables them to excel at natural language processing tasks like machine translation, where understanding the context of words in a sentence is crucial?",
    "question_text_ko": "시퀀스 모델의 어떤 주요 특징이 기계 번역과 같은 자연어 처리 작업에서 탁월한 성과를 낼 수 있게 해주는가? 이 작업에서 문장 속 단어의 맥락을 이해하는 것이 중요하다.",
    "options_en": [
      "Capture Dependencies",
      "Handle Variable Length",
      "Predict Future Values",
      "Generate New Sequences"
    ],
    "options_ko": [
      "중축성 편차",
      "가변 길이 처리",
      "미래 가치 예측",
      "새로운 시퀀스 생성"
    ],
    "correct_answer": 0,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.068328+00:00",
    "updated_at": "2025-11-29T14:15:31.068328+00:00"
  },
  {
    "id": "8b13df30-32a6-4ba9-9d0e-150e5cd08eb3",
    "question_text_en": "In an RNN, how is the input at each time step processed?",
    "question_text_ko": "RNN에서 각 시간 단계의 입력은 어떻게 처리되나요?",
    "options_en": [
      "It is directly fed into the output layer.",
      "It is combined with the previous hidden state.",
      "It is processed independently of the previous hidden state.",
      "It is first passed through a convolutional layer."
    ],
    "options_ko": [
      "이는 출력 계층에 직접 공급됩니다.",
      "이는 이전의 숨겨진 상태와 결합됩니다.",
      "이는 이전의 숨겨진 상태와 독립적으로 처리됩니다.",
      "먼저 함성곱 계층을 통과합니다."
    ],
    "correct_answer": 1,
    "category": "RNNs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.122369+00:00",
    "updated_at": "2025-11-29T14:15:31.122369+00:00"
  },
  {
    "id": "f3a17e8d-4e46-432e-8667-f0fd68e5625d",
    "question_text_en": "Which of the following is NOT an application of RNNs in Natural Language Processing (NLP)?",
    "question_text_ko": "다음 중 자연어 처리(NLP)에 RNN을 적용한 것이 아닌 것은 무엇입니까?",
    "options_en": [
      "Machine translation",
      "Sentiment analysis",
      "Image recognition",
      "Text generation"
    ],
    "options_ko": [
      "기계 번역",
      "감정 분석",
      "이미지 인식",
      "텍스트 생성"
    ],
    "correct_answer": 2,
    "category": "RNNs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.165926+00:00",
    "updated_at": "2025-11-29T14:15:31.165926+00:00"
  },
  {
    "id": "a8f67902-4ed7-4738-b9c7-9358366fae86",
    "question_text_en": "Which of the following architectures are designed to mitigate the vanishing gradient problem? (Choose 2 Correct Answers)",
    "question_text_ko": "다음 아키텍처 중 어느 것이 그래디언트 소실 문제를 완화하도록 설계되었습니까? (정답 2개 선택)",
    "options_en": [
      "Convolutional Neural Networks (CNNs)",
      "Long Short-Term Memory (LSTM) networks",
      "Gated Recurrent Units (GRUs)",
      "Generative Adversarial Networks (GANs)",
      "Multilayer Perceptrons (MLPs)"
    ],
    "options_ko": [
      "합성곱 신경망(CNN)",
      "장단기 메모리(LSTM) 네트워크",
      "게이트형 순환 회로(GRU)",
      "생성적 적대 신경망(GAN)",
      "다층 퍼셉트론(MLP)"
    ],
    "correct_answer": 1,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.222356+00:00",
    "updated_at": "2025-11-29T14:15:31.222356+00:00"
  },
  {
    "id": "8ee14d74-57b1-4d38-9dfb-761dcb522972",
    "question_text_en": "What is the core issue in the vanishing gradient problem?",
    "question_text_ko": "사라지는 기울기 문제의 핵심 문제는 무엇입니까?",
    "options_en": [
      "Gradients become exponentially larger as they propagate backward through layers.",
      "Gradients become exponentially smaller as they propagate backward through layers.",
      "Gradients remain constant as they propagate backward through layers.",
      "Gradients fluctuate randomly as they propagate backward through layers."
    ],
    "options_ko": [
      "기울기는 레이어에 따라 뒤로 전달될수록 기하급수적으로 커집니다.",
      "기울기는 계층을 따라 뒤로 전달될수록 기하급수적으로 작아집니다.",
      "기울기는 레이어를 따라 뒤로 전달되면서도 일정하게 유지됩니다.",
      "기울기는 층을 따라 뒤로 전달되면서 무작위로 변동합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.263482+00:00",
    "updated_at": "2025-11-29T14:15:31.263482+00:00"
  },
  {
    "id": "e8022764-7ef8-4454-8330-4d98fcaf01b4",
    "question_text_en": "What is the key innovation introduced by the Transformer architecture?",
    "question_text_ko": "Transformer 아키텍처가 도입한 주요 혁신은 무엇입니까?",
    "options_en": [
      "Convolutional layers",
      "Recurrent neural networks",
      "Self-attention mechanisms",
      "Long short-term memory cells"
    ],
    "options_ko": [
      "합성곱 레이어",
      "순환 신경망",
      "자기 주의 메커니즘",
      "장기 단기 기억 셀"
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.306782+00:00",
    "updated_at": "2025-11-29T14:15:31.306782+00:00"
  },
  {
    "id": "05ac1b57-4657-4982-8072-ffcf4aa29407",
    "question_text_en": "What is the purpose of having multiple attention heads in Transformers?",
    "question_text_ko": "트랜스포머에 여러 개의 어텐션 헤더가 있는 목적은 무엇입니까?",
    "options_en": [
      "To increase the model's computational complexity",
      "To allow the model to focus on different aspects of the input simultaneously",
      "To reduce the number of parameters in the model",
      "To enable the model to process images and text data together"
    ],
    "options_ko": [
      "모델의 계산 복잡성을 높이려면",
      "모델이 입력의 다양한 부분에 동시에 집중할 수 있도록 하려면",
      "모델의 매개변수 수를 줄이려면",
      "모델이 이미지와 텍스트 데이터를 함께 처리할 수 있도록 하려면"
    ],
    "correct_answer": 1,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.346757+00:00",
    "updated_at": "2025-11-29T14:15:31.346757+00:00"
  },
  {
    "id": "78726705-abc0-418d-a81a-39d72359156a",
    "question_text_en": "What is the primary role of positional encoding in Transformers?",
    "question_text_ko": "트랜스포머에서 위치 인코딩의 주요 역할은 무엇입니까?",
    "options_en": [
      "To provide information about the absolute position of each word in the sequence.",
      "To enable the model to distinguish between different words in the vocabulary.",
      "To reduce the number of parameters in the model.",
      "To improve the model's ability to handle image data."
    ],
    "options_ko": [
      "시퀀스에서 각 단어의 절대 위치에 대한 정보를 제공합니다.",
      "모델이 입력의 순익 다양한 단어를 구별할 수 있도록 합니다.",
      "모델의 매개변수 수를 줄이려면.",
      "모델의 이미지 데이터 처리 능력을 향상시킵니다."
    ],
    "correct_answer": 0,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.411093+00:00",
    "updated_at": "2025-11-29T14:15:31.411093+00:00"
  },
  {
    "id": "5af18b5d-ce3a-4126-a722-7f8db8782449",
    "question_text_en": "How is positional encoding typically incorporated into the model's input?",
    "question_text_ko": "위치 인코딩은 일반적으로 어떻게 모델의 입력에 통합됩니까?",
    "options_en": [
      "It is used to replace the word embeddings entirely.",
      "It is fed into a separate network that generates attention masks.",
      "It is concatenated with the word embeddings.",
      "It is used to initialize the model's weights."
    ],
    "options_ko": [
      "이는 단어 임베딩을 완전히 대체하는 데 사용됩니다.",
      "이는 주의 마스크를 생성하는 별도의 네트워크에 입력됩니다.",
      "이는 단어 임베딩과 연결됩니다.",
      "모델의 가중치를 초기화하는 데 사용됩니다."
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.456369+00:00",
    "updated_at": "2025-11-29T14:15:31.456369+00:00"
  },
  {
    "id": "92d57649-72bf-4004-9f6a-df9d5c5c89f4",
    "question_text_en": "What is the primary challenge posed by the permutation-invariant nature of self-attention in Transformers when dealing with natural language?",
    "question_text_ko": "자연어를 다룰 때 트랜스포머에서 자기 주의의 순열 불변적 특성으로 인해 발생하는 주요 과제는 무엇입니까?",
    "options_en": [
      "It makes it difficult to capture long-range dependencies in a sentence.",
      "It prevents the model from distinguishing between synonyms.",
      "It makes it difficult to understand the relationships between words in a sentence.",
      "It leads to the model generating grammatically incorrect sentences."
    ],
    "options_ko": [
      "문맥이 장거리 종속성을 포함하기 어렵게 만듭니다.",
      "이로 인해 모델이 동일한 단어를 구별하지 못합니다.",
      "문장 속 단어 사이의 관계를 이해하는 것이 어렵습니다.",
      "이로 인해 모델이 문법적으로 잘못된 문장을 생성하게 됩니다."
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.504998+00:00",
    "updated_at": "2025-11-29T14:15:31.504998+00:00"
  },
  {
    "id": "c117ecb2-5355-4845-b86f-e16e1bfc5d9a",
    "question_text_en": "What is the primary purpose of memory cells in LSTMs?",
    "question_text_ko": "LSTM에서 메모리 셀의 주요 목적은 무엇입니까?",
    "options_en": [
      "To process input sequences in parallel.",
      "To introduce non-linearity into the network.",
      "To maintain long-term information across time steps.",
      "To regulate the learning rate during training."
    ],
    "options_ko": [
      "입력 시퀀스를 병렬로 처리합니다.",
      "네트워크의 비선형성을 도입합니다.",
      "시간 단위에 걸쳐 장기 정보를 유지합니다.",
      "훈련 중 학습률을 조절합니다."
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.547742+00:00",
    "updated_at": "2025-11-29T14:15:31.547742+00:00"
  },
  {
    "id": "09fdc6a6-e983-4749-965a-d0bfaf052b1a",
    "question_text_en": "What is the purpose of pre-training in LLM development?",
    "question_text_ko": "LLM 개발에서 사전 교육의 목적은 무엇입니까?",
    "options_en": [
      "To specialize the model for a specific task",
      "To teach the model general language patterns from diverse text sources",
      "To reduce the model's size",
      "To improve the model's inference speed"
    ],
    "options_ko": [
      "특정 작업에 맞게 모델을 전문화하려면",
      "다양한 텍스트 소스에서 모델 일반 언어 패턴을 가르치려면",
      "모델의 크기를 줄이려면",
      "모델의 추론 속도를 개선하려면"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.58989+00:00",
    "updated_at": "2025-11-29T14:15:31.58989+00:00"
  },
  {
    "id": "68fee0d7-f8e5-4611-b7f3-446592f52a57",
    "question_text_en": "What is the main purpose of a Transformer pipeline in Hugging Face's Transformers library?",
    "question_text_ko": "Hugging Face의 Transformers 라이브러리에서 Transformer 파이프라인의 주요 목적은 무엇입니까?",
    "options_en": [
      "To train a Transformer model from scratch.",
      "To fine-tune a pre-trained Transformer model on a specific task",
      "To simplify the process of applying pre-trained Transformer models to various NLP tasks",
      "To visualize the internal workings of a Transformer model"
    ],
    "options_ko": [
      "Transformer 모델을 처음부터 학습합니다.",
      "특정 작업에 대해서 사전 훈련된 Transformer 모델을 미세 조정하려면",
      "다양한 NLP 작업에 사전 훈련된 Transformer 모델을 적용하는 프로세스를 단순화하려면",
      "Transformer 모델의 내부 작동을 시각화하려면"
    ],
    "correct_answer": 2,
    "category": "Transformers",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.62335+00:00",
    "updated_at": "2025-11-29T14:15:31.62335+00:00"
  },
  {
    "id": "4e36e9df-9d63-4f4c-aacc-0579acbb66ce",
    "question_text_en": "When using a Hugging Face pipeline for text classification, what is the typical input?",
    "question_text_ko": "텍스트 분류에 Hugging Face 파이프라인을 사용할 때 일반적인 입력은 무엇입니까?",
    "options_en": [
      "A pre-trained LLM",
      "A list of text samples to be classified",
      "The desired output labels",
      "The path to a dataset"
    ],
    "options_ko": [
      "사전 훈련된 LLM",
      "분류할 텍스트 샘플 목록",
      "원하는 출력 레이블",
      "데이터 세트 경로"
    ],
    "correct_answer": 1,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.66341+00:00",
    "updated_at": "2025-11-29T14:15:31.66341+00:00"
  },
  {
    "id": "344bc5dd-b057-48e1-a189-b7c2a389a25b",
    "question_text_en": "What is a primary expectation from learning the fundamentals of machine learning?",
    "question_text_ko": "",
    "options_en": [
      "Understanding different machine learning algorithms and their applications",
      "Writing low-level assembly code for GPUs",
      "Developing new operating systems for AI workloads",
      "Designing hardware components for deep learning models"
    ],
    "options_ko": [],
    "correct_answer": 0,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.622821+00:00",
    "updated_at": "2025-11-29T14:15:32.622821+00:00"
  },
  {
    "id": "dd0832a9-7870-4fb6-8e38-c13d2ab3cfb0",
    "question_text_en": "What is the core principle behind Generative Adversarial Networks (GANs)?",
    "question_text_ko": "생성적 적대 신경망(GAN)의 핵심 원리는 무엇입니까?",
    "options_en": [
      "Two neural networks collaborate to create realistic content.",
      "One neural network learns to compress data, while another decompresses it.",
      "Two neural networks compete against each other, one generating content and the other evaluating its realism.",
      "A single neural network learns to predict the next word in a sequence."
    ],
    "options_ko": [
      "두 개의 신경망이 협력하여 사실적인 콘텐츠를 만듭니다.",
      "한 신경망은 데이터를 압축하는 법을 배우고, 다른 신경망은 압축을 해제합니다.",
      "두 개의 신경망이 서로 경쟁하는데, 하나는 콘텐츠를 생성하고 다른 하나는 콘텐츠의 현실성을 평가합니다.",
      "단일 신경망은 시퀀스의 다음 단계를 예측하는 법을 학습합니다."
    ],
    "correct_answer": 2,
    "category": "Model Architecture",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.7004+00:00",
    "updated_at": "2025-11-29T14:15:31.7004+00:00"
  },
  {
    "id": "beebd8cf-cd44-44a8-9320-fd48d81f51ba",
    "question_text_en": "Why is diversity crucial in the data used to train generative AI models?",
    "question_text_ko": "생성 시 모델을 훈련하는 데 사용되는 데이터에서 다양성이 왜 중요한가요?",
    "options_en": [
      "It helps the model avoid overfitting to specific patterns",
      "It makes the model more versatile and capable of generating a wider range of content",
      "It reduces the computational resources required for training",
      "It ensures the model's output is always factually accurate"
    ],
    "options_ko": [
      "이는 모델이 특정 패턴에 과도하게 맞춰지는 것을 방지하는 데 도움이 됩니다.",
      "이는 모델을 더욱 다재다능하게 만들고 더 광범위한 콘텐츠를 생성할 수 있게 해줍니다.",
      "훈련에 필요한 계산 리소스를 줄여줍니다.",
      "이는 모델의 출력이 항상 사실적으로 정확함을 보장합니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.732947+00:00",
    "updated_at": "2025-11-29T14:15:31.732947+00:00"
  },
  {
    "id": "553f5d54-f53d-492c-a6c4-58b645645b20",
    "question_text_en": "What is the advantage of incorporating texts from specific fields like medicine, law, or finance into LLM training data?",
    "question_text_ko": "의학, 법률, 금융 등 특정 분야의 텍스트를 LLM 교육 데이터에 통합하는 이점은 무엇입니까?",
    "options_en": [
      "It allows the model to develop specialized knowledge in those domains",
      "It improves the model's overall language understanding",
      "It speeds up the training process",
      "It enhances the model's ability to generate poetry"
    ],
    "options_ko": [
      "이를 통해 모델은 해당 도메인에 대한 전문 지식을 개발할 수 있습니다.",
      "모델의 전반적인 언어 이해도가 향상됩니다.",
      "훈련 과정을 가속화합니다.",
      "이는 모델의 생성 능력을 향상시킵니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.795149+00:00",
    "updated_at": "2025-11-29T14:15:31.795149+00:00"
  },
  {
    "id": "8cb46c3c-8d8a-44f6-9f49-1b98df9a8048",
    "question_text_en": "What is a direct consequence of training Large Language Models (LLMs) on poor-quality data?",
    "question_text_ko": "품질이 낮은 데이터로 대규모 언어 모델(LLM)을 훈련하면 직접적인 결과는 무엇입니까?",
    "options_en": [
      "Improved accuracy and reliability.",
      "Increased generalization to new information.",
      "Inaccurate outputs and biased responses.",
      "Faster training times and reduced computational costs."
    ],
    "options_ko": [
      "정확도와 신뢰성이 향상되었습니다.",
      "새로운 정보에 대한 일반화가 강해졌습니다.",
      "부정확한 출력과 편향된 응답.",
      "훈련 시간과 단축되고 계산 비용이 절감됩니다."
    ],
    "correct_answer": 2,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.840695+00:00",
    "updated_at": "2025-11-29T14:15:31.840695+00:00"
  },
  {
    "id": "0dcafc09-0b9c-46a1-bc36-95ebed3c3fd0",
    "question_text_en": "How does NVIDIA contribute to the data pipeline for AI tasks?",
    "question_text_ko": "NVIDIA 사 작업을 위한 데이터 파이프라인이 어떻게 기여합니까?",
    "options_en": [
      "By manually curating training datasets for AI models",
      "By enabling GPU acceleration and distributed computing for data processing",
      "By replacing the need for diverse training data through AI simulations",
      "By focusing only on hardware and not on AI data pipelines"
    ],
    "options_ko": [
      "AI 모델 훈련을 위한 데이터 세트를 수동으로 큐레이팅하여",
      "데이터 처리를 위한 GPU 가속 및 분산 컴퓨팅을 활성화함으로써",
      "AI 시뮬레이션을 통해 다양한 효과의 데이터의 필요성을 대체함으로써",
      "AI 데이터 파이프라인이 아닌 하드웨어에만 집중함으로써"
    ],
    "correct_answer": 1,
    "category": "AI Infrastructure",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.886849+00:00",
    "updated_at": "2025-11-29T14:15:31.886849+00:00"
  },
  {
    "id": "66f1dd97-cc8c-4051-95a1-a7cf4f4b6ec6",
    "question_text_en": "What are the key challenges of feeding poor-quality data to large language models (LLMs)?",
    "question_text_ko": "품질이 낮은 데이터를 대규모 언어 모델(LLM)에 공급하는 데 있어 주요 과제는 무엇입니까?",
    "options_en": [
      "It improves the model’s ability to generalize new information.",
      "It results in inaccurate outputs, biased responses, and unreliable predictions.",
      "It has no impact on the performance of LLMs.",
      "It speeds up the training process of LLMs."
    ],
    "options_ko": [
      "이는 새로운 정보에 대한 모델의 능력을 향상시킵니다.",
      "그 결과 편향된 출력, 편향된 응답, 신뢰할 수 없는 예측이 발생합니다.",
      "이는 LLM의 성능에 영향을 미치지 않습니다.",
      "LLM의 교육 과정이 빨라집니다."
    ],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.929925+00:00",
    "updated_at": "2025-11-29T14:15:31.929925+00:00"
  },
  {
    "id": "a2599003-ac81-44a5-a50d-43cd66fd6fa7",
    "question_text_en": "What does \"zero-shot learning\" refer to in the context of LLMs?",
    "question_text_ko": "1. LLM에서 '제로샷 러닝'이란 무엇을 의미합니까?",
    "options_en": [
      "The model's ability to learn new tasks without any prior examples or training.",
      "The model's ability to perform tasks with zero errors.",
      "The initial stage of training where the model has no knowledge.",
      "The process of fine-tuning the model on a specific task."
    ],
    "options_ko": [
      "① 모델은 사전 지식나 훈련 없이도 새로운 작업을 학습할 수 있는 능력을 갖추고 있습니다.",
      "② 모델이 오류 없이 작업을 수행할 수 있는 능력입니다.",
      "③ 모델이 아무런 지식도 가지고 있지 않은 환경의 초기 단계입니다.",
      "④ 특정 작업에 맞게 모델을 미세 조정하는 과정입니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:31.982697+00:00",
    "updated_at": "2025-11-29T14:15:31.982697+00:00"
  },
  {
    "id": "6a37c64c-bea4-4fb5-a9fa-cbec4fc59405",
    "question_text_en": "What is the core principle behind few-shot learning in Large Language Models (LLMs)?",
    "question_text_ko": "2. 대규모 언어 모델(LLM)에서 퓨샷 학습의 핵심 원리는 무엇입니까?",
    "options_en": [
      "LLMs require massive amounts of labeled data to learn any task.",
      "LLMs can learn to perform tasks by observing only a few examples or demonstrations.",
      "LLMs can only generate text, not understand or classify it.",
      "LLMs are incapable of adapting to new tasks without extensive retraining."
    ],
    "options_ko": [
      "① LLM은 어떤 작업을 학습하기 위해 엄청난 양의 레이블이 지정된 데이터가 필요합니다.",
      "② LLM은 몇 가지 예시만 관찰해도 작업을 수행하는 방법을 배울 수 있습니다.",
      "③ LLM은 텍스트를 생성할 수만 있고 이해하거나 분류할 수는 없습니다.",
      "④ LLM은 광범위한 재교육 없이는 새로운 업무에 적용할 수 없습니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.039392+00:00",
    "updated_at": "2025-11-29T14:15:32.039392+00:00"
  },
  {
    "id": "4ab34669-bec9-4673-ae1f-76930fa8247d",
    "question_text_en": "How does instruction fine-tuning improve the performance of LLMs?",
    "question_text_ko": "3. 교육 세부 조정을 통해 LLM의 성과가 어떻게 향상됩니까?",
    "options_en": [
      "It increases the model's size and complexity",
      "It enables the model to understand and follow instructions more accurately.",
      "It makes the model more creative and capable of generating diverse outputs.",
      "It reduces the need for large-scale pre-training"
    ],
    "options_ko": [
      "① 모델의 크기와 복잡성이 증가합니다.",
      "② 이를 통해 모델의 지식을 더 정확하게 이해하고 따를 수 있습니다.",
      "③ 이를 통해 모델은 더욱 창의적이 되고 다양한 결과물을 생성할 수 있습니다.",
      "④ 대규모 사전 훈련의 필요성이 줄어듭니다."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.077808+00:00",
    "updated_at": "2025-11-29T14:15:32.077808+00:00"
  },
  {
    "id": "dbc22f43-24cc-49e8-bc78-8b7af525e03b",
    "question_text_en": "What does cross-entropy loss measure in the context of LLMs?",
    "question_text_ko": "4. LLM 맥락에서 교차 엔트로피 손실은 무엇을 측정합니까?",
    "options_en": [
      "The difference between predicted and actual numerical values.",
      "The dissimilarity between the predicted probability distribution of words and the actual distribution in the training data",
      "The margin between correct and incorrect classifications.",
      "The distance between two probability distributions."
    ],
    "options_ko": [
      "① 예측된 수치와 실제 수치의 차이.",
      "② 예측된 단어의 확률 분포와 훈련 데이터에서의 실제 분포의 차이",
      "③ 올바른 분류와 잘못된 분류 사이의 차이.",
      "④ 두 확률 분포 사이의 거리."
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.118427+00:00",
    "updated_at": "2025-11-29T14:15:32.118427+00:00"
  },
  {
    "id": "9703b757-9c9a-4d59-bc5d-2a3b57bd859b",
    "question_text_en": "What is the primary goal of LLM alignment?",
    "question_text_ko": "LLM 정의의 주요 목표는 무엇입니까?",
    "options_en": [
      "Maximizing the accuracy of language models on benchmark datasets.",
      "Making sure LLMs generate the most creative and entertaining responses possible.",
      "Ensuring that the behavior and outputs of LLMs are in line with human values, preferences, and ethical principles",
      "Reducing the computational resources required to train LLMs."
    ],
    "options_ko": [
      "벤치마크 데이터 세트에서 얻어진 모델의 정확도를 극대화합니다.",
      "LLM이 가능한 한 가장 창의적이고 재미있는 답변을 낼 수 있도록 보장합니다.",
      "LLM 행동의 결과가 인간의 가치, 신뢰도 및 윤리 원칙에 부합하는지 확인합니다.",
      "LLM을 훈련하는 데 필요한 컴퓨팅 리소스를 줄입니다."
    ],
    "correct_answer": 2,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.161703+00:00",
    "updated_at": "2025-11-29T14:15:32.161703+00:00"
  },
  {
    "id": "808a5f73-0dde-4e75-8686-e2659e519435",
    "question_text_en": "Which aspect of LLM output evaluation focuses on the grammatical correctness and natural flow of the generated text?",
    "question_text_ko": "LLM 결과를 평가할 어떤 측정이 생성된 텍스트의 문법적 정확성과 자연스러운 흐름에 초점을 맞춥니까?",
    "options_en": [
      "Accuracy",
      "Fluency",
      "Relevance",
      "Coherence"
    ],
    "options_ko": [
      "정확성",
      "유창성",
      "관련성",
      "통일"
    ],
    "correct_answer": 1,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.198361+00:00",
    "updated_at": "2025-11-29T14:15:32.198361+00:00"
  },
  {
    "id": "ff380534-67d6-44a1-bc08-8c9b3c17213a",
    "question_text_en": "A lower perplexity score indicates:",
    "question_text_ko": "낮은 등차도 점수는 다음을 나타냅니다.",
    "options_en": [
      "The model is less confident in its predictions.",
      "The model is more likely to produce grammatically incorrect sentences.",
      "The model is better at predicting the next word in a sequence.",
      "The model is less suitable for language generation tasks."
    ],
    "options_ko": [
      "해당 모델은 예측에 대한 신뢰도가 낮습니다.",
      "이 모델은 문맥적으로 관련성 있는 문장을 생성할 가능성이 더 높습니다.",
      "이 모델은 시퀀스의 다음 단어를 예측하는 데 더 뛰어납니다.",
      "이 모델은 언어 생성 작업에 적합하지 않습니다."
    ],
    "correct_answer": 2,
    "category": "NLP",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.241008+00:00",
    "updated_at": "2025-11-29T14:15:32.241008+00:00"
  },
  {
    "id": "f83cce4b-c5f4-4209-b5cb-8efef5f69c02",
    "question_text_en": "Why is human feedback crucial in identifying biases in LLM outputs?",
    "question_text_ko": "LLM 결과문의 함량을 파악하는 데 인간의 피드백이 왜 중요한가요?",
    "options_en": [
      "Humans are better at detecting subtle biases and nuances in language than automated systems.",
      "Humans can provide large amounts of labeled data for retraining LLMs.",
      "Humans are immune to biases and can therefore provide perfectly objective feedback.",
      "Human feedback is the only way to evaluate the performance of LLMs."
    ],
    "options_ko": [
      "언어를 자동화된 시스템보다 언어 속의 미묘한 편차와 차 nuance를 더 잘 감지합니다.",
      "인간은 LLM을 추적하여 학습의 레이블이 지정된 데이터피드백을 제공할 수 있습니다.",
      "인간은 환경에 맞게 있음으로 존엄함하면서 객관적인 피드백을 제공할 수 있습니다.",
      "LLM의 성과를 평가할 수 있는 유일한 방법은 인간의 피드백입니다."
    ],
    "correct_answer": 0,
    "category": "LLMs",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.278882+00:00",
    "updated_at": "2025-11-29T14:15:32.278882+00:00"
  },
  {
    "id": "24c47503-e079-42a7-b602-e4e7bfd384b1",
    "question_text_en": "GPUs possess dedicated high-bandwidth memory. What benefit does this provide during LLM training?",
    "question_text_ko": "GPU는 적은 그래픽 메모리를 가지고 있습니다. 이는 LLM 학습 중에 어떤 이점을 제공합니까?",
    "options_en": [
      "Enables faster data transfer between the CPU and GPU",
      "Allows for the storage of larger LLM models",
      "Reduces the overall power consumption of the system",
      "Facilitates quick access and processing of vast amounts of training data"
    ],
    "options_ko": [
      "CPU와 GPU 간의 더 빠른 데이터 전송을 가능하게 합니다.",
      "더 큰 LLM 모델을 저장할 수 있습니다.",
      "시스템의 전체 전력을 절감할 수 있습니다.",
      "대량의 입력 교육 데이터에 대한 빠른 검색 및 처리를 용이하게 합니다."
    ],
    "correct_answer": 3,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.332375+00:00",
    "updated_at": "2025-11-29T14:15:32.332375+00:00"
  },
  {
    "id": "2354f6d2-072e-47f6-b0d7-503b0d42a62e",
    "question_text_en": "What is the role of 'Data' in machine learning?",
    "question_text_ko": "머신러닝에서 '데이터'의 역할은 무엇인가요?",
    "options_en": [
      "It provides the examples and patterns the model learns from.",
      "It acts as the brain of the model.",
      "It determines the accuracy of the model.",
      "It has no significant role in machine learning."
    ],
    "options_ko": [
      "모델이 학습할 예제와 패턴을 제공합니다.",
      "이는 모델의 틀이나 역할을 합니다.",
      "이는 모델의 정체성을 결정합니다.",
      "머신러닝에서는 중요한 역할이 없습니다."
    ],
    "correct_answer": 0,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.372564+00:00",
    "updated_at": "2025-11-29T14:15:32.372564+00:00"
  },
  {
    "id": "92730fcb-d58a-4615-b3fe-a50eb48e74cd",
    "question_text_en": "In the context of predicting house sale prices, what is the role of the 'Algorithm'?",
    "question_text_ko": "주택 매매 가격을 예측하는 머신러닝에서 '출력값(목표)'의 역할은 무엇인가요?",
    "options_en": [
      "It represents the final predicted sale price of the house.",
      "It is the data used to train the model, such as square footage and number of bedrooms.",
      "It is the specific machine learning model (e.g., linear regression, decision tree) that learns the relationship between features like square footage and the sale price.",
      "It refers to the process of selecting and transforming features, such as creating a new feature that combines square footage and a number of bedrooms."
    ],
    "options_ko": [
      "이는 주택의 실제 매매 가격을 나타냅니다.",
      "모델을 훈련하는 데 사용되는 데이터로, 입력값 될 수 없이 있습니다.",
      "이는 현재의 판매 가격 및 동의 환경을 예측하는 특정 머신 러닝 모델(예: 선형 회귀, 의사결정 트리)입니다.",
      "이는 현재의 정보 수끌 결합된 새로운 특징을 만드는 것과 같이 특징을 선택하고 변형하는 과정을 말합니다."
    ],
    "correct_answer": 2,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.431098+00:00",
    "updated_at": "2025-11-29T14:15:32.431098+00:00"
  },
  {
    "id": "8285ae82-a279-4ea0-a621-ca6083a37f7d",
    "question_text_en": "Which of the following utilizes artificial neural networks with multiple layers to learn complex patterns in data?",
    "question_text_ko": "다음 중 여러 층으로 구성된 인공 신경망을 활용하여 데이터의 복잡한 패턴을 학습하는 것은 무엇입니까?",
    "options_en": [
      "Deep Learning",
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics"
    ],
    "options_ko": [
      "딥러닝",
      "인공지능",
      "C-머신 러닝",
      "초보자 학습"
    ],
    "correct_answer": 0,
    "category": "Deep Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.488048+00:00",
    "updated_at": "2025-11-29T14:15:32.488048+00:00"
  },
  {
    "id": "f98d192c-6aa4-43a5-b06a-c12df4dfe108",
    "question_text_en": "In which type of machine learning does the algorithm learn from labeled data, where the correct output is provided for each input example?",
    "question_text_ko": "각 입력 데이터에 대해 올바른 출력이 레이블이 지정된 데이터에서 알고리즘이 학습하는 머신 러닝 유형은 무엇입니까?",
    "options_en": [
      "Unsupervised Learning",
      "Supervised Learning",
      "Reinforcement Learning",
      "Transfer Learning"
    ],
    "options_ko": [
      "비지도 학습",
      "지도 학습",
      "C-강화 학습",
      "전이 학습"
    ],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.529472+00:00",
    "updated_at": "2025-11-29T14:15:32.529472+00:00"
  },
  {
    "id": "c2f29fdb-b339-4f3b-98f2-37f7161fa481",
    "question_text_en": "Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?",
    "question_text_ko": "",
    "options_en": [
      "AI is a subset of Deep Learning, which is a subset of Machine Learning",
      "Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning",
      "Machine Learning and Deep Learning are completely separate from AI",
      "Deep Learning is a broader concept that includes both AI and Machine Learning"
    ],
    "options_ko": [],
    "correct_answer": 1,
    "category": "Machine Learning Fundamentals",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.669555+00:00",
    "updated_at": "2025-11-29T14:15:32.669555+00:00"
  },
  {
    "id": "6935da89-1673-455f-a355-60d42b3e08dc",
    "question_text_en": "Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False",
    "question_text_ko": "",
    "options_en": [
      "True",
      "False"
    ],
    "options_ko": [],
    "correct_answer": 0,
    "category": "Reinforcement Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.709776+00:00",
    "updated_at": "2025-11-29T14:15:32.709776+00:00"
  },
  {
    "id": "8f214e2b-f2d4-4590-b951-fad174c89300",
    "question_text_en": "What is the primary purpose of feature scaling in machine learning?",
    "question_text_ko": "",
    "options_en": [
      "It improves the interpretability of categorical data",
      "It prevents certain features from dominating others due to different scales",
      "It removes duplicate rows from the dataset",
      "It eliminates the need for model validation"
    ],
    "options_ko": [],
    "correct_answer": 1,
    "category": "Training Techniques",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.756338+00:00",
    "updated_at": "2025-11-29T14:15:32.756338+00:00"
  },
  {
    "id": "badf9dd6-ef61-4715-8c09-b5dc7678affb",
    "question_text_en": "What is the purpose of StandardScaler() in sklearn.preprocessing?",
    "question_text_ko": "",
    "options_en": [
      "It converts categorical variables into numerical values",
      "It normalizes features by scaling them between 0 and 1",
      "It standardizes features by removing the mean and scaling to unit variance",
      "It replaces missing values in a dataset"
    ],
    "options_ko": [],
    "correct_answer": 2,
    "category": "Preprocessing",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:15:32.794263+00:00",
    "updated_at": "2025-11-29T14:15:32.794263+00:00"
  },
  {
    "id": "13df0df3-41f6-4bfb-9bc0-976714ce7725",
    "question_text_en": "What is a primary expectation from learning the fundamentals of machine learning?",
    "question_text_ko": "머신 러닝의 기본을 배우는 데 있어 가장 기대되는 것은 무엇입니까?",
    "options_en": [
      "Understanding different machine learning algorithms and their applications",
      "Writing low-level assembly code for GPUs",
      "Developing new operating systems for AI workloads",
      "Designing hardware components for deep learning models"
    ],
    "options_ko": [
      "다양한 머신 러닝 알고리즘과 그 응용 프로그램의 이해",
      "GPU와 최적화 연관성을 빠르게 적기",
      "새 워크로드를 위한 새로운 운영 체제 개발",
      "머신 러닝 모델을 위한 하드웨어 구성 요소 설계"
    ],
    "correct_answer": 0,
    "category": "Machine Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:21:58.853892+00:00",
    "updated_at": "2025-11-29T14:21:58.853892+00:00"
  },
  {
    "id": "245f67e5-f339-4958-89f1-4549c7ca0b6c",
    "question_text_en": "Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?",
    "question_text_ko": "다음 중 AI, 머신러닝, 딥러닝의 관계를 가장 잘 설명하는 것은 무엇입니까?",
    "options_en": [
      "AI is a subset of Deep Learning, which is a subset of Machine Learning",
      "Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning",
      "Machine Learning and Deep Learning are completely separate from AI",
      "Deep Learning is a broader concept that includes both AI and Machine Learning"
    ],
    "options_ko": [
      "AI는 머신 러닝에 의해 완전히 구현된 기술입니다.",
      "머신 러닝은 AI의 하위 집합이고 딥 러닝은 머신 러닝의 하위 집합입니다.",
      "머신러닝과 딥러닝은 AI와 완전히 별개입니다.",
      "딥러닝은 AI와 머신러닝을 모두 포함하는 더 광범위한 개념입니다."
    ],
    "correct_answer": 1,
    "category": "Machine Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:21:59.097227+00:00",
    "updated_at": "2025-11-29T14:21:59.097227+00:00"
  },
  {
    "id": "911c652d-ca6c-4ac4-bf69-2912fb0c6c57",
    "question_text_en": "Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False",
    "question_text_ko": "강화 학습은 에이전트가 환경과 상호 작용하고 보상이나 페널티를 받아 학습하는 것을 포함합니다. 참 또는 거짓을 나타냅니다.",
    "options_en": [
      "True",
      "False"
    ],
    "options_ko": [
      "진실",
      "거짓"
    ],
    "correct_answer": 0,
    "category": "Reinforcement Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:21:59.194326+00:00",
    "updated_at": "2025-11-29T14:21:59.194326+00:00"
  },
  {
    "id": "872fe74a-a399-47ce-8e04-1bee3aae95bd",
    "question_text_en": "What is the primary purpose of feature scaling in machine learning?",
    "question_text_ko": "머신 러닝에서 기능 스케일링의 주요 목적은 무엇입니까?",
    "options_en": [
      "It improves the interpretability of categorical data",
      "It prevents certain features from dominating others due to different scales",
      "It removes duplicate rows from the dataset",
      "It eliminates the need for model validation"
    ],
    "options_ko": [
      "반응형 데이터를 핵심적으로 향상시킵니다.",
      "이는 다른 규모의 연속 특징이 다른 기능과 기울기를 지배하는 것을 방지합니다.",
      "데이터의 세트에서 정확 복사를 피합니다.",
      "모델 검증의 필요성이 없습니다."
    ],
    "correct_answer": 1,
    "category": "Machine Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:21:59.290472+00:00",
    "updated_at": "2025-11-29T14:21:59.290472+00:00"
  },
  {
    "id": "e8f9dad4-0570-40d7-b206-b08df6c0fa5d",
    "question_text_en": "What is the purpose of StandardScaler() in sklearn.preprocessing?",
    "question_text_ko": "sklearn.preprocessing에서 StandardScaler()의 목적은 무엇입니까?",
    "options_en": [
      "It converts categorical variables into numerical values",
      "It normalizes features by scaling them between 0 and 1",
      "It standardizes features by removing the mean and scaling to unit variance",
      "It replaces missing values in a dataset"
    ],
    "options_ko": [
      "반응형 변수를 숫자 값으로 변환합니다.",
      "0과 1 사이의 스케일링으로 기능을 정규화합니다.",
      "평균과 표준편차로 입력 변수를 스케일링하여 기능을 표준화합니다.",
      "데이터 세트에서 누락된 값을 대체합니다."
    ],
    "correct_answer": 2,
    "category": "Machine Learning",
    "difficulty": "medium",
    "source_day": null,
    "source_image_en": null,
    "source_image_ko": null,
    "created_at": "2025-11-29T14:21:59.381446+00:00",
    "updated_at": "2025-11-29T14:21:59.381446+00:00"
  }
]
