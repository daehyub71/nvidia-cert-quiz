# NVIDIA Generative AI LLMs Certification Quiz Questions

Total Questions: 302

---

## Question 1

**Category:** Model Optimization
**Difficulty:** medium

### English

Which technique involves reducing the precision of model parameters to achieve a smaller model size and faster inference?

1. [ ] Pruning
2. [✓] Quantization
3. [ ] Knowledge Distillation
4. [ ] Transfer Learning

### 한국어

어떤 기술이 모델 매개변수의 정밀도를 낮춰 더 작은 모델 크기와 더 빠른 추론을 달성하는 것일까요?

1. [ ] 전정
2. [✓] 양자화
3. [ ] 지식 증류
4. [ ] 전이 학습

**Correct Answer:** 2

---

## Question 2

**Category:** ONNX
**Difficulty:** medium

### English

How does ONNX act as an "interoperability bridge"?

1. [ ] It translates code between different programming languages used in machine learning.
2. [✓] It enables seamless exchange and deployment of models across various frameworks and hardware platforms.
3. [ ] It creates a standardized API for interacting with all machine learning models.
4. [ ] It provides a cloud-based platform for storing and sharing machine learning models.

### 한국어

ONNX는 어떻게 '상호운용성 브리지' 역할을 하나요?

1. [ ] 머신 러닝에 사용되는 다양한 프로그래밍 언어 간의 코드를 번역합니다.
2. [✓] 다양한 프레임워크와 하드웨어 플랫폼에서 모델을 원활하게 교환하고 배포할 수 있습니다.
3. [ ] 모든 머신 러닝 모델과 상호작용하기 위한 표준화된 API를 만듭니다.
4. [ ] 머신 러닝 모델을 저장하고 공유하기 위한 클라우드 기반 플랫폼을 제공합니다.

**Correct Answer:** 2

---

## Question 3

**Category:** ONNX
**Difficulty:** medium

### English

What is the key benefit of using ONNX Runtime?

1. [ ] It simplifies the process of training machine learning models.
2. [✓] It optimizes model execution for improved performance across diverse platforms.
3. [ ] It automatically generates synthetic data for training models.
4. [ ] It ensures that all models achieve the same level of accuracy.

### 한국어

ONNX 런타임을 사용하는 주요 이점은 무엇입니까?

1. [ ] 머신 러닝 모델을 실행하는 과정을 간소화합니다.
2. [✓] 다양한 플랫폼에서 성능을 향상시키기 위해 모델 실행을 최적화합니다.
3. [ ] 모델을 훈련하기 위한 합성 데이터를 자동으로 생성합니다.
4. [ ] 이를 통해 모든 모델이 동일한 수준의 정확도를 달성할 수 있습니다.

**Correct Answer:** 2

---

## Question 4

**Category:** Model Evaluation
**Difficulty:** medium

### English

What is meant by "model drift" in the context of large language models (LLMs)?

1. [ ] The model's ability to adapt to new language patterns over time.
2. [✓] The gradual decrease in a model's accuracy and effectiveness due to changes in data distribution
3. [ ] The tendency of a model to generate biased or harmful content
4. [ ] The process of fine-tuning a pre-trained model on a specific task.

### 한국어

대규모 언어 모델(LLM)의 맥락에서 '모델 드리프트'란 무엇을 의미합니까?

1. [ ] 시간이 지남에 따라 새로운 언어 패턴에 적응할 수 있는 모델의 능력.
2. [✓] 데이터의 분포가 변화로 인해 모델의 정확도와 효과성이 점차 감소하는 현상
3. [ ] 모델이 편향적이거나 유해한 콘텐츠를 생성하는 경향
4. [ ] 특정 작업에 맞춰 사전 학습된 모델을 미세 조정하는 과정입니다.

**Correct Answer:** 2

---

## Question 5

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

The F1 Score is calculated as the:

1. [ ] Arithmetic mean of precision and recall
2. [✓] Harmonic mean of precision and recall
3. [ ] Product of precision and recall
4. [ ] Difference between precision and recall

### 한국어

F1 점수는 다음과 같이 계산됩니다.

1. [ ] 정밀도와 재현율의 산술 평균
2. [✓] 정밀도와 재현율의 조화 평균
3. [ ] 정밀도와 재현율의 차이
4. [ ] 정밀도와 재현율의 곱

**Correct Answer:** 2

---

## Question 6

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary focus of NVIDIA AI Enterprise?

1. [ ] Developing cutting-edge hardware for AI research.
2. [✓] Providing a comprehensive platform for the entire AI model lifecycle.
3. [ ] Exclusively focusing on large language model (LLM) development.
4. [ ] Creating open-source AI frameworks and libraries.

### 한국어

NVIDIA AI Enterprise의 주요 초점은 무엇입니까?

1. [ ] AI 연구를 위한 최첨단 하드웨어 개발
2. [✓] AI 모델 수명 주기 전반에 대한 포괄적인 플랫폼을 제공합니다.
3. [ ] 대규모 언어 모델(LLM) 개발에만 집중합니다.
4. [ ] 오픈소스 프레임워크와 라이브러리를 만듭니다.

**Correct Answer:** 2

---

## Question 7

**Category:** Model Deployment
**Difficulty:** medium

### English

Which of the following is a common deployment strategy for Large Language Models (LLMs)?

1. [✓] Deploying the model as a cloud-based API
2. [ ] Running the model only on local machines without any networking
3. [ ] Avoiding scaling considerations for inference
4. [ ] Using only on-premises hardware with no updates

### 한국어

다음 중 대규모 언어 모델(LLM)에 대한 일반적인 배포 전략은 무엇입니까?

1. [✓] 모델을 클라우드 기반 API로 배포
2. [ ] 네트워크 없이 로컬 머신에서 모델 실행
3. [ ] 추론을 위한 스케일링 고려 사항 피하기
4. [ ] 업데이트 없이 온프레미스 하드웨어만 사용

**Correct Answer:** 1

---

## Question 8

**Category:** Monitoring and Evaluation
**Difficulty:** medium

### English

Which of the following is a common metric used to monitor LLMs in production?

1. [ ] Number of training epochs
2. [✓] Response latency
3. [ ] Model parameter count
4. [ ] Number of layers in the neural network

### 한국어

다음 중 프로덕션에서 LLM을 모니터링하는 데 사용되는 일반적인 지표는 무엇입니까?

1. [ ] 훈련 에포크 수
2. [✓] 응답 지연 시간
3. [ ] 모델 매개변수 개수
4. [ ] 신경망의 계층 수

**Correct Answer:** 2

---

## Question 9

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary benefit of using NVIDIA’s ecosystem for LLM deployment?

1. [✓] Hardware-accelerated inference and training for high-efficiency
2. [ ] Completely replacing deep learning frameworks like PyTorch and TensorFlow
3. [ ] Eliminating the need for cloud-based deployments
4. [ ] Avoiding AI model fine-tuning

### 한국어

LLM 배포에 NVIDIA의 생태계를 사용하는 주요 이점은 무엇입니까?

1. [✓] 고효율을 위한 하드웨어 가속을 통한 학습
2. [ ] PyTorch나 TensorFlow와 같은 딥러닝 프레임워크를 완전히 대체
3. [ ] 클라우드 기반 배포의 필요성 제거
4. [ ] AI 모델 미세 조정 방지

**Correct Answer:** 1

---

## Question 10

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is the primary purpose of prompt engineering?

1. [ ] To train an AI language model from scratch
2. [✓] To unlock the full potential of an AI language model and get the best possible results
3. [ ] To replace human writers with AI
4. [ ] To limit the capabilities of an AI language model

### 한국어

신속한 엔지니어링의 주요 목적은 무엇입니까?

1. [ ] AI 언어 모델을 처음부터 훈련하려면
2. [✓] AI 언어 모델의 잠재력을 최대한 활용하여 최상의 결과를 얻으려면
3. [ ] 인간 작가를 새로 대체하기 위해
4. [ ] AI 언어 모델의 기능을 제한하려면

**Correct Answer:** 2

---

## Question 11

**Category:** Model Evaluation Metrics
**Difficulty:** medium

### English

In a scenario where even small errors can have significant consequences, which metric would you pay more attention to?

1. [✓] MAE
2. [ ] RMSE
3. [ ] R-squared
4. [ ] It depends on the specific context.

### 한국어

2. 아무리 작은 오류라도 중대한 결과를 초래할 수 있는 상황에서 어떤 지표에 더 많은 주의를 기울여야 할까요?

1. [✓] 정확도
2. [ ] RMSE
3. [ ] R제곱
4. [ ] 이는 구체적인 상황에 따라 달라집니다.

**Correct Answer:** 1

---

## Question 12

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is prompt design in the context of AI language models?

1. [ ] A random process of generating input for the model
2. [✓] The art of crafting clear and specific instructions to guide the AI's output
3. [ ] A complex coding language used to program AI models
4. [ ] A method for limiting the AI's capabilities

### 한국어

AI 언어 모델의 맥락에서 신속한 디자인이란 무엇인가?

1. [ ] 모델에 대한 입력을 생성하는 무작위 프로세스
2. [✓] AI의 출력을 안내하기 위한 명확하고 구체적인 지침을 작성하는 기술
3. [ ] AI 모델을 프로그래밍하는 데 사용되는 복잡한 코딩 언어
4. [ ] AI의 역할을 제한하는 방법

**Correct Answer:** 2

---

## Question 13

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is the primary purpose of providing context in prompts for AI language models?

1. [ ] To confuse the AI and test its capabilities
2. [✓] To guide the AI's understanding and steer its output in the desired direction
3. [ ] To make the prompt longer and more complex
4. [ ] To provide the AI with irrelevant information

### 한국어

AI 언어 모델의 프롬프트에서 맥락을 제공하는 주된 목적은 무엇입니까?

1. [ ] AI를 훈련스럽게 하고 그 능력을 테스트하기 위해
2. [✓] AI의 이해를 안내하고 원하는 방향으로 출력을 조정합니다.
3. [ ] 프롬프트를 더 길고 복잡하게 만들려면
4. [ ] AI에게 관련 없는 정보를 제공하기 위해

**Correct Answer:** 2

---

## Question 14

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary goal of PEFT in the context of large language models (LLMs)?

1. [ ] To train a new LLM from scratch
2. [✓] To efficiently adapt pre-trained LLMs to specific tasks
3. [ ] To reduce the size of pre-trained LLMs
4. [ ] To improve the general language understanding of LLMs

### 한국어

대규모 언어 모델(LLM)의 맥락에서 PET의 주요 목표는 무엇입니까?

1. [ ] 새로운 LLM을 처음부터 교육하려면
2. [✓] 사전 훈련된 LLM을 특정 작업에 효율적으로 적용하려면
3. [ ] 사전 훈련된 LLM의 크기를 줄이려면
4. [ ] LLM의 일반적인 언어 이해력을 향상시키기 위해

**Correct Answer:** 2

---

## Question 15

**Category:** Natural Language Processing
**Difficulty:** medium

### English

What is the primary focus of prompt learning in natural language processing?

1. [ ] Training language models from scratch on massive datasets
2. [ ] Improving the general language understanding capabilities of language models
3. [✓] Teaching language models to better understand and respond to instructions or prompts
4. [ ] Reducing the size of pre-trained language models

### 한국어

자연어 처리에서 신속한 학습의 주요 초점은 무엇입니까?

1. [ ] 대규모 데이터 세트를 기반으로 처음부터 언어 모델 학습
2. [ ] 언어 모델의 일반 언어 이해 능력 향상
3. [✓] 지나친 프로프트를 더 잘 이해하고 이에 대응하기 위한 언어 모델 교육
4. [ ] 사전 학습된 언어 모델의 크기 줄이기

**Correct Answer:** 3

---

## Question 16

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA NeMo?

1. [ ] To create realistic images and videos
2. [✓] To simplify and accelerate the development and deployment of conversational AI models
3. [ ] To analyze large datasets for business insights
4. [ ] To translate text between different languages

### 한국어

NVIDIA NeMo의 주요 목적은 무엇입니까?

1. [ ] 사실적인 이미지와 비디오를 만들려면
2. [✓] 대화형 AI 모델의 개발 및 배포를 단순화하고 가속화하기 위해
3. [ ] 비즈니스 통찰력을 위해 대규모 데이터 세트를 분석하려면
4. [ ] 다양한 언어 간의 텍스트를 번역하려면

**Correct Answer:** 2

---

## Question 17

**Category:** Training Techniques
**Difficulty:** medium

### English

Why is it important to experiment with various prompts when working with AI language models?

1. [ ] To keep the AI entertained and prevent boredom.
2. [✓] To discover the most effective prompts for achieving desired outcomes.
3. [ ] To trick the AI into revealing its hidden capabilities.
4. [ ] To generate random and unpredictable responses.

### 한국어

AI 언어 모델을 사용할 때 다양한 프롬프트를 실행하는 것이 왜 중요한가요?

1. [ ] AI를 즐겁게 해주고 지루함을 방지하기 위해서입니다.
2. [✓] 원하는 결과를 얻기 위한 효과적인 프롬프트를 발견하세요.
3. [ ] AI를 속여 숨겨진 능력을 드러내게 하는 것입니다.
4. [ ] 무작위적이고 예측할 수 없는 반응을 생성합니다.

**Correct Answer:** 2

---

## Question 18

**Category:** Retrieval-Augmented Generation
**Difficulty:** medium

### English

What is the primary purpose of Retrieval Augmented Generation (RAG)?

1. [ ] To train large language models (LLMs) from scratch
2. [✓] To enhance the capabilities of LLMs by combining them with external knowledge sources
3. [ ] To reduce the size of LLMs
4. [ ] To replace human knowledge with AI

### 한국어

검색 증강 생성(RAG)의 주요 목적은 무엇입니까?

1. [ ] 대규모 언어 모델(LLM)을 처음부터 훈련하려면
2. [✓] 외부 지식 소스와 결합하여 LLM의 역량을 강화합니다.
3. [ ] LLM의 크기를 줄이려면
4. [ ] 인간의 지식을 AI로 대체하기 위해

**Correct Answer:** 2

---

## Question 19

**Category:** Retrieval-Augmented Generation
**Difficulty:** medium

### English

Which type of database is commonly used in RAG for efficient document retrieval?

1. [ ] Relational databases (SQL)
2. [ ] Blockchain databases
3. [ ] Flat file storage
4. [✓] Vector databases

### 한국어

RAG에서는 효율적인 문서 검색을 위해 일반적으로 어떤 유형의 데이터베이스를 사용합니까?

1. [ ] 관계형 데이터베이스(SQL)
2. [ ] 블록체인 데이터베이스
3. [ ] 클라우드 파일 저장
4. [✓] 벡터 데이터베이스

**Correct Answer:** 4

---

## Question 20

**Category:** Data Visualization
**Difficulty:** medium

### English

Which of the following visualization techniques is best suited for displaying the frequency of different categories or items?

1. [ ] Heatmap
2. [✓] Bar chart
3. [ ] Scattertext
4. [ ] Network graph

### 한국어

다음 시각화 기술 중에서 다양한 범주나 항목의 빈도를 표시하는 데 가장 적합한 것은 무엇인가요?

1. [ ] 히트맵
2. [✓] 막대형 차트
3. [ ] 산점도
4. [ ] 네트워크 그래프

**Correct Answer:** 2

---

## Question 21

**Category:** Data Visualization
**Difficulty:** medium

### English

What is the primary goal of text data visualization?

1. [ ] To make text data more aesthetically pleasing
2. [✓] To transform unstructured text into visual representations for easier understanding and analysis
3. [ ] To replace the need for reading and interpreting text
4. [ ] To create complex and intricate visual displays

### 한국어

텍스트 데이터 시각화의 주요 목표는 무엇인가요?

1. [ ] 텍스트 데이터를 대용 미적으로 만들기 위해
2. [✓] 구조화되지 않은 텍스트를 시각적 표현으로 변환하여 더 쉽게 이해하고 분석할 수 있도록 합니다.
3. [ ] 텍스트를 읽고 해석할 필요성을 대체하기 위해
4. [ ] 복잡하고 정교한 시각적 디스플레이를 만들려면

**Correct Answer:** 2

---

## Question 22

**Category:** Classification Metrics
**Difficulty:** medium

### English

Which of the following is NOT a metric directly derived from a confusion matrix?

1. [ ] Accuracy
2. [ ] Precision
3. [ ] Recall
4. [✓] Mean Squared Error (MSE)

### 한국어

3. 다음 중 혼동 행렬에서 직접 파생된 지표가 아닌 것은 무엇입니까?

1. [ ] 정확성
2. [ ] 정도
3. [ ] 상기력
4. [✓] 평균 제곱 오차(MSE)

**Correct Answer:** 4

---

## Question 23

**Category:** Data Visualization
**Difficulty:** medium

### English

Word clouds are particularly effective for:

1. [ ] Showing the exact frequency of each word in a text
2. [ ] Displaying the relationships between different words or concepts
3. [✓] Highlighting the most prominent or frequent words in a text
4. [ ] Visualizing the sentiment or emotional tone of a text

### 한국어

워드 클라우드는 다음과 같은 경우에 특히 효과적입니다.

1. [ ] 텍스트에서 각 단어의 정확한 빈도 표시
2. [ ] 다양한 단어나 개념 간의 관계 표시
3. [✓] 텍스트에서 가장 눈에 띄거나 자주 등장하는 단어 강조하기
4. [ ] 텍스트의 감정이나 감정적 톤을 시각화합니다.

**Correct Answer:** 3

---

## Question 24

**Category:** Data Visualization
**Difficulty:** medium

### English

Which visualization technique is best suited for revealing relationships between two numerical variables?

1. [ ] Bar chart
2. [ ] Pie chart
3. [✓] Scatter plot
4. [ ] Heatmap

### 한국어

두 수치 변수 간의 관계를 밝히는 데 가장 적합한 시각화 기술은 무엇인가요?

1. [ ] 막대형 차트
2. [ ] 파이 차트
3. [✓] 산점도
4. [ ] 히트맵

**Correct Answer:** 3

---

## Question 25

**Category:** Data Visualization
**Difficulty:** medium

### English

Line charts are commonly used to:

1. [✓] Show trends or changes in data over time
2. [ ] Compare the frequencies of different categories
3. [ ] Display the distribution of values across two dimensions
4. [ ] Visualize the hierarchical structure of data

### 한국어

선형 차트는 일반적으로 다음과 같은 경우에 사용됩니다.

1. [✓] 시간 경과에 따라 데이터의 증분 또는 변화를 표시
2. [ ] 다양한 카테고리의 범주를 비교하려고 함
3. [ ] 두 숫자의 절대 값 비교 표시
4. [ ] 데이터의 계층 구조를 시각화합니다

**Correct Answer:** 1

---

## Question 26

**Category:** Data Analysis Tools
**Difficulty:** medium

### English

What is the primary purpose of CuDF in the context of data analysis?

1. [ ] To visualize large datasets
2. [✓] To provide a GPU-accelerated DataFrame library for data manipulation and analysis
3. [ ] To build machine learning models
4. [ ] To manage database connections

### 한국어

데이터 분석 영역에서 CuDF의 주요 목적은 무엇입니까?

1. [ ] 대규모 데이터 세트를 시각화하려면
2. [✓] 데이터 조작 및 처리을 위한 GPU 가속 DataFrame 라이브러리 제공
3. [ ] 머신 러닝 모델을 교육하려면
4. [ ] 데이터베이스 연결을 관리하려면

**Correct Answer:** 2

---

## Question 27

**Category:** Data Visualization
**Difficulty:** medium

### English

Which type of plot is ideal for showing correlations between two continuous variables?

1. [✓] Scatter Plot
2. [ ] Pie Chart
3. [ ] Bar Chart
4. [ ] Box Plot

### 한국어

두 연속 변수 간의 상관관계를 보여주는 데 가장 적합한 차트 유형은 무엇입니까?

1. [✓] 산점도
2. [ ] 바이올린 차트
3. [ ] 매트릭스 차트
4. [ ] 상자 그림

**Correct Answer:** 1

---

## Question 28

**Category:** Data Analysis Tools
**Difficulty:** medium

### English

Which of the following tasks can be accelerated using Dask-cuDF?

1. [ ] Creating deep learning models
2. [ ] Running web applications
3. [✓] Distributed DataFrame operations across multiple GPUs
4. [ ] Building NoSQL databases

### 한국어

다음 중 Dask-cuDF를 사용하여 가능하게 할 수 있는 작업은 무엇입니까?

1. [ ] 데이터 프레임 생성
2. [ ] 연 애플리케이션의 실행
3. [✓] 여러 GPU에 걸친 분산 DataFrame 작업
4. [ ] NoSQL 데이터베이스 구성

**Correct Answer:** 3

---

## Question 29

**Category:** Data Visualization
**Difficulty:** medium

### English

Which visualization method is most effective for analyzing the distribution of text lengths in a dataset?

1. [ ] Line Chart
2. [ ] Heatmap
3. [ ] Box Plot
4. [✓] Histogram

### 한국어

데이터 세트에서 텍스트의 깊이 분류를 분석하는 데 가장 효과적인 시간절약 방법은 무엇입니까?

1. [ ] 선형 서치
2. [ ] 히프를 사용
3. [ ] 상자 스키밍
4. [✓] 워크스루 활용

**Correct Answer:** 4

---

## Question 30

**Category:** LLMs
**Difficulty:** medium

### English

How do LLMs learn to generate human-like text?

1. [ ] By interacting with human users in real-time conversations
2. [✓] By leveraging massive datasets and algorithms to learn patterns in language
3. [ ] By being explicitly programmed with grammar and vocabulary rules
4. [ ] By observing human behavior in various settings

### 한국어

1. LLM은 어떻게 인간과 유사한 텍스트를 생성하는 방법을 택하나요?

1. [ ] 실시간 대화에서 인간 사용자와 상호 작용하여
2. [✓] 대규모 데이터 세트와 알고리즘을 활용하여 언어 패턴을 학습합니다.
3. [ ] 완벽한 이해 구체의 인식적으로 프로그래밍되어 있음
4. [ ] 다양한 환경에서 인간의 행동을 관찰함으로써

**Correct Answer:** 2

---

## Question 31

**Category:** LLMs
**Difficulty:** medium

### English

What is a key concern when developing and deploying large language models (LLMs)?

1. [ ] Ensuring they can generate creative and entertaining text.
2. [ ] Minimizing their computational requirements.
3. [✓] Identifying and mitigating potential biases in their output.
4. [ ] Maximizing their ability to generate code.

### 한국어

2. 대규모 언어 모델(LLM)을 개발할 때 목표할 때 가장 중요한 고려 사항은 무엇인가요?

1. [ ] 창의적이고 재미있는 텍스트를 생성할 수 있도록 보장합니다.
2. [ ] 개선 요구 사항을 최소화합니다.
3. [✓] 훈습하면서 정확한 문법과 철자를 완성합니다.
4. [ ] 모델 생성 비용을 극대화합니다.

**Correct Answer:** 3

---

## Question 32

**Category:** Training Techniques
**Difficulty:** medium

### English

Which hyperparameter tuning method systematically explores all possible combinations from a predefined set of values?

1. [✓] Grid Search
2. [ ] Random Search
3. [ ] Bayesian Optimization
4. [ ] Genetic Algorithms

### 한국어

3. 여러 정렬의 각 집합에 모든 가능한 조합을 체계적으로 탐색하는 하이퍼파라미터 튜닝 방법은 무엇인가요?

1. [✓] 그리드 검색
2. [ ] 무작위 검색
3. [ ] 베이지안 최적화
4. [ ] 유전 알고리즘

**Correct Answer:** 1

---

## Question 33

**Category:** Model Architecture
**Difficulty:** medium

### English

What are hyperparameters in the context of large language models (LLMs)?

1. [ ] The words and phrases used to train the model.
2. [✓] The internal settings that govern the model's architecture, learning rate, batch size, etc.
3. [ ] The output generated by the model in response to a prompt.
4. [ ] The evaluation metrics used to assess the model's performance.

### 한국어

4. 대규모 언어 모델(LLM)에서 일반적인 하이퍼파라미터는 무엇인가요?

1. [ ] 모델을 운영하는 핵심적인 하드웨어 구문입니다.
2. [✓] 모델의 아키텍처, 학습률, 배치 크기 등을 결정하는 내부 설정입니다.
3. [ ] 프로젝트에 대한 향후 모델의 성장을 측정합니다.
4. [ ] 모델의 성능을 평가하는 데 사용되는 평가 지표입니다.

**Correct Answer:** 2

---

## Question 34

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA Triton Inference Server?

1. [ ] To train large language models (LLMs) from scratch.
2. [✓] To simplify the deployment of AI models at scale in production.
3. [ ] To collect and preprocess data for model training.
4. [ ] To design and optimize model architectures.

### 한국어

1. NVIDIA Triton 추론 서버의 주요 목적은 무엇입니까?

1. [ ] 연구실 없이 딥러닝을 처음부터 훈련합니다.
2. [✓] 생산 환경에서 AI 모델을 대규모로 배포하는 기본 구조합니다.
3. [ ] 모델 학습을 위해 데이터를 수집하고 정제합니다.
4. [ ] 모델 연구개발을 수행하기 최적화합니다.

**Correct Answer:** 2

---

## Question 35

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary purpose of A/B testing in the context of LLMs?

1. [ ] To randomly deploy different LLM versions without any evaluation.
2. [✓] To systematically evaluate different versions of LLMs and their impact on user experience and key metrics
3. [ ] To compare the performance of LLMs against traditional rule-based systems
4. [ ] To measure the computational efficiency of different LLM architectures

### 한국어

1. LLM에서 A/B 테스트의 주요 목적은 무엇입니까?

1. [ ] 평가 없이 다양한 LLM 버전을 무작위로 배포합니다.
2. [✓] 실험을 진행하여 변경된 사양과 특정 목표 지표에 미치는 영향을 체계적으로 평가합니다.
3. [ ] LLM의 성능을 기존 규제 시스템과 비교하면서
4. [ ] 다양한 LLM 아키텍처의 계산 효율성을 측정하면서

**Correct Answer:** 2

---

## Question 36

**Category:** Development Practices
**Difficulty:** medium

### English

What is the primary benefit of using a Version Control System (VCS) in LLM development regarding reproducibility?

1. [ ] It automatically improves the model’s accuracy.
2. [ ] It prevents any changes from being made to the code or data.
3. [✓] It allows for easy tracking of changes, enabling reversion to previous versions and replication of experiments.
4. [ ] It generates new versions of the model automatically.

### 한국어

2. 재현성과 관련하여 LLM 개발에서 버전 제어 시스템(VCS)을 사용하는 주요 이유는 무엇입니까?

1. [ ] 모델의 정확도가 자동으로 향상됩니다.
2. [ ] 코드나 데이터가 전환되는 것을 방지합니다.
3. [✓] 모델 개발 과정을 사양과 다른 버전으로 되돌리고 실험을 재현할 수 있습니다.
4. [ ] 모델의 새로운 버전을 자동으로 생성합니다.

**Correct Answer:** 3

---

## Question 37

**Category:** Development Practices
**Difficulty:** medium

### English

Why is version control important for large language model (LLM) projects?

1. [ ] It allows for faster training of LLMs by optimizing computational resources.
2. [✓] It enables reproducibility, collaboration, and efficient management of LLM projects.
3. [ ] It prevents LLMs from making errors during text generation.
4. [ ] It automates hyperparameter tuning for better model performance.

### 한국어

3. 대규모 언어 모델(LLM) 프로젝트에 버전 제어가 중요한 이유는 무엇입니까?

1. [ ] 이를 통해 개인 리소스를 최적화하여 LLM의 학습 속도를 높일 수 있습니다.
2. [✓] LLM 프로젝트의 개선과, 협업 및 효율적인 관리가 가능합니다.
3. [ ] 이를 통해 LLM의 레벨과 성능 등에 오류를 찾는 과정을 실행할 수 있습니다.
4. [ ] 더 나은 모델 성능을 위해 하이퍼파라미터 튜닝을 재정립합니다.

**Correct Answer:** 2

---

## Question 38

**Category:** LLMs
**Difficulty:** medium

### English

Why is the BioNeMo LLM service particularly suitable for the biomedical and pharmaceutical industries?

1. [ ] Because it generates medical content based on general language models
2. [✓] Because it is pre-trained on massive biomedical datasets and allows customization for specific tasks
3. [ ] Because it replaces the need for human expertise in healthcare decision-making
4. [ ] Because it primarily focuses on real-time conversations with healthcare professionals

### 한국어

4. BioNeMo LLM 서비스가 생물의학 및 헬스 산업에 특히 적합한 이유는 무엇입니까?

1. [ ] 평가 없이 모델을 기반으로 의료 컨텐츠를 생성하기 때문이며
2. [✓] 대규모 의료 데이터세트에 대한 사전 학습 없이도 특정 질병에 대한 사용자의 정의가 가능하기 때문입니다.
3. [ ] 이는 의료 원격진료에 있어 인간의 질병 예측이 좀 더 용이 하기 때문입니다.
4. [ ] 주요 의료 과정에서의 실시간 데이터의 흐름을 유지기 때문입니다.

**Correct Answer:** 2

---

## Question 39

**Category:** AI Agents
**Difficulty:** medium

### English

How do NVIDIA AI Agents perceive and interact with their environment?

1. [ ] By following pre-programmed scripts for user interactions
2. [✓] By processing visual and auditory inputs using computer vision and natural language models
3. [ ] By only responding to text-based user commands
4. [ ] By relying solely on predefined responses without real-time reasoning

### 한국어

5. NVIDIA AI 엔터프라이즈 솔루션은 이렇게 변환된 인식을 어떻게 향상하고 신속 적용합니까?

1. [ ] 사용자 속성을 위한 새로운 사전 프로그램과의 스크립트를 만들고
2. [✓] 현재의 비전과 작업의 다양한 사용이 시각적 및 관심적 인식을 제공함으로써
3. [ ] 텍스트로부터 사용자의 정밀한 단평을 모으고
4. [ ] 실시간 추천 없이 미리 정의된 응답만을 일관함으로써

**Correct Answer:** 2

---

## Question 40

**Category:** Model Optimization
**Difficulty:** medium

### English

What is the primary purpose of Kernel Auto-Tuning?

1. [ ] To minimize memory usage during model execution
2. [ ] To enable parallel processing of multiple input streams
3. [✓] To select the most efficient kernels for a given GPU architecture
4. [ ] To optimize models for mixed-precision computation

### 한국어

커널 자동 튜닝의 주요 목적은 무엇입니까?

1. [ ] 같은 성능 중 메모리 사용을 최소화하려면
2. [ ] 여러 알고리즘의 병렬 처리를 활성화하려면
3. [✓] 주어진 GPU 아키텍처에 가장 적절한 커널을 선택하려면
4. [ ] 초밥 정도 계산을 위한 모델 최적화

**Correct Answer:** 3

---

## Question 41

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary focus of the NVIDIA BioNeMo LLM Service?

1. [ ] General-purpose language tasks
2. [ ] Financial analysis and predictions
3. [✓] Biomedical and pharmaceutical applications
4. [ ] Image and video processing

### 한국어

NVIDIA BioNeMo LLM 서비스의 주요 초점은 무엇입니까?

1. [ ] 일반 언어 작업
2. [ ] 재무 분석 및 예측
3. [✓] 생물학적 및 화학 응용 분야
4. [ ] 이미지 및 비디오 처리

**Correct Answer:** 3

---

## Question 42

**Category:** AI Agents
**Difficulty:** medium

### English

Which of the following capabilities falls under the “Perception” aspect of NVIDIA AI Agents?

1. [ ] Generating creative text responses
2. [✓] Processing visual and auditory input to understand the environment
3. [ ] Making complex decisions based on internal knowledge
4. [ ] Planning a sequence of actions to achieve a goal

### 한국어

다음 기능 중 NVIDIA AI Agents의 “지각” 측면에 속하는 것은 무엇입니까?

1. [ ] 정확한 테스트 로봇 생성
2. [✓] 주변 환경을 이해하기 위해 시각적, 청각적 입력을 처리합니다.
3. [ ] 내부 자신이 기계적 발전과 심화 연결
4. [ ] 목표를 중심하기 위한 일반의 행동 계획

**Correct Answer:** 2

---

## Question 43

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the core idea behind the Mixture of Experts (MoE) architectural paradigm?

1. [ ] Training multiple smaller models and combining their outputs.
2. [✓] Dividing the model into multiple specialized experts, each focusing on a specific task or domain
3. [ ] Reducing the size of the model by removing unnecessary parameters
4. [ ] Fine-tuning the model on a large dataset of diverse tasks

### 한국어

전문가 혼합(MoE) 모델 패러다임의 핵심 아이디어는 무엇입니까?

1. [ ] 여러 개의 작은 모델을 훈련하고 각각의 출력을 결합합니다.
2. [✓] 모델을 특정 작업이나 도메인에 연공하는 여러 전문가를 분할
3. [ ] 집중적으로 예방처리를 피하면서 모델 크기 줄이기
4. [ ] 다양한 작업의 대규모 데이터셋에 대한 모델 미세 조정

**Correct Answer:** 2

---

## Question 44

**Category:** AI Development
**Difficulty:** medium

### English

What is the main purpose of NVIDIA AI Workflows?

1. [ ] To provide a marketplace for buying and selling AI models.
2. [ ] To focus solely on data collection and preprocessing.
3. [✓] To streamline and accelerate the entire AI development process.
4. [ ] To automate the deployment of AI models in production.

### 한국어

2. NVIDIA AI 솔루션의 주요 목적은 무엇입니까?

1. [ ] AI 모델을 할당할 수 있는 시장을 제공합니다.
2. [ ] 데이터 신뢰성 강화를 보장합니다.
3. [✓] AI 개발 프로세스 전반의 효율성을 가속화합니다.
4. [ ] 프로덕션에서 모델의 빠른 작업을 지원합니다.

**Correct Answer:** 3

---

## Question 45

**Category:** Optimization
**Difficulty:** medium

### English

What is NVIDIA cuOpt?

1. [ ] A cloud-based platform for managing logistics operations
2. [✓] A GPU-accelerated optimization library
3. [ ] A deep learning framework for image recognition
4. [ ] A programming language for developing logistics software

### 한국어

3. NVIDIA cuOpt란 무엇입니까?

1. [ ] 유류 운영 문제를 위한 솔루션의 기본 플랫폼
2. [✓] GPU 가속 최적화 라이브러리
3. [ ] 이미지 인식을 위한 고급 라이브러리
4. [ ] 효율적 프로그램 개발을 위한 프로그래밍 언어

**Correct Answer:** 2

---

## Question 46

**Category:** Conversational AI
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA RIVA?

1. [ ] To generate realistic images
2. [✓] To enable developers to build and deploy real-time, highly accurate conversational AI applications
3. [ ] To analyze large datasets for business insights
4. [ ] To translate text between different languages

### 한국어

4. NVIDIA Riva의 주요 목적은 무엇입니까?

1. [ ] 사전과 이미지 생성하기
2. [✓] 개발자가 실시간으로 음성 인식이 높은 대화형 AI 애플리케이션을 구축하고 배포할 수 있도록 지원
3. [ ] 비디오나 음성으로부터 대규모 데이터 세트를 분석하고 해석
4. [ ] 다양한 언어 간에 텍스트를 변환하기

**Correct Answer:** 2

---

## Question 47

**Category:** Recommender Systems
**Difficulty:** medium

### English

What is NVIDIA Merlin?

1. [ ] A cloud-based platform for managing customer relationships
2. [ ] A deep learning framework for image recognition
3. [✓] An open-source framework for building and deploying recommender systems
4. [ ] A programming language for developing e-commerce websites

### 한국어

5. NVIDIA Merlin이란 무엇입니까?

1. [ ] 고객 관계 관리를 위한 솔루션의 기본 플랫폼
2. [ ] 이미지 인식을 위한 라이브러리입니다
3. [✓] 추천 시스템 구성 및 배포를 위한 오픈 소스 프레임워크
4. [ ] 정보처리 형식에서 제품을 위한 프로그래밍 언어

**Correct Answer:** 3

---

## Question 48

**Category:** Explainable AI
**Difficulty:** medium

### English

The concept of Explainable AI (XAI) is most closely associated with which pillar of responsible AI?

1. [ ] Fairness
2. [✓] Transparency & Explainability
3. [ ] Accountability
4. [ ] Privacy

### 한국어

설명 가능한 AI(XAI) 개념은 책임 있는 AI의 기둥 중 가장 밀접하게 연관되어 있습니까?

1. [ ] 공정성
2. [✓] 투명성 및 설명 가능성
3. [ ] 책임
4. [ ] 존중

**Correct Answer:** 2

---

## Question 49

**Category:** Data Privacy
**Difficulty:** medium

### English

What is data consent in the context of AI and data handling?

1. [ ] Implicit agreement assumed from users when they use a service.
2. [✓] Explicit permission from individuals to collect, use, and share their data.
3. [ ] The right of companies to use data without informing users.
4. [ ] The process of obtaining data from public sources.

### 한국어

AI와 데이터 처리의 맥락에서 데이터 주권은 무엇입니까?

1. [ ] 사용자가 서비스를 사용할 때 명목적으로 동일답다고 가정합니다.
2. [✓] 개인이 자신의 데이터를 수집, 사용, 공유하도록 의식적으로 허가합니다.
3. [ ] 사용자가 명시적 강요만으로 데이터를 사용할 수 있는 개인의 권리.
4. [ ] 공공 소스에서 데이터를 얻는 과정.

**Correct Answer:** 2

---

## Question 50

**Category:** AI Safety
**Difficulty:** medium

### English

What is the primary purpose of Nvidia’s NeMo Guardrails toolkit?

1. [ ] To accelerate the training of large language models
2. [✓] To build safer and more controlled conversational AI models
3. [ ] To improve the accuracy of image recognition models
4. [ ] To optimize the performance of deep learning algorithms

### 한국어

Nvidia의 NeMo Guardrails를 통한 주요 목적은 무엇입니까?

1. [ ] 대규모 언어 모델의 학습을 가속화설명력
2. [✓] 더욱 안전하고 통제 가능한 대화형 AI 모델을 구축하려면
3. [ ] 이미지 인식 모델의 정확도를 향상시키기 위해
4. [ ] 일반적 알고리즘의 성능을 최적화하려면

**Correct Answer:** 2

---

## Question 51

**Category:** AI Fairness
**Difficulty:** medium

### English

What is the main goal of using the Omniverse Replicator in the context of AI fairness?

1. [ ] To improve the accuracy of AI models on benchmark datasets.
2. [✓] To generate synthetic data that enhances diversity and representation in training datasets
3. [ ] To create explainable AI models
4. [ ] To establish governance structures for AI development

### 한국어

AI 공정성 전략에서 Omniverse Replicator를 사용하는 주요 목표는 무엇입니까?

1. [ ] 복잡한 데이터 세트에서 AI 모델의 명확도를 개선합니다.
2. [✓] 훈련 데이터 세트의 다양성과 편견을 정량하는 합성 데이터를 생성합니다.
3. [ ] 설명 가능한 AI 모델을 연구하다
4. [ ] AI 개발을 위한 가상현실 구조 구축

**Correct Answer:** 2

---

## Question 52

**Category:** AI Ethics
**Difficulty:** medium

### English

What is the primary goal of Trustworthy AI in NVIDIA's generative AI and LLMs?

1. [ ] A: To enhance AI performance without considering ethical implications
2. [✓] B: To ensure AI systems are reliable, safe, fair, transparent, and accountable
3. [ ] C: To make AI systems self-learning and fully autonomous
4. [ ] D: To prioritize AI accuracy over ethical considerations

### 한국어

1. NVIDIA의 생성 AI와 LLM에서 신뢰할 수 있는 AI의 주요 목표는 무엇입니까?

1. [ ] A. 문제의 모바일 경험에서 인지 성능 향상을시키고 있습니다.
2. [✓] B. AI 시스템이 윤리적이고 안정적인 결정으로부터 책임이 있는지 확인하기 위해
3. [ ] C. AI 시스템을 자체 학습하여 문제 해결하기 위해
4. [ ] D. 문제의 고급사용자만의 사용자 정의를 우선시합니다.

**Correct Answer:** 2

---

## Question 53

**Category:** Data Privacy
**Difficulty:** medium

### English

Why is data privacy crucial in artificial intelligence and large language model (LLM) development?

1. [ ] A: Because it ensures AI models can collect unlimited data for better performance
2. [✓] B: Because it builds trust, mitigates risks, ensures fairness, and complies with regulations
3. [ ] C: Because AI models require personal data to function effectively
4. [ ] D: Because it allows AI developers to bypass regulatory requirements

### 한국어

2. 인공지능과 대규모 언어 모델(LLM) 개발에 있어서 데이터 개인정보 보호가 왜 중요한가요?

1. [ ] A. 사용자가 민감한 행동을 위해 개인정보를 습득할 수 있도록 장려하기 때문입니다.
2. [✓] B. 신뢰 구축으로, 인류를 보호하며, 공정성을 보장하며, 규제를 준수하기 때문입니다.
3. [ ] C. AI 모델이 교육자료를 추천하면 개인 데이터가 필요하기 때문입니다.
4. [ ] D. 개발자가 국가 요구 사항을 무시할 수 있기 때문입니다.

**Correct Answer:** 2

---

## Question 54

**Category:** Data Privacy
**Difficulty:** medium

### English

Which of the following is a key approach used by NVIDIA to ensure data privacy in AI development?

1. [ ] A: Storing all collected data in centralized databases for easier access
2. [✓] B: Using federated learning, confidential computing, and privacy-preserving techniques
3. [ ] C: Collecting as much data as possible to improve AI accuracy
4. [ ] D: Ignoring data privacy concerns if the AI system operates in a country without strict regulations

### 한국어

3. 다음 중 NVIDIA가 개발에서 데이터 개인 정보 보호를 보장하기 위해 사용하는 주요 접근 방식은 무엇입니까?

1. [ ] A. 수집된 모든 데이터를 중앙 데이터베이스에서 저장하여 더 쉽게 접근 가능
2. [✓] B. 암호 학습, 커플 통계 및 개인 정보 보호 기술 사용
3. [ ] C. 왜곡중립 정책을 지배하는 공개 데이터 사용
4. [ ] D. 엄격한 규제가 없는 국가에서 시스템의 운용되는 경우 데이터 개인 정보 보호 문제를 무시합니다.

**Correct Answer:** 2

---

## Question 55

**Category:** AI Ethics
**Difficulty:** medium

### English

How does NVIDIA ensure AI trustworthiness in its solutions?

1. [✓] A: By embedding trustworthy AI principles at every stage of AI development
2. [ ] B: By manually reviewing AI outputs to ensure ethical compliance
3. [ ] C: By relying solely on third-party organizations to establish AI safety standards
4. [ ] D: By restricting AI models to avoid real-world applications

### 한국어

4. NVIDIA는 어떻게 복구 시뮬레이션의 AI 신뢰성을 보장합니까?

1. [✓] A. 개발된 모든 데이터를 디지털 있는 시스템을 보관함으로써
2. [ ] B. 문제의 고유 설정을 사용자 정보와 신뢰의 흐름을 보관합니다.
3. [ ] C. 신뢰성을 문제에 적용하여 생산적인 방법으로
4. [ ] D. 일반적인 응용 프로그램 및 일반적 규칙 기반 모델을 활용함으로써

**Correct Answer:** 1

---

## Question 56

**Category:** Bias Mitigation
**Difficulty:** medium

### English

How does NVIDIA approach bias mitigation in AI systems?

1. [ ] A: By relying solely on human-curated datasets for training
2. [ ] B: By completely eliminating bias through AI algorithms
3. [✓] C: By using the Omniverse Replicator to generate synthetic data
4. [ ] D: By avoiding transparency and explainability in AI models

### 한국어

5. NVIDIA는 AI 시스템의 문제 해결에 어떤 접근 방식을 취합니까?

1. [ ] A. 관련 통합 시뮬의 복구 방법을 데이터 AI에 포함하는 것은 잘못된 생각입니다. 따라서, 이는 강력한 설계 변경 및 디버깅이 심한 데이터를 AI로 통합합니다. NVIDIA는 대강연 데이터 통합 방식에 의해 발생 가능한 기능적 설계 강화를 제공합니다.
2. [ ] B. 복구를 위해 확장된 통합이 개선된 문제 해결 방법입니다. NVIDIA는 검증절로 관한 AI 설계의 끝점인 고급화 정책을 사용하며 클라우드를 사용하는 것이 있습니다. 또한 문제의 정비 관리자를 최소화하고 다른 팀과의 상호작용과 조화를 통해 ‘NVIDIA AI 실내 버전’ 응용을 권장하고 있습니다.
3. [✓] C. Omniverse Replicator 를 생산적 증명에서 해결하여 문제를 생성하기를 목표로 합니다. NVIDIA의 Omniverse Replicator를 사용하여 더 크고 다양한 데이터 문제를 제당하는 도구로, 스케일의 타임을 더 많이 얻어 봅니다. 자세한 내용은 'NVIDIA AI 문제 습관' 항목을 참조하십시오.
4. [ ] D. 문제의 방지 작업과 최종 실행을 함께 보장함으로써 이루어지는 것입입니다. NVIDIA는 AI의 방지 계약 설멩 강화를 권장하며, CI/CD 생산 서비스와의 파트너쉽 관계를 통해 설복할 수 있도록 합니다. 자세한 내용은 'NVIDIA의 최적 AI 지원' 항목을 참조하십시오.

**Correct Answer:** 3

---

## Question 57

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is the primary goal of a regression algorithm in machine learning?

1. [ ] To assign input data into predefined categories or classes.
2. [✓] To predict a continuous numerical value based on input features.
3. [ ] To group similar data points together based on their inherent patterns.
4. [ ] To discover hidden structures in unlabeled data.

### 한국어

머신 러닝에서 회귀 알고리즘의 주요 목표는 무엇인가요?

1. [ ] 입력 데이터로 미리 정의된 부분과 클래스에 할당합니다.
2. [✓] 입력 특징을 기반으로 연속적인 수치 값을 예측합니다.
3. [ ] 고유한 패턴을 기준으로 유사한 데이터 포인트를 그룹화합니다.
4. [ ] 레이블이 지정되지 않은 데이터에서 숨겨진 구조를 발견합니다.

**Correct Answer:** 2

---

## Question 58

**Category:** Model Architecture
**Difficulty:** medium

### English

What does LogisticRegression.coef_ represent in a logistic regression model?

1. [ ] The predicted probabilities for each class
2. [✓] The weights or coefficients assigned to each feature in the model
3. [ ] The accuracy of the model
4. [ ] The log-odds of the positive class

### 한국어

로지스틱 회귀 모델에서 LogisticRegression.coef_는 무엇을 나타내나요?

1. [ ] 각 클래스에 대한 예측 확률
2. [✓] 모델의 각 기능에 할당된 가중치 또는 계수
3. [ ] 모델의 정확도
4. [ ] 양의 클래스의 로그 오즈

**Correct Answer:** 2

---

## Question 59

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

What does a high recall indicate about the model?

1. [ ] The model has a low rate of false positives.
2. [✓] The model is excellent at identifying all instances of a specific class.
3. [ ] The model is good at predicting a specific class when it does predict it.
4. [ ] The model is well-balanced in terms of precision and recall.

### 한국어

높은 재현율은 모델에 대해 무엇을 나타내는가?

1. [ ] 해당 모델은 거짓 양성률이 높습니다.
2. [✓] 이 모델은 특정 클래스의 모든 인스턴스를 식별하는 데 매우 뛰어납니다.
3. [ ] 이 모델은 특정 클래스를 예측하는 데 효과적입니다.
4. [ ] 이 모델은 정밀도와 재현율 측면에서 균형이 잘 잡혀 있습니다.

**Correct Answer:** 2

---

## Question 60

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

Which metric is best suited for imbalanced datasets?

1. [ ] Accuracy
2. [ ] Recall
3. [ ] Precision
4. [✓] F1 Score

### 한국어

불균형 데이터 세트에 가장 적합한 지표는 무엇인가요?

1. [ ] 정확성
2. [ ] 정기하다
3. [ ] 정도
4. [✓] F1 점수

**Correct Answer:** 4

---

## Question 61

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

Which of the following formulas represents precision?

1. [ ] TP / (TP + FN)
2. [✓] TP / (TP + FP)
3. [ ] (TP + TN) / (TP + FP + FN + TN)
4. [ ] 2 X Precision X Recall / (Precision + Recall)

### 한국어

다음 중 어느 공식이 정밀도를 나타내나요?

1. [ ] TP / (TP + FN)
2. [✓] TP / (TP + FP)
3. [ ] TP + TN / (TP + FP + FN + TN)
4. [ ] 2 x 정밀도 x 재현율 / (정밀도 + 재현율)

**Correct Answer:** 2

---

## Question 62

**Category:** Regression Analysis
**Difficulty:** medium

### English

What does an R-squared value of 0.85 indicate?

1. [✓] 85% of the variance in the target variable is explained by the model
2. [ ] The model's predictions are 85% accurate
3. [ ] The average error of the model is 0.85 units
4. [ ] 15% of the variance in the target variable is unexplained by the model

### 한국어

1. R-제곱 값이 0.85는 무엇을 나타냅니까?

1. [✓] 목표 변수의 분산의 85%는 모델에 의해 설명됩니다.
2. [ ] 모델의 예측 정확도는 85%입니다.
3. [ ] 모델의 평균 오차율은 0.85 단위입니다.
4. [ ] 목표 변수의 분산 중 15%는 모델에 의해 설명되지 않습니다.

**Correct Answer:** 1

---

## Question 63

**Category:** Classification Metrics
**Difficulty:** medium

### English

In a confusion matrix, what does a high number of False Negatives indicate?

1. [ ] The model is predicting many positive cases incorrectly.
2. [✓] The model is failing to identify many actual positive cases.
3. [ ] The model is performing well in identifying negative cases.
4. [ ] The model has a high accuracy.

### 한국어

4. 혼동 행렬에서 거짓 부정의 수가 많다는 것은 무엇을 의미합니까?

1. [ ] 해당 모델은 많은 양성 사례를 잘못 예측하고 있습니다.
2. [✓] 이 모델은 실제로 양성 환자 사례를 많이 식별하지 못하고 있습니다.
3. [ ] 해당 모델은 부정적인 사례를 식별하는 데 좋은 성과를 보이고 있습니다.
4. [ ] 해당 모델은 정확도가 높습니다.

**Correct Answer:** 2

---

## Question 64

**Category:** Classification Problems
**Difficulty:** medium

### English

Which of the following is an example of a classification problem?

1. [ ] Predicting the price of a house
2. [✓] Identifying whether an email is spam or not
3. [ ] Estimating the number of customers in a store
4. [ ] Predicting the temperature of a city

### 한국어

5. 다음 중 분류 문제의 예는 무엇입니까?

1. [ ] 주택 가격 예측
2. [✓] 이메일이 스팸인지 아닌지 식별하기
3. [ ] 매장의 고객 수 추산
4. [ ] 도시의 온도 예측

**Correct Answer:** 2

---

## Question 65

**Category:** Regression Metrics
**Difficulty:** medium

### English

Which evaluation metric is NOT typically used for regression models?

1. [ ] R-squared (R²)
2. [ ] Mean Absolute Error (MAE)
3. [✓] F1-score
4. [ ] Root Mean Squared Error (RMSE)

### 한국어

6. 어떤 평가 지표가 일반적으로 회귀 모델에 사용되지 않습니까?

1. [ ] R제곱(R²)
2. [ ] 평균 절대 오차(MAE)
3. [✓] F1 점수
4. [ ] 평균 제곱근 오차(RMSE)

**Correct Answer:** 3

---

## Question 66

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following is NOT a typical application of hierarchical clustering?

1. [ ] Image segmentation
2. [ ] Customer segmentation
3. [✓] Linear regression
4. [ ] Anomaly detection

### 한국어

다음 중 계층적 클러스터링의 일반적인 적용 분야가 아닌 것은 무엇입니까?

1. [ ] 이미지 분할
2. [ ] 고객 세분화
3. [✓] 선형 회귀
4. [ ] 이상 감지

**Correct Answer:** 3

---

## Question 67

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following is the first step in the k-means algorithm?

1. [ ] Assignment of data points to the nearest centroids
2. [ ] Recalculation of centroids
3. [✓] Random initialization of centroids
4. [ ] Iteration until convergence

### 한국어

다음 중 k-평균 알고리즘의 첫 번째 단계는 무엇입니까?

1. [ ] 가장 가까운 중심에 데이터 포인트 할당
2. [ ] 중심점 재계산
3. [✓] 중심점의 무작위 초기화
4. [ ] 수렴할 때까지 반복

**Correct Answer:** 3

---

## Question 68

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following methods helps assess how well each data point fits within its assigned cluster in k-means?

1. [ ] Elbow Method
2. [✓] Silhouette Analysis
3. [ ] Domain Knowledge
4. [ ] Grid Search

### 한국어

다음 방법 중 어떤 것이 k-공간에서 각 데이터 포인트가 할당된 클러스터에 얼마나 잘 들어맞는지 평가하는 데 도움이 됩니까?

1. [ ] 관측치 방법
2. [✓] 실루엣 분석
3. [ ] 도메인 지식
4. [ ] 그리드 검색

**Correct Answer:** 2

---

## Question 69

**Category:** Clustering
**Difficulty:** medium

### English

What are we looking for in the plot generated by the Elbow Method?

1. [ ] A sharp peak
2. [ ] A gradual slope
3. [✓] A bend or "elbow" point
4. [ ] A straight line

### 한국어

엘보우방법으로 생성된 플롯에서 우리는 무엇을 찾고 있는가?

1. [ ] 낮아진 분점
2. [ ] 점진적인 감소
3. [✓] 균형 또는 '팔꿈치' 지점
4. [ ] 직선

**Correct Answer:** 3

---

## Question 70

**Category:** Clustering
**Difficulty:** medium

### English

What is the visual representation of the hierarchical clustering process called?

1. [ ] Scatter plot
2. [✓] Dendrogram
3. [ ] Histogram
4. [ ] Box plot

### 한국어

계층적 클러스터링 과정의 시각적 표현은 무엇이라고 하나요?

1. [ ] 산포도
2. [✓] 덴드로그램
3. [ ] 히스토그램
4. [ ] 상자 그림

**Correct Answer:** 2

---

## Question 71

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following statements is true about agglomerative clustering?

1. [ ] It's a top-down approach
2. [✓] It starts with each data point as its own cluster
3. [ ] It's computationally less expensive than divisive clustering for large datasets
4. [ ] It doesn't require a distance metric

### 한국어

다음 중 응집적 클러스터링에 관해 사실인 진술은 무엇입니까?

1. [ ] 그것은 상향식 접근 방식입니다
2. [✓] 각 데이터 포인트로 자체 클러스터로 시작됩니다.
3. [ ] 대규모 데이터 세트의 경우 분할 클러스터링보다 계산 비용이 저렴합니다.
4. [ ] 거리 측정이 필요하지 않습니다.

**Correct Answer:** 2

---

## Question 72

**Category:** Clustering
**Difficulty:** medium

### English

Which Clustering method can help us to find clusters of arbitrary shapes?

1. [ ] K-Means Clustering
2. [ ] Hierarchical Clustering
3. [✓] DBScan Clustering
4. [ ] K-Medoids Clustering

### 한국어

어떤 클러스터링 방법이 임의의 모양의 클러스터를 찾는 데 도움이 될 수 있습니까?

1. [ ] 계층적 클러스터링
2. [ ] 계속적 클러스터링
3. [✓] DBScan 클러스터링
4. [ ] K-Medoids 클러스터링

**Correct Answer:** 3

---

## Question 73

**Category:** Association Rule Mining
**Difficulty:** medium

### English

What are the two key metrics used to evaluate the strength of an association rule?

1. [ ] Accuracy and Precision
2. [✓] Support and Confidence
3. [ ] Recall and F1-score
4. [ ] Mean and Median

### 한국어

연관 규칙의 강도를 평가하는 데 사용되는 두 가지 주요 지표는 무엇입니까?

1. [ ] 정확도와 정밀도
2. [✓] 지연과 신뢰
3. [ ] 리콜 및 F1 점수
4. [ ] 평균과 중앙값

**Correct Answer:** 2

---

## Question 74

**Category:** Association Rule Mining
**Difficulty:** medium

### English

Which metric quantifies the likelihood of item Y being purchased when item X is purchased, relative to the overall likelihood of Y being purchased?

1. [ ] Support
2. [ ] Confidence
3. [✓] Lift
4. [ ] Count

### 한국어

어떤 지표는 품목 X가 구매될 때 품목 Y가 구매될 가능성을 Y가 구매될 전체 가능성에 비해 정량화하는가?

1. [ ] 지지력
2. [ ] 신뢰
3. [✓] 승강기
4. [ ] 세다

**Correct Answer:** 3

---

## Question 75

**Category:** Association Rule Mining
**Difficulty:** medium

### English

Which of the following is NOT a step in the association rule mining process?

1. [ ] Generate Frequent Itemsets
2. [ ] Generate Rules
3. [ ] Evaluate Rules
4. [✓] Cluster Analysis

### 한국어

다음 중 연관 규칙 마이닝 프로세스의 단계가 아닌 것은 무엇입니까?

1. [ ] 빈발한 항목 집합 생성
2. [ ] 규칙 생성
3. [ ] 규칙 평가
4. [✓] 클러스터 분석

**Correct Answer:** 4

---

## Question 76

**Category:** RAPIDS
**Difficulty:** medium

### English

Which of the following is NOT a key feature of RAPIDS?

1. [ ] Open-Source Software Library
2. [ ] GPU Acceleration
3. [ ] Drop-In Replacement for Existing Libraries
4. [✓] Automatic Model Selection

### 한국어

다음 중 RAPIDS의 핵심이 아닌 것은 무엇입니까?

1. [ ] 오픈 소스 소프트웨어 라이브러리
2. [ ] GPU 가속
3. [ ] 기존 도서관에 대한 드롭인 교체
4. [✓] 자동 모델 선택

**Correct Answer:** 4

---

## Question 77

**Category:** NLP
**Difficulty:** medium

### English

Which of the following is NOT a typical type of named entity recognized in NLP tasks?

1. [ ] Person
2. [ ] Organization
3. [ ] Location
4. [✓] Adjective

### 한국어

다음 중 NLP 작업에서 인식되는 일반적인 명명된 엔티티 유형이 아닌 것은 무엇입니까?

1. [ ] 사람
2. [ ] 조직
3. [ ] 위치
4. [✓] 형용사

**Correct Answer:** 4

---

## Question 78

**Category:** Model Architecture
**Difficulty:** medium

### English

Which layer in a DNN is responsible for receiving the raw input data?

1. [✓] Input Layer
2. [ ] Hidden Layer
3. [ ] It determines the accuracy of the model.
4. [ ] It has no significant role in machine learning

### 한국어

DNN의 어느 계층이 원시 입력 데이터를 수신하는 역할을 합니까?

1. [✓] 입력 레이어
2. [ ] 숨겨진 레이어
3. [ ] 이는 정확성 정확도를 결정합니다.
4. [ ] 마지막에서 중요한 역할을 합니다.

**Correct Answer:** 1

---

## Question 79

**Category:** Model Architecture
**Difficulty:** medium

### English

Which type of Deep Neural Network is best suited for processing images and videos?

1. [ ] Multi-Layer Perceptron (MLP)
2. [✓] Convolutional Neural Network (CNN)
3. [ ] Recurrent Neural Network (RNN)
4. [ ] Generative Adversarial Network (GAN)

### 한국어

이런 유형의 딥 신경망이 이미지와 비디오를 처리하는 데 가장 적합합니까?

1. [ ] 다층 퍼셉트론(MLP)
2. [✓] 합성곱 신경망(CNN)
3. [ ] 순환 신경망(RNN)
4. [ ] 생성적 적대 신경망(GAN)

**Correct Answer:** 2

---

## Question 80

**Category:** Model Architecture
**Difficulty:** medium

### English

What role do Weights play in an artificial neuron?

1. [ ] Introduce non-linearity
2. [✓] Determine the importance of each input
3. [ ] Provide a constant offset
4. [ ] Receive the initial data

### 한국어

인공 뉴런에서 가중치는 어떤 역할을 하나요?

1. [ ] 비선형성을 도입합니다
2. [✓] 각 입력의 중요성을 결정하세요
3. [ ] 큰 단일 값으로 계산
4. [ ] 초기 데이터 수신

**Correct Answer:** 2

---

## Question 81

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the first step in the computation process of an artificial neuron?

1. [ ] Apply the activation function
2. [✓] Calculate the weighted sum
3. [ ] Transmit the output signal
4. [ ] Adjust the bias

### 한국어

인공 뉴런의 계층 경계에서 첫 번째 단계는 무엇입니까?

1. [ ] 활성화 함수를 적용합니다
2. [✓] 가중치를 계산합니다
3. [ ] 출력 신호를 전송합니다
4. [ ] 입력을 조정하다

**Correct Answer:** 2

---

## Question 82

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the initial step in the Gradient Descent algorithm?

1. [ ] Calculate the gradient of the loss function
2. [ ] Update the model parameters
3. [✓] Initialize the model parameters with random values
4. [ ] Repeat steps until convergence

### 한국어

경사 하강 알고리즘의 초기 단계는 무엇입니까?

1. [ ] 손실 함수의 기울기를 계산합니다
2. [ ] 모델 입력처리를 만듭니다
3. [✓] 알맞은 모듈로 모델 매개변수를 초기화합니다
4. [ ] 추출된 매개변수를 변형합니다

**Correct Answer:** 3

---

## Question 83

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the mathematical formula for the ReLU activation function?

1. [✓] f(x) = max(0, x)
2. [ ] f(x) = 1 / (1 + e^-x)
3. [ ] f(x) = tanh(x)
4. [ ] f(x) = x

### 한국어

ReLU 활성화 함수의 수학 공식은 무엇인가요?

1. [✓] f(x) = max(0, x)
2. [ ] f(x) = 1 / (1 + e^-x)
3. [ ] f(x) = tanh(x)
4. [ ] f(x) = x

**Correct Answer:** 1

---

## Question 84

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the purpose of applying an activation function in a neuron?

1. [ ] To normalize the input values
2. [✓] To introduce non-linearity into the model
3. [ ] To calculate the weighted sum of inputs
4. [ ] To produce the final prediction

### 한국어

뚜렷이 활성화 함수를 적용하는 목적은 무엇인가요?

1. [ ] 입력값을 규정화하기 위해
2. [✓] 모델의 비선형성을 도입하려면
3. [ ] 입력의 가중평균을 계산하려면
4. [ ] 새로운 예측을 생성하려면

**Correct Answer:** 2

---

## Question 85

**Category:** Model Architecture
**Difficulty:** medium

### English

In the equation Z = W * X + b, what does Z represent?

1. [ ] The weight matrix
2. [ ] The input matrix
3. [ ] The bias vector
4. [✓] The matrix of weighted sums for all neurons in a layer

### 한국어

Z = W * x + b 방정식에서 Z는 무엇을 나타내나요?

1. [ ] 가중치 행렬
2. [ ] 편향 행렬
3. [ ] 하이퍼볼릭 탄젠트
4. [✓] 계층의 모든 뉴런에 대한 가중 합의 행렬

**Correct Answer:** 4

---

## Question 86

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the primary goal of backpropagation in neural networks?

1. [ ] To initialize the model's parameters
2. [ ] To make predictions on new data
3. [✓] To minimize the overall error and improve model accuracy
4. [ ] To introduce non-linearity into the model

### 한국어

신경망에서 역전파 알고리즘의 주요 목적은 무엇인가요?

1. [ ] 모델의 파라미터를 초기화하려면
2. [ ] 새로운 데이터에 대한 예측을 하려면
3. [✓] 성능을 최적화하고 모델의 정확도를 향상시키려면
4. [ ] 모델의 비선형성을 도입하려면

**Correct Answer:** 3

---

## Question 87

**Category:** Training Techniques
**Difficulty:** medium

### English

Which step involves feeding the input data through the network to generate a prediction?

1. [✓] Forward Pass
2. [ ] Loss Calculation
3. [ ] Backward Pass
4. [ ] Weight Initialization

### 한국어

예측을 생성하기 위해 딥러닝 네트워크에 공급하는 단계는 무엇인가?

1. [✓] 프로토콜 분석
2. [ ] 손실 계산
3. [ ] 역전파
4. [ ] 가중치 초기화

**Correct Answer:** 1

---

## Question 88

**Category:** Data Preprocessing
**Difficulty:** medium

### English

Given a categorical feature with values ['red', 'green', 'blue'], what would be the one-hot encoded representation of 'green'?

1. [ ] [1, 0, 0]
2. [✓] [0, 1, 0]
3. [ ] [0, 0, 1]
4. [ ] [1, 1, 0]

### 한국어

'red', 'green', 'blue' ]라는 범주의 특성이 주어졌을 때, 'green'의 원핫 인코딩 표현은 무엇인가요?

1. [ ] [0, 1, 0]
2. [✓] [1, 0, 0]
3. [ ] [0, 0, 1]
4. [ ] [1, 1, 0]

**Correct Answer:** 2

---

## Question 89

**Category:** Model Architecture
**Difficulty:** medium

### English

What type of data are Convolutional Neural Networks (CNNs) primarily designed to process?

1. [ ] Sequential data, such as text or time series
2. [ ] Tabular data with structured features
3. [✓] Grid-like data, such as images and video
4. [ ] Audio data

### 한국어

합성곱 신경망(CNN)은 주로 어떤 유형의 데이터를 처리하도록 설계되었습니까?

1. [ ] 텍스트나 시계열과 같은 순차적 데이터
2. [ ] 구조화된 값이 있는 표 형식 데이터
3. [✓] 이미지, 비디오 등 2 그리드 형탤 데이터
4. [ ] 오디오 데이터

**Correct Answer:** 3

---

## Question 90

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of Pooling Layers in a CNN?

1. [ ] To increase the spatial dimensions of the data
2. [ ] To introduce non-linearity into the model
3. [✓] To reduce the spatial dimensions of the data by downsampling
4. [ ] To generate the final output predictions

### 한국어

CNN에서 풀링 레이어의 주요 목적은 무엇입니까?

1. [ ] 데이터의 공간적 차원을 늘리려면
2. [ ] 모델의 반상성능을 도울하려면
3. [✓] 다운샘플링을 통해 데이터의 공간적 차원을 줄이려면
4. [ ] 최종 출력 예측을 생성하려면

**Correct Answer:** 3

---

## Question 91

**Category:** NLP
**Difficulty:** medium

### English

What is the primary goal of Named Entity Recognition (NER)?

1. [✓] To identify and classify named entities in text, such as names of people, organizations, locations, etc.
2. [ ] To translate text from one language to another
3. [ ] To generate human-like text
4. [ ] To summarize large documents

### 한국어

명명된 개체 인식(NER)의 주요 목표는 무엇인가요?

1. [✓] 사람, 조직, 위치 등의 이름 등 텍스트에서 명명된 엔티티를 식별하고 분류합니다.
2. [ ] 한 언어에서 다른 언어로 텍스트를 번역하려면
3. [ ] 인간과 유사한 텍스트를 생성하려면
4. [ ] 대용량 문서를 요약하려면

**Correct Answer:** 1

---

## Question 92

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the core concept behind transfer learning?

1. [ ] Training a model from scratch on a small dataset.
2. [✓] Leveraging knowledge from a pre-trained model on a new but related task.
3. [ ] Creating a completely new neural network architecture for every task.
4. [ ] Only using labeled data for training.

### 한국어

전이 학습의 핵심 개념은 무엇입니까?

1. [ ] 작은 데이터세트를 이용해 처음부터 모델을 학습합니다.
2. [✓] 사전 훈련된 모델의 지식을 새롭지만 관련된 작업에 활용합니다.
3. [ ] 모든 작업에 대해 완전히 새로운 신경망 아키텍처를 만듭니다.
4. [ ] 레이블이 지정된 데이터만 사용하여 학습합니다.

**Correct Answer:** 2

---

## Question 93

**Category:** Training Techniques
**Difficulty:** medium

### English

In which scenario is transfer learning most likely to be beneficial?

1. [ ] You have abundant labeled data for your specific task.
2. [ ] The pre-trained model was trained on a task completely unrelated to your target task.
3. [ ] You have ample computational resources and a large dataset for your new task.
4. [✓] You have a small dataset for your specific task and limited computational resources.

### 한국어

어떤 시나리오에서 전이 학습이 가장 유익할 가능성이 높습니까?

1. [ ] 다량의 특정 환경에 적합한 레이블이 지정된 데이터가 풍부합니다.
2. [ ] 사전 학습된 모델은 대상 작업과 전혀 관련이 없는 작업에 대해 학습되었습니다.
3. [ ] 새로운 작업을 수행하기에 충분한 컴퓨팅 리소스와 대규모 데이터 세트를 찾고 있습니다.
4. [✓] 다량의 특정 환경에 필요한 데이터 세트는 작고 컴퓨팅 리소스도 제한적입니다.

**Correct Answer:** 4

---

## Question 94

**Category:** Model Architecture
**Difficulty:** medium

### English

When loading the VGG16 model, what does setting include_top=False signify?

1. [✓] It excludes the final fully connected classification layers of the model
2. [ ] It excludes the convolutional base of the model
3. [ ] It loads the model without pre-trained weights
4. [ ] It disables transfer learning

### 한국어

VGG16 모델을 로드할 때 include_top=False로 설정하는 것은 무엇을 의미합니까?

1. [✓] 모델의 최상 층에 있는 Dense 계층을 제외합니다.
2. [ ] 모델의 학습량 기반을 제외합니다.
3. [ ] 사전 훈련된 가중치 없이 모델을 로드합니다.
4. [ ] 같이 학습을 비활성화합니다.

**Correct Answer:** 1

---

## Question 95

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the purpose of freezing layers in the VGG16 model during transfer learning?

1. [✓] To prevent the pre-trained weights from being updated during training
2. [ ] To slightly speed up the training process
3. [ ] To ensure the model learns only from the new data
4. [ ] To reduce the model’s complexity

### 한국어

같이 학습 없이 VGG16 모델에서 레이어를 동결하는 '활용'은 무엇입니까?

1. [✓] 사전 훈련된 가중치가 없는 모델에서는 정확성을 저하
2. [ ] 훈련 과정 맨 마지막부터 접근하려면
3. [ ] 모델에 새로운 데이터셋만 학습하도록 하려면
4. [ ] 모델의 복잡성을 줄이려면

**Correct Answer:** 1

---

## Question 96

**Category:** Deep Learning
**Difficulty:** medium

### English

Which activation function maps the input to a range between 0 and 1 and is historically popular but suffers from vanishing gradients?

1. [✓] Sigmoid
2. [ ] Hyperbolic Tangent (tanh)
3. [ ] Rectified Linear Unit (ReLU)
4. [ ] Linear

### 한국어

어떤 활성 함수가 입력을 0~1 사이의 범위에 매핑하며, 역사적으로 입력 값 자체가 기울기가 사라지는 문제가 있는가?

1. [✓] 시그모이드
2. [ ] 쌍곡탄젠트(tanh)
3. [ ] 정류 선형 유닛(ReLU)
4. [ ] 선형

**Correct Answer:** 1

---

## Question 97

**Category:** Deep Learning
**Difficulty:** medium

### English

Which activation function is similar to sigmoid but maps the input to a range between -1 and 1?

1. [ ] Sigmoid
2. [✓] Hyperbolic Tangent (tanh)
3. [ ] Rectified Linear Unit (ReLU)
4. [ ] Linear

### 한국어

시그모이드와 유사하지만 입력을 -1과 1 사이의 범위로 매핑하는 활성화 함수는 무엇인가?

1. [ ] 시그모이드
2. [✓] 쌍곡탄젠트(tanh)
3. [ ] 정류 선형 유닛(ReLU)
4. [ ] 선형

**Correct Answer:** 2

---

## Question 98

**Category:** Transfer Learning
**Difficulty:** medium

### English

Which of the following is a common approach in transfer learning?

1. [ ] Training a model from scratch with random weights
2. [ ] Completely discarding pre-trained models in every training iteration
3. [ ] Avoiding the use of neural networks
4. [✓] Using a pre-trained model as a feature extractor and fine-tuning only specific layers

### 한국어

다음 중 같이 학습에서 일반적인 접근 방식은 무엇인가?

1. [ ] 무작위 가중치를 사용하여 처음부터 모델 학습
2. [ ] 모든 훈련 반복에서 사전 훈련 모델을 무시합니다.
3. [ ] 신경망 사전 훈련
4. [✓] 가중치 변환에 생성적 기능 출력을 사용하는 특성 데이터에 페널티 적용

**Correct Answer:** 4

---

## Question 99

**Category:** NLP
**Difficulty:** medium

### English

What is the primary challenge that Natural Language Processing (NLP) aims to address?

1. [✓] The complexity and ambiguity of human language.
2. [ ] The speed at which humans can process information.
3. [ ] The vast amount of data generated by machines.
4. [ ] The difficulty of programming computers in binary code.

### 한국어

자연어 처리(NLP)가 해결하고자 하는 주요 과제는 무엇입니까?

1. [✓] 인간 언어의 복잡성과 모호성.
2. [ ] 인간이 정보를 처리할 수 있는 속도.
3. [ ] 기계가 생성하는 양질의 데이터.
4. [ ] 이진 코드를 컴퓨터를 프로그래밍하는 것은 어렵다.

**Correct Answer:** 1

---

## Question 100

**Category:** NLP
**Difficulty:** medium

### English

Which NLP preprocessing technique involves breaking down a text into smaller units like words or subwords?

1. [✓] Tokenization
2. [ ] Stopword Removal
3. [ ] Stemming
4. [ ] Lemmatization

### 한국어

어떤 NLP 전처리 기법이 텍스트를 단어나 하위 단어와 같은 더 작은 단위로 분해하는 것을 포함합니까?

1. [✓] 토큰화
2. [ ] 불용어 제거
3. [ ] 어간 분석
4. [ ] 레마티제이션

**Correct Answer:** 1

---

## Question 101

**Category:** NLP
**Difficulty:** medium

### English

Which text normalization technique aims to reduce words to their base or root form, often by removing suffixes?

1. [✓] Stemming
2. [ ] Lemmatization
3. [ ] Expanding contractions
4. [ ] Tokenization

### 한국어

어떤 텍스트 정규화 기술이 접미사를 제거하여 단어를 기본 형태나 어근 형태로 줄이는 것을 목표로 합니까?

1. [✓] 어간 분석
2. [ ] 레마티제이션
3. [ ] 추상 추출
4. [ ] 토큰화

**Correct Answer:** 1

---

## Question 102

**Category:** NLP
**Difficulty:** medium

### English

When building an NLP pipeline, how should you choose the specific components to include?

1. [ ] Randomly select components.
2. [ ] Always use the same components for every task
3. [✓] Base the selection on the specific NLP task you are trying to solve
4. [ ] Only use pre-built pipelines, never customize

### 한국어

NLP 파이프라인을 구축할 때 포함할 특정 구성 요소를 어떻게 선택해야 합니까?

1. [ ] 무작위로 구성요소를 선택합니다.
2. [ ] 모든 작업이 항상 동일한 구성 요소를 사용하십시오.
3. [✓] 해결하려는 특정 NLP 작업에 따라 선택을 기반으로 하세요.
4. [ ] 미리 구축된 파이프라인만 사용하고 사용자 정의하지 마십시오.

**Correct Answer:** 3

---

## Question 103

**Category:** Word Embeddings
**Difficulty:** medium

### English

What are word embeddings?

1. [ ] Sparse matrices representing the frequency of words in a document.
2. [✓] Dense vector representations of words in a continuous vector space.
3. [ ] One-hot encoded representations of words.
4. [ ] Syntactic trees capturing the grammatical structure of sentences.

### 한국어

워드 임베딩이란 무엇인가요?

1. [ ] 문서에서 단어의 빈도를 나타내는 희소 행렬입니다.
2. [✓] 연속적인 벡터 공간에서 단어에 밀집 벡터 표현입니다.
3. [ ] 단어의 원작 인코딩 표현.
4. [ ] 문장의 문법적 구조를 포함하는 구문 트리.

**Correct Answer:** 2

---

## Question 104

**Category:** Word Embeddings
**Difficulty:** medium

### English

How are pre-trained word embeddings typically used in NLP models?

1. [ ] They are directly fed into the final output layer of the model.
2. [✓] They are used as input features to the model.
3. [ ] They replace the need for any other feature engineering.
4. [ ] They are only used for language generation tasks.

### 한국어

사전 훈련된 단어 임베딩은 일반적으로 NLP 모델에서 어떻게 사용됩니까?

1. [ ] 이는 모델의 최종 출력 계층에 직접 입력됩니다.
2. [✓] 이는 모델의 입력 기능으로 사용됩니다.
3. [ ] 이는 다른 기능 엔지니어링 필요성을 대체합니다.
4. [ ] 이는 언어 생성 작업에만 사용됩니다.

**Correct Answer:** 2

---

## Question 105

**Category:** Word Embeddings
**Difficulty:** medium

### English

Which of the following are the two main architectures used in Word2Vec?

1. [✓] Continuous Bag-of-Words (CBOW) and Skip-gram
2. [ ] Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)
3. [ ] Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs)
4. [ ] Transformer and BERT

### 한국어

다음 중 Word2Vec에 사용되는 두 가지 주요 아키텍처는 무엇입니까?

1. [✓] 연속 백 오브 워드(CBOW) 및 스킵그램
2. [ ] 합성곱 신경망(CNN)과 순환 신경망(RNN)
3. [ ] 장단기 기억(LSTM) 및 게이트형 순환 단위(GRU)
4. [ ] 트랜스포머와 BERT

**Correct Answer:** 1

---

## Question 106

**Category:** Word Embeddings
**Difficulty:** medium

### English

In the Continuous Bag-of-Words (CBOW) architecture of Word2Vec, what is the model trying to predict?

1. [ ] The next word in a sentence.
2. [✓] The missing word in a sentence given its surrounding context.
3. [ ] The surrounding context words given a target word
4. [ ] The sentiment of a sentence

### 한국어

Word2Vec의 CBOW(Continuous Bag-of-Words) 아키텍처에서 모델은 무엇을 예측하려고 합니까?

1. [ ] 문장의 다음 단어.
2. [✓] 주변 맥락을 고려했을 때 문장에서 빠진 단어.
3. [ ] 입력 단어가 주어졌을 때 주변 맥락 단어
4. [ ] 문장의 감정

**Correct Answer:** 2

---

## Question 107

**Category:** NLP
**Difficulty:** medium

### English

Which of the following best describes the nature of text data?

1. [ ] Highly structured and uniform
2. [✓] Unstructured and diverse
3. [ ] Primarily numerical
4. [ ] Limited to short sentences

### 한국어

다음 중 텍스트 데이터의 특성을 가장 잘 설명하는 것은 무엇입니까?

1. [ ] 고도로 구조화되고 규일함
2. [✓] 비구조적이고 다양함
3. [ ] 주로 숫자
4. [ ] 짧은 문장으로 제한됨

**Correct Answer:** 2

---

## Question 108

**Category:** RNNs
**Difficulty:** medium

### English

In an RNN, how is the input at each time step processed?

1. [ ] It is directly fed into the output layer.
2. [✓] It is combined with the previous hidden state.
3. [ ] It is processed independently of the previous hidden state.
4. [ ] It is first passed through a convolutional layer.

### 한국어

RNN에서 각 시간 단계의 입력은 어떻게 처리되나요?

1. [ ] 이는 출력 계층에 직접 공급됩니다.
2. [✓] 이는 이전의 숨겨진 상태와 결합됩니다.
3. [ ] 이는 이전의 숨겨진 상태와 독립적으로 처리됩니다.
4. [ ] 먼저 함성곱 계층을 통과합니다.

**Correct Answer:** 2

---

## Question 109

**Category:** RNNs
**Difficulty:** medium

### English

Which of the following is NOT an application of RNNs in Natural Language Processing (NLP)?

1. [ ] Machine translation
2. [ ] Sentiment analysis
3. [✓] Image recognition
4. [ ] Text generation

### 한국어

다음 중 자연어 처리(NLP)에 RNN을 적용한 것이 아닌 것은 무엇입니까?

1. [ ] 기계 번역
2. [ ] 감정 분석
3. [✓] 이미지 인식
4. [ ] 텍스트 생성

**Correct Answer:** 3

---

## Question 110

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the core issue in the vanishing gradient problem?

1. [ ] Gradients become exponentially larger as they propagate backward through layers.
2. [✓] Gradients become exponentially smaller as they propagate backward through layers.
3. [ ] Gradients remain constant as they propagate backward through layers.
4. [ ] Gradients fluctuate randomly as they propagate backward through layers.

### 한국어

사라지는 기울기 문제의 핵심 문제는 무엇입니까?

1. [ ] 기울기는 레이어에 따라 뒤로 전달될수록 기하급수적으로 커집니다.
2. [✓] 기울기는 계층을 따라 뒤로 전달될수록 기하급수적으로 작아집니다.
3. [ ] 기울기는 레이어를 따라 뒤로 전달되면서도 일정하게 유지됩니다.
4. [ ] 기울기는 층을 따라 뒤로 전달되면서 무작위로 변동합니다.

**Correct Answer:** 2

---

## Question 111

**Category:** Transformers
**Difficulty:** medium

### English

What is the key innovation introduced by the Transformer architecture?

1. [ ] Convolutional layers
2. [ ] Recurrent neural networks
3. [✓] Self-attention mechanisms
4. [ ] Long short-term memory cells

### 한국어

Transformer 아키텍처가 도입한 주요 혁신은 무엇입니까?

1. [ ] 합성곱 레이어
2. [ ] 순환 신경망
3. [✓] 자기 주의 메커니즘
4. [ ] 장기 단기 기억 셀

**Correct Answer:** 3

---

## Question 112

**Category:** Transformers
**Difficulty:** medium

### English

What is the purpose of having multiple attention heads in Transformers?

1. [ ] To increase the model's computational complexity
2. [✓] To allow the model to focus on different aspects of the input simultaneously
3. [ ] To reduce the number of parameters in the model
4. [ ] To enable the model to process images and text data together

### 한국어

트랜스포머에 여러 개의 어텐션 헤더가 있는 목적은 무엇입니까?

1. [ ] 모델의 계산 복잡성을 높이려면
2. [✓] 모델이 입력의 다양한 부분에 동시에 집중할 수 있도록 하려면
3. [ ] 모델의 매개변수 수를 줄이려면
4. [ ] 모델이 이미지와 텍스트 데이터를 함께 처리할 수 있도록 하려면

**Correct Answer:** 2

---

## Question 113

**Category:** Transformers
**Difficulty:** medium

### English

What is the primary role of positional encoding in Transformers?

1. [✓] To provide information about the absolute position of each word in the sequence.
2. [ ] To enable the model to distinguish between different words in the vocabulary.
3. [ ] To reduce the number of parameters in the model.
4. [ ] To improve the model's ability to handle image data.

### 한국어

트랜스포머에서 위치 인코딩의 주요 역할은 무엇입니까?

1. [✓] 시퀀스에서 각 단어의 절대 위치에 대한 정보를 제공합니다.
2. [ ] 모델이 입력의 순익 다양한 단어를 구별할 수 있도록 합니다.
3. [ ] 모델의 매개변수 수를 줄이려면.
4. [ ] 모델의 이미지 데이터 처리 능력을 향상시킵니다.

**Correct Answer:** 1

---

## Question 114

**Category:** Data Preprocessing
**Difficulty:** medium

### English




### 한국어

머신 러닝에서 기능 스케일링의 주요 목적은 무엇입니까?

1. [ ] 반응형 데이터를 핵심적으로 향상시킵니다.
2. [✓] 이는 다른 규모의 연속 특징이 다른 기능과 기울기를 지배하는 것을 방지합니다.
3. [ ] 데이터의 세트에서 정확 복사를 피합니다.
4. [ ] 모델 검증의 필요성이 없습니다.

**Correct Answer:** 2

---

## Question 115

**Category:** Transformers
**Difficulty:** medium

### English

How is positional encoding typically incorporated into the model's input?

1. [ ] It is used to replace the word embeddings entirely.
2. [ ] It is fed into a separate network that generates attention masks.
3. [✓] It is concatenated with the word embeddings.
4. [ ] It is used to initialize the model's weights.

### 한국어

위치 인코딩은 일반적으로 어떻게 모델의 입력에 통합됩니까?

1. [ ] 이는 단어 임베딩을 완전히 대체하는 데 사용됩니다.
2. [ ] 이는 주의 마스크를 생성하는 별도의 네트워크에 입력됩니다.
3. [✓] 이는 단어 임베딩과 연결됩니다.
4. [ ] 모델의 가중치를 초기화하는 데 사용됩니다.

**Correct Answer:** 3

---

## Question 116

**Category:** Transformers
**Difficulty:** medium

### English

What is the primary challenge posed by the permutation-invariant nature of self-attention in Transformers when dealing with natural language?

1. [ ] It makes it difficult to capture long-range dependencies in a sentence.
2. [ ] It prevents the model from distinguishing between synonyms.
3. [✓] It makes it difficult to understand the relationships between words in a sentence.
4. [ ] It leads to the model generating grammatically incorrect sentences.

### 한국어

자연어를 다룰 때 트랜스포머에서 자기 주의의 순열 불변적 특성으로 인해 발생하는 주요 과제는 무엇입니까?

1. [ ] 문맥이 장거리 종속성을 포함하기 어렵게 만듭니다.
2. [ ] 이로 인해 모델이 동일한 단어를 구별하지 못합니다.
3. [✓] 문장 속 단어 사이의 관계를 이해하는 것이 어렵습니다.
4. [ ] 이로 인해 모델이 문법적으로 잘못된 문장을 생성하게 됩니다.

**Correct Answer:** 3

---

## Question 117

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of memory cells in LSTMs?

1. [ ] To process input sequences in parallel.
2. [ ] To introduce non-linearity into the network.
3. [✓] To maintain long-term information across time steps.
4. [ ] To regulate the learning rate during training.

### 한국어

LSTM에서 메모리 셀의 주요 목적은 무엇입니까?

1. [ ] 입력 시퀀스를 병렬로 처리합니다.
2. [ ] 네트워크의 비선형성을 도입합니다.
3. [✓] 시간 단위에 걸쳐 장기 정보를 유지합니다.
4. [ ] 훈련 중 학습률을 조절합니다.

**Correct Answer:** 3

---

## Question 118

**Category:** LLMs
**Difficulty:** medium

### English

What is the purpose of pre-training in LLM development?

1. [ ] To specialize the model for a specific task
2. [✓] To teach the model general language patterns from diverse text sources
3. [ ] To reduce the model's size
4. [ ] To improve the model's inference speed

### 한국어

LLM 개발에서 사전 교육의 목적은 무엇입니까?

1. [ ] 특정 작업에 맞게 모델을 전문화하려면
2. [✓] 다양한 텍스트 소스에서 모델 일반 언어 패턴을 가르치려면
3. [ ] 모델의 크기를 줄이려면
4. [ ] 모델의 추론 속도를 개선하려면

**Correct Answer:** 2

---

## Question 119

**Category:** Transformers
**Difficulty:** medium

### English

What is the main purpose of a Transformer pipeline in Hugging Face's Transformers library?

1. [ ] To train a Transformer model from scratch.
2. [ ] To fine-tune a pre-trained Transformer model on a specific task
3. [✓] To simplify the process of applying pre-trained Transformer models to various NLP tasks
4. [ ] To visualize the internal workings of a Transformer model

### 한국어

Hugging Face의 Transformers 라이브러리에서 Transformer 파이프라인의 주요 목적은 무엇입니까?

1. [ ] Transformer 모델을 처음부터 학습합니다.
2. [ ] 특정 작업에 대해서 사전 훈련된 Transformer 모델을 미세 조정하려면
3. [✓] 다양한 NLP 작업에 사전 훈련된 Transformer 모델을 적용하는 프로세스를 단순화하려면
4. [ ] Transformer 모델의 내부 작동을 시각화하려면

**Correct Answer:** 3

---

## Question 120

**Category:** NLP
**Difficulty:** medium

### English

When using a Hugging Face pipeline for text classification, what is the typical input?

1. [ ] A pre-trained LLM
2. [✓] A list of text samples to be classified
3. [ ] The desired output labels
4. [ ] The path to a dataset

### 한국어

텍스트 분류에 Hugging Face 파이프라인을 사용할 때 일반적인 입력은 무엇입니까?

1. [ ] 사전 훈련된 LLM
2. [✓] 분류할 텍스트 샘플 목록
3. [ ] 원하는 출력 레이블
4. [ ] 데이터 세트 경로

**Correct Answer:** 2

---

## Question 121

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the core principle behind Generative Adversarial Networks (GANs)?

1. [ ] Two neural networks collaborate to create realistic content.
2. [ ] One neural network learns to compress data, while another decompresses it.
3. [✓] Two neural networks compete against each other, one generating content and the other evaluating its realism.
4. [ ] A single neural network learns to predict the next word in a sequence.

### 한국어

생성적 적대 신경망(GAN)의 핵심 원리는 무엇입니까?

1. [ ] 두 개의 신경망이 협력하여 사실적인 콘텐츠를 만듭니다.
2. [ ] 한 신경망은 데이터를 압축하는 법을 배우고, 다른 신경망은 압축을 해제합니다.
3. [✓] 두 개의 신경망이 서로 경쟁하는데, 하나는 콘텐츠를 생성하고 다른 하나는 콘텐츠의 현실성을 평가합니다.
4. [ ] 단일 신경망은 시퀀스의 다음 단계를 예측하는 법을 학습합니다.

**Correct Answer:** 3

---

## Question 122

**Category:** Training Techniques
**Difficulty:** medium

### English

Why is diversity crucial in the data used to train generative AI models?

1. [ ] It helps the model avoid overfitting to specific patterns
2. [✓] It makes the model more versatile and capable of generating a wider range of content
3. [ ] It reduces the computational resources required for training
4. [ ] It ensures the model's output is always factually accurate

### 한국어

생성 시 모델을 훈련하는 데 사용되는 데이터에서 다양성이 왜 중요한가요?

1. [ ] 이는 모델이 특정 패턴에 과도하게 맞춰지는 것을 방지하는 데 도움이 됩니다.
2. [✓] 이는 모델을 더욱 다재다능하게 만들고 더 광범위한 콘텐츠를 생성할 수 있게 해줍니다.
3. [ ] 훈련에 필요한 계산 리소스를 줄여줍니다.
4. [ ] 이는 모델의 출력이 항상 사실적으로 정확함을 보장합니다.

**Correct Answer:** 2

---

## Question 123

**Category:** LLMs
**Difficulty:** medium

### English

What is the advantage of incorporating texts from specific fields like medicine, law, or finance into LLM training data?

1. [✓] It allows the model to develop specialized knowledge in those domains
2. [ ] It improves the model's overall language understanding
3. [ ] It speeds up the training process
4. [ ] It enhances the model's ability to generate poetry

### 한국어

의학, 법률, 금융 등 특정 분야의 텍스트를 LLM 교육 데이터에 통합하는 이점은 무엇입니까?

1. [✓] 이를 통해 모델은 해당 도메인에 대한 전문 지식을 개발할 수 있습니다.
2. [ ] 모델의 전반적인 언어 이해도가 향상됩니다.
3. [ ] 훈련 과정을 가속화합니다.
4. [ ] 이는 모델의 생성 능력을 향상시킵니다.

**Correct Answer:** 1

---

## Question 124

**Category:** Data Preprocessing
**Difficulty:** medium

### English




### 한국어

sklearn.preprocessing에서 StandardScaler()의 목적은 무엇입니까?

1. [ ] 반응형 변수를 숫자 값으로 변환합니다.
2. [ ] 0과 1 사이의 스케일링으로 기능을 정규화합니다.
3. [✓] 평균과 표준편차로 입력 변수를 스케일링하여 기능을 표준화합니다.
4. [ ] 데이터 세트에서 누락된 값을 대체합니다.

**Correct Answer:** 3

---

## Question 125

**Category:** Training Techniques
**Difficulty:** medium

### English

What is a direct consequence of training Large Language Models (LLMs) on poor-quality data?

1. [ ] Improved accuracy and reliability.
2. [ ] Increased generalization to new information.
3. [✓] Inaccurate outputs and biased responses.
4. [ ] Faster training times and reduced computational costs.

### 한국어

품질이 낮은 데이터로 대규모 언어 모델(LLM)을 훈련하면 직접적인 결과는 무엇입니까?

1. [ ] 정확도와 신뢰성이 향상되었습니다.
2. [ ] 새로운 정보에 대한 일반화가 강해졌습니다.
3. [✓] 부정확한 출력과 편향된 응답.
4. [ ] 훈련 시간과 단축되고 계산 비용이 절감됩니다.

**Correct Answer:** 3

---

## Question 126

**Category:** AI Infrastructure
**Difficulty:** medium

### English

How does NVIDIA contribute to the data pipeline for AI tasks?

1. [ ] By manually curating training datasets for AI models
2. [✓] By enabling GPU acceleration and distributed computing for data processing
3. [ ] By replacing the need for diverse training data through AI simulations
4. [ ] By focusing only on hardware and not on AI data pipelines

### 한국어

NVIDIA 사 작업을 위한 데이터 파이프라인이 어떻게 기여합니까?

1. [ ] AI 모델 훈련을 위한 데이터 세트를 수동으로 큐레이팅하여
2. [✓] 데이터 처리를 위한 GPU 가속 및 분산 컴퓨팅을 활성화함으로써
3. [ ] AI 시뮬레이션을 통해 다양한 효과의 데이터의 필요성을 대체함으로써
4. [ ] AI 데이터 파이프라인이 아닌 하드웨어에만 집중함으로써

**Correct Answer:** 2

---

## Question 127

**Category:** Training Techniques
**Difficulty:** medium

### English

What are the key challenges of feeding poor-quality data to large language models (LLMs)?

1. [ ] It improves the model’s ability to generalize new information.
2. [✓] It results in inaccurate outputs, biased responses, and unreliable predictions.
3. [ ] It has no impact on the performance of LLMs.
4. [ ] It speeds up the training process of LLMs.

### 한국어

품질이 낮은 데이터를 대규모 언어 모델(LLM)에 공급하는 데 있어 주요 과제는 무엇입니까?

1. [ ] 이는 새로운 정보에 대한 모델의 능력을 향상시킵니다.
2. [✓] 그 결과 편향된 출력, 편향된 응답, 신뢰할 수 없는 예측이 발생합니다.
3. [ ] 이는 LLM의 성능에 영향을 미치지 않습니다.
4. [ ] LLM의 교육 과정이 빨라집니다.

**Correct Answer:** 2

---

## Question 128

**Category:** LLMs
**Difficulty:** medium

### English

What does "zero-shot learning" refer to in the context of LLMs?

1. [✓] The model's ability to learn new tasks without any prior examples or training.
2. [ ] The model's ability to perform tasks with zero errors.
3. [ ] The initial stage of training where the model has no knowledge.
4. [ ] The process of fine-tuning the model on a specific task.

### 한국어

1. LLM에서 '제로샷 러닝'이란 무엇을 의미합니까?

1. [✓] ① 모델은 사전 지식나 훈련 없이도 새로운 작업을 학습할 수 있는 능력을 갖추고 있습니다.
2. [ ] ② 모델이 오류 없이 작업을 수행할 수 있는 능력입니다.
3. [ ] ③ 모델이 아무런 지식도 가지고 있지 않은 환경의 초기 단계입니다.
4. [ ] ④ 특정 작업에 맞게 모델을 미세 조정하는 과정입니다.

**Correct Answer:** 1

---

## Question 129

**Category:** LLMs
**Difficulty:** medium

### English

What is the core principle behind few-shot learning in Large Language Models (LLMs)?

1. [ ] LLMs require massive amounts of labeled data to learn any task.
2. [✓] LLMs can learn to perform tasks by observing only a few examples or demonstrations.
3. [ ] LLMs can only generate text, not understand or classify it.
4. [ ] LLMs are incapable of adapting to new tasks without extensive retraining.

### 한국어

2. 대규모 언어 모델(LLM)에서 퓨샷 학습의 핵심 원리는 무엇입니까?

1. [ ] ① LLM은 어떤 작업을 학습하기 위해 엄청난 양의 레이블이 지정된 데이터가 필요합니다.
2. [✓] ② LLM은 몇 가지 예시만 관찰해도 작업을 수행하는 방법을 배울 수 있습니다.
3. [ ] ③ LLM은 텍스트를 생성할 수만 있고 이해하거나 분류할 수는 없습니다.
4. [ ] ④ LLM은 광범위한 재교육 없이는 새로운 업무에 적용할 수 없습니다.

**Correct Answer:** 2

---

## Question 130

**Category:** LLMs
**Difficulty:** medium

### English

How does instruction fine-tuning improve the performance of LLMs?

1. [ ] It increases the model's size and complexity
2. [✓] It enables the model to understand and follow instructions more accurately.
3. [ ] It makes the model more creative and capable of generating diverse outputs.
4. [ ] It reduces the need for large-scale pre-training

### 한국어

3. 교육 세부 조정을 통해 LLM의 성과가 어떻게 향상됩니까?

1. [ ] ① 모델의 크기와 복잡성이 증가합니다.
2. [✓] ② 이를 통해 모델의 지식을 더 정확하게 이해하고 따를 수 있습니다.
3. [ ] ③ 이를 통해 모델은 더욱 창의적이 되고 다양한 결과물을 생성할 수 있습니다.
4. [ ] ④ 대규모 사전 훈련의 필요성이 줄어듭니다.

**Correct Answer:** 2

---

## Question 131

**Category:** LLMs
**Difficulty:** medium

### English

What does cross-entropy loss measure in the context of LLMs?

1. [ ] The difference between predicted and actual numerical values.
2. [✓] The dissimilarity between the predicted probability distribution of words and the actual distribution in the training data
3. [ ] The margin between correct and incorrect classifications.
4. [ ] The distance between two probability distributions.

### 한국어

4. LLM 맥락에서 교차 엔트로피 손실은 무엇을 측정합니까?

1. [ ] ① 예측된 수치와 실제 수치의 차이.
2. [✓] ② 예측된 단어의 확률 분포와 훈련 데이터에서의 실제 분포의 차이
3. [ ] ③ 올바른 분류와 잘못된 분류 사이의 차이.
4. [ ] ④ 두 확률 분포 사이의 거리.

**Correct Answer:** 2

---

## Question 132

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary goal of LLM alignment?

1. [ ] Maximizing the accuracy of language models on benchmark datasets.
2. [ ] Making sure LLMs generate the most creative and entertaining responses possible.
3. [✓] Ensuring that the behavior and outputs of LLMs are in line with human values, preferences, and ethical principles
4. [ ] Reducing the computational resources required to train LLMs.

### 한국어

LLM 정의의 주요 목표는 무엇입니까?

1. [ ] 벤치마크 데이터 세트에서 얻어진 모델의 정확도를 극대화합니다.
2. [ ] LLM이 가능한 한 가장 창의적이고 재미있는 답변을 낼 수 있도록 보장합니다.
3. [✓] LLM 행동의 결과가 인간의 가치, 신뢰도 및 윤리 원칙에 부합하는지 확인합니다.
4. [ ] LLM을 훈련하는 데 필요한 컴퓨팅 리소스를 줄입니다.

**Correct Answer:** 3

---

## Question 133

**Category:** LLMs
**Difficulty:** medium

### English

Which aspect of LLM output evaluation focuses on the grammatical correctness and natural flow of the generated text?

1. [ ] Accuracy
2. [✓] Fluency
3. [ ] Relevance
4. [ ] Coherence

### 한국어

LLM 결과를 평가할 어떤 측정이 생성된 텍스트의 문법적 정확성과 자연스러운 흐름에 초점을 맞춥니까?

1. [ ] 정확성
2. [✓] 유창성
3. [ ] 관련성
4. [ ] 통일

**Correct Answer:** 2

---

## Question 134

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is a primary expectation from learning the fundamentals of machine learning?

1. [✓] Understanding different machine learning algorithms and their applications
2. [ ] Writing low-level assembly code for GPUs
3. [ ] Developing new operating systems for AI workloads
4. [ ] Designing hardware components for deep learning models

### 한국어




**Correct Answer:** 1

---

## Question 135

**Category:** NLP
**Difficulty:** medium

### English

A lower perplexity score indicates:

1. [ ] The model is less confident in its predictions.
2. [ ] The model is more likely to produce grammatically incorrect sentences.
3. [✓] The model is better at predicting the next word in a sequence.
4. [ ] The model is less suitable for language generation tasks.

### 한국어

낮은 등차도 점수는 다음을 나타냅니다.

1. [ ] 해당 모델은 예측에 대한 신뢰도가 낮습니다.
2. [ ] 이 모델은 문맥적으로 관련성 있는 문장을 생성할 가능성이 더 높습니다.
3. [✓] 이 모델은 시퀀스의 다음 단어를 예측하는 데 더 뛰어납니다.
4. [ ] 이 모델은 언어 생성 작업에 적합하지 않습니다.

**Correct Answer:** 3

---

## Question 136

**Category:** LLMs
**Difficulty:** medium

### English

Why is human feedback crucial in identifying biases in LLM outputs?

1. [✓] Humans are better at detecting subtle biases and nuances in language than automated systems.
2. [ ] Humans can provide large amounts of labeled data for retraining LLMs.
3. [ ] Humans are immune to biases and can therefore provide perfectly objective feedback.
4. [ ] Human feedback is the only way to evaluate the performance of LLMs.

### 한국어

LLM 결과문의 함량을 파악하는 데 인간의 피드백이 왜 중요한가요?

1. [✓] 언어를 자동화된 시스템보다 언어 속의 미묘한 편차와 차 nuance를 더 잘 감지합니다.
2. [ ] 인간은 LLM을 추적하여 학습의 레이블이 지정된 데이터피드백을 제공할 수 있습니다.
3. [ ] 인간은 환경에 맞게 있음으로 존엄함하면서 객관적인 피드백을 제공할 수 있습니다.
4. [ ] LLM의 성과를 평가할 수 있는 유일한 방법은 인간의 피드백입니다.

**Correct Answer:** 1

---

## Question 137

**Category:** Training Techniques
**Difficulty:** medium

### English

GPUs possess dedicated high-bandwidth memory. What benefit does this provide during LLM training?

1. [ ] Enables faster data transfer between the CPU and GPU
2. [ ] Allows for the storage of larger LLM models
3. [ ] Reduces the overall power consumption of the system
4. [✓] Facilitates quick access and processing of vast amounts of training data

### 한국어

GPU는 적은 그래픽 메모리를 가지고 있습니다. 이는 LLM 학습 중에 어떤 이점을 제공합니까?

1. [ ] CPU와 GPU 간의 더 빠른 데이터 전송을 가능하게 합니다.
2. [ ] 더 큰 LLM 모델을 저장할 수 있습니다.
3. [ ] 시스템의 전체 전력을 절감할 수 있습니다.
4. [✓] 대량의 입력 교육 데이터에 대한 빠른 검색 및 처리를 용이하게 합니다.

**Correct Answer:** 4

---

## Question 138

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is the role of 'Data' in machine learning?

1. [✓] It provides the examples and patterns the model learns from.
2. [ ] It acts as the brain of the model.
3. [ ] It determines the accuracy of the model.
4. [ ] It has no significant role in machine learning.

### 한국어

머신러닝에서 '데이터'의 역할은 무엇인가요?

1. [✓] 모델이 학습할 예제와 패턴을 제공합니다.
2. [ ] 이는 모델의 틀이나 역할을 합니다.
3. [ ] 이는 모델의 정체성을 결정합니다.
4. [ ] 머신러닝에서는 중요한 역할이 없습니다.

**Correct Answer:** 1

---

## Question 139

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

In the context of predicting house sale prices, what is the role of the 'Algorithm'?

1. [ ] It represents the final predicted sale price of the house.
2. [ ] It is the data used to train the model, such as square footage and number of bedrooms.
3. [✓] It is the specific machine learning model (e.g., linear regression, decision tree) that learns the relationship between features like square footage and the sale price.
4. [ ] It refers to the process of selecting and transforming features, such as creating a new feature that combines square footage and a number of bedrooms.

### 한국어

주택 매매 가격을 예측하는 머신러닝에서 '출력값(목표)'의 역할은 무엇인가요?

1. [ ] 이는 주택의 실제 매매 가격을 나타냅니다.
2. [ ] 모델을 훈련하는 데 사용되는 데이터로, 입력값 될 수 없이 있습니다.
3. [✓] 이는 현재의 판매 가격 및 동의 환경을 예측하는 특정 머신 러닝 모델(예: 선형 회귀, 의사결정 트리)입니다.
4. [ ] 이는 현재의 정보 수끌 결합된 새로운 특징을 만드는 것과 같이 특징을 선택하고 변형하는 과정을 말합니다.

**Correct Answer:** 3

---

## Question 140

**Category:** Deep Learning
**Difficulty:** medium

### English

Which of the following utilizes artificial neural networks with multiple layers to learn complex patterns in data?

1. [✓] Deep Learning
2. [ ] Artificial Intelligence
3. [ ] Machine Learning
4. [ ] Robotics

### 한국어

다음 중 여러 층으로 구성된 인공 신경망을 활용하여 데이터의 복잡한 패턴을 학습하는 것은 무엇입니까?

1. [✓] 딥러닝
2. [ ] 인공지능
3. [ ] C-머신 러닝
4. [ ] 초보자 학습

**Correct Answer:** 1

---

## Question 141

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

In which type of machine learning does the algorithm learn from labeled data, where the correct output is provided for each input example?

1. [ ] Unsupervised Learning
2. [✓] Supervised Learning
3. [ ] Reinforcement Learning
4. [ ] Transfer Learning

### 한국어

각 입력 데이터에 대해 올바른 출력이 레이블이 지정된 데이터에서 알고리즘이 학습하는 머신 러닝 유형은 무엇입니까?

1. [ ] 비지도 학습
2. [✓] 지도 학습
3. [ ] C-강화 학습
4. [ ] 전이 학습

**Correct Answer:** 2

---

## Question 142

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

When selecting a machine learning model, what is a common trade-off that practitioners need to consider?

1. [ ] Accuracy vs. Speed
2. [✓] Complexity vs. Interpretability
3. [ ] Data Size vs. Model Size
4. [ ] Supervised vs. Unsupervised Learning

### 한국어

머신 러닝 모델을 선택할 때 실무자가 고려해야 할 일반적인 균형점은 무엇인가요?

1. [ ] 정확도 대 속도
2. [✓] 복잡성 대 해석 가능성
3. [ ] C-데이터 필요량 대 모델 크기
4. [ ] 지도 학습 vs. 비지도 학습

**Correct Answer:** 2

---

## Question 143

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English




### 한국어

머신 러닝의 기본을 배우는 데 있어 가장 기대되는 것은 무엇입니까?

1. [✓] 다양한 머신 러닝 알고리즘과 그 응용 프로그램의 이해
2. [ ] GPU와 최적화 연관성을 빠르게 적기
3. [ ] 새 워크로드를 위한 새로운 운영 체제 개발
4. [ ] 머신 러닝 모델을 위한 하드웨어 구성 요소 설계

**Correct Answer:** 1

---

## Question 144

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English




### 한국어

다음 중 AI, 머신러닝, 딥러닝의 관계를 가장 잘 설명하는 것은 무엇입니까?

1. [ ] AI는 머신 러닝에 의해 완전히 구현된 기술입니다.
2. [✓] 머신 러닝은 AI의 하위 집합이고 딥 러닝은 머신 러닝의 하위 집합입니다.
3. [ ] 머신러닝과 딥러닝은 AI와 완전히 별개입니다.
4. [ ] 딥러닝은 AI와 머신러닝을 모두 포함하는 더 광범위한 개념입니다.

**Correct Answer:** 2

---

## Question 145

**Category:** Reinforcement Learning
**Difficulty:** medium

### English




### 한국어

강화 학습은 에이전트가 환경과 상호 작용하고 보상이나 페널티를 받아 학습하는 것을 포함합니다. 참 또는 거짓을 나타냅니다.

1. [✓] 진실
2. [ ] 거짓

**Correct Answer:** 1

---

## Question 146

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?

1. [ ] AI is a subset of Deep Learning, which is a subset of Machine Learning
2. [✓] Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning
3. [ ] Machine Learning and Deep Learning are completely separate from AI
4. [ ] Deep Learning is a broader concept that includes both AI and Machine Learning

### 한국어




**Correct Answer:** 2

---

## Question 147

**Category:** Reinforcement Learning
**Difficulty:** medium

### English

Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False

1. [✓] True
2. [ ] False

### 한국어




**Correct Answer:** 1

---

## Question 148

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the primary purpose of feature scaling in machine learning?

1. [ ] It improves the interpretability of categorical data
2. [✓] It prevents certain features from dominating others due to different scales
3. [ ] It removes duplicate rows from the dataset
4. [ ] It eliminates the need for model validation

### 한국어




**Correct Answer:** 2

---

## Question 149

**Category:** Preprocessing
**Difficulty:** medium

### English

What is the purpose of StandardScaler() in sklearn.preprocessing?

1. [ ] It converts categorical variables into numerical values
2. [ ] It normalizes features by scaling them between 0 and 1
3. [✓] It standardizes features by removing the mean and scaling to unit variance
4. [ ] It replaces missing values in a dataset

### 한국어




**Correct Answer:** 3

---

## Question 150

**Category:** NLP
**Difficulty:** medium

### English

Which key feature of sequence models enables them to excel at natural language processing tasks like machine translation, where understanding the context of words in a sentence is crucial?

1. [✓] Capture Dependencies
2. [ ] Handle Variable Length
3. [ ] Predict Future Values
4. [ ] Generate New Sequences

### 한국어

시퀀스 모델의 어떤 주요 특징이 기계 번역과 같은 자연어 처리 작업에서 탁월한 성과를 낼 수 있게 해주는가? 이 작업에서 문장 속 단어의 맥락을 이해하는 것이 중요하다.

1. [✓] 중축성 편차
2. [ ] 가변 길이 처리
3. [ ] 미래 가치 예측
4. [ ] 새로운 시퀀스 생성

**Correct Answer:** 1

---

## Question 151

**Category:** Deep Learning
**Difficulty:** medium

### English

Which of the following architectures are designed to mitigate the vanishing gradient problem? (Choose 2 Correct Answers)

1. [ ] Convolutional Neural Networks (CNNs)
2. [✓] Long Short-Term Memory (LSTM) networks
3. [ ] Gated Recurrent Units (GRUs)
4. [ ] Generative Adversarial Networks (GANs)
5. [ ] Multilayer Perceptrons (MLPs)

### 한국어

다음 아키텍처 중 어느 것이 그래디언트 소실 문제를 완화하도록 설계되었습니까? (정답 2개 선택)

1. [ ] 합성곱 신경망(CNN)
2. [✓] 장단기 메모리(LSTM) 네트워크
3. [ ] 게이트형 순환 회로(GRU)
4. [ ] 생성적 적대 신경망(GAN)
5. [ ] 다층 퍼셉트론(MLP)

**Correct Answer:** 2

---

## Question 152

**Category:** Model Optimization
**Difficulty:** medium

### English

Which technique involves reducing the precision of model parameters to achieve a smaller model size and faster inference?

1. [ ] Pruning
2. [✓] Quantization
3. [ ] Knowledge Distillation
4. [ ] Transfer Learning

### 한국어

어떤 기술이 모델 매개변수의 정밀도를 낮춰 더 작은 모델 크기와 더 빠른 추론을 달성하는 것일까요?

1. [ ] 전정
2. [✓] 양자화
3. [ ] 지식 증류
4. [ ] 전이 학습

**Correct Answer:** 2

---

## Question 153

**Category:** ONNX
**Difficulty:** medium

### English

How does ONNX act as an "interoperability bridge"?

1. [ ] It translates code between different programming languages used in machine learning.
2. [✓] It enables seamless exchange and deployment of models across various frameworks and hardware platforms.
3. [ ] It creates a standardized API for interacting with all machine learning models.
4. [ ] It provides a cloud-based platform for storing and sharing machine learning models.

### 한국어

ONNX는 어떻게 '상호운용성 브리지' 역할을 하나요?

1. [ ] 머신 러닝에 사용되는 다양한 프로그래밍 언어 간의 코드를 번역합니다.
2. [✓] 다양한 프레임워크와 하드웨어 플랫폼에서 모델을 원활하게 교환하고 배포할 수 있습니다.
3. [ ] 모든 머신 러닝 모델과 상호작용하기 위한 표준화된 API를 만듭니다.
4. [ ] 머신 러닝 모델을 저장하고 공유하기 위한 클라우드 기반 플랫폼을 제공합니다.

**Correct Answer:** 2

---

## Question 154

**Category:** ONNX
**Difficulty:** medium

### English

What is the key benefit of using ONNX Runtime?

1. [ ] It simplifies the process of training machine learning models.
2. [✓] It optimizes model execution for improved performance across diverse platforms.
3. [ ] It automatically generates synthetic data for training models.
4. [ ] It ensures that all models achieve the same level of accuracy.

### 한국어

ONNX 런타임을 사용하는 주요 이점은 무엇입니까?

1. [ ] 머신 러닝 모델을 실행하는 과정을 간소화합니다.
2. [✓] 다양한 플랫폼에서 성능을 향상시키기 위해 모델 실행을 최적화합니다.
3. [ ] 모델을 훈련하기 위한 합성 데이터를 자동으로 생성합니다.
4. [ ] 이를 통해 모든 모델이 동일한 수준의 정확도를 달성할 수 있습니다.

**Correct Answer:** 2

---

## Question 155

**Category:** Model Evaluation
**Difficulty:** medium

### English

What is meant by "model drift" in the context of large language models (LLMs)?

1. [ ] The model's ability to adapt to new language patterns over time.
2. [✓] The gradual decrease in a model's accuracy and effectiveness due to changes in data distribution
3. [ ] The tendency of a model to generate biased or harmful content
4. [ ] The process of fine-tuning a pre-trained model on a specific task.

### 한국어

대규모 언어 모델(LLM)의 맥락에서 '모델 드리프트'란 무엇을 의미합니까?

1. [ ] 시간이 지남에 따라 새로운 언어 패턴에 적응할 수 있는 모델의 능력.
2. [✓] 데이터의 분포가 변화로 인해 모델의 정확도와 효과성이 점차 감소하는 현상
3. [ ] 모델이 편향적이거나 유해한 콘텐츠를 생성하는 경향
4. [ ] 특정 작업에 맞춰 사전 학습된 모델을 미세 조정하는 과정입니다.

**Correct Answer:** 2

---

## Question 156

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

The F1 Score is calculated as the:

1. [ ] Arithmetic mean of precision and recall
2. [✓] Harmonic mean of precision and recall
3. [ ] Product of precision and recall
4. [ ] Difference between precision and recall

### 한국어

F1 점수는 다음과 같이 계산됩니다.

1. [ ] 정밀도와 재현율의 산술 평균
2. [✓] 정밀도와 재현율의 조화 평균
3. [ ] 정밀도와 재현율의 차이
4. [ ] 정밀도와 재현율의 곱

**Correct Answer:** 2

---

## Question 157

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary focus of NVIDIA AI Enterprise?

1. [ ] Developing cutting-edge hardware for AI research.
2. [✓] Providing a comprehensive platform for the entire AI model lifecycle.
3. [ ] Exclusively focusing on large language model (LLM) development.
4. [ ] Creating open-source AI frameworks and libraries.

### 한국어

NVIDIA AI Enterprise의 주요 초점은 무엇입니까?

1. [ ] AI 연구를 위한 최첨단 하드웨어 개발
2. [✓] AI 모델 수명 주기 전반에 대한 포괄적인 플랫폼을 제공합니다.
3. [ ] 대규모 언어 모델(LLM) 개발에만 집중합니다.
4. [ ] 오픈소스 프레임워크와 라이브러리를 만듭니다.

**Correct Answer:** 2

---

## Question 158

**Category:** Model Deployment
**Difficulty:** medium

### English

Which of the following is a common deployment strategy for Large Language Models (LLMs)?

1. [✓] Deploying the model as a cloud-based API
2. [ ] Running the model only on local machines without any networking
3. [ ] Avoiding scaling considerations for inference
4. [ ] Using only on-premises hardware with no updates

### 한국어

다음 중 대규모 언어 모델(LLM)에 대한 일반적인 배포 전략은 무엇입니까?

1. [✓] 모델을 클라우드 기반 API로 배포
2. [ ] 네트워크 없이 로컬 머신에서 모델 실행
3. [ ] 추론을 위한 스케일링 고려 사항 피하기
4. [ ] 업데이트 없이 온프레미스 하드웨어만 사용

**Correct Answer:** 1

---

## Question 159

**Category:** Monitoring and Evaluation
**Difficulty:** medium

### English

Which of the following is a common metric used to monitor LLMs in production?

1. [ ] Number of training epochs
2. [✓] Response latency
3. [ ] Model parameter count
4. [ ] Number of layers in the neural network

### 한국어

다음 중 프로덕션에서 LLM을 모니터링하는 데 사용되는 일반적인 지표는 무엇입니까?

1. [ ] 훈련 에포크 수
2. [✓] 응답 지연 시간
3. [ ] 모델 매개변수 개수
4. [ ] 신경망의 계층 수

**Correct Answer:** 2

---

## Question 160

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary benefit of using NVIDIA’s ecosystem for LLM deployment?

1. [✓] Hardware-accelerated inference and training for high-efficiency
2. [ ] Completely replacing deep learning frameworks like PyTorch and TensorFlow
3. [ ] Eliminating the need for cloud-based deployments
4. [ ] Avoiding AI model fine-tuning

### 한국어

LLM 배포에 NVIDIA의 생태계를 사용하는 주요 이점은 무엇입니까?

1. [✓] 고효율을 위한 하드웨어 가속을 통한 학습
2. [ ] PyTorch나 TensorFlow와 같은 딥러닝 프레임워크를 완전히 대체
3. [ ] 클라우드 기반 배포의 필요성 제거
4. [ ] AI 모델 미세 조정 방지

**Correct Answer:** 1

---

## Question 161

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is the primary purpose of prompt engineering?

1. [ ] To train an AI language model from scratch
2. [✓] To unlock the full potential of an AI language model and get the best possible results
3. [ ] To replace human writers with AI
4. [ ] To limit the capabilities of an AI language model

### 한국어

신속한 엔지니어링의 주요 목적은 무엇입니까?

1. [ ] AI 언어 모델을 처음부터 훈련하려면
2. [✓] AI 언어 모델의 잠재력을 최대한 활용하여 최상의 결과를 얻으려면
3. [ ] 인간 작가를 새로 대체하기 위해
4. [ ] AI 언어 모델의 기능을 제한하려면

**Correct Answer:** 2

---

## Question 162

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is prompt design in the context of AI language models?

1. [ ] A random process of generating input for the model
2. [✓] The art of crafting clear and specific instructions to guide the AI's output
3. [ ] A complex coding language used to program AI models
4. [ ] A method for limiting the AI's capabilities

### 한국어

AI 언어 모델의 맥락에서 신속한 디자인이란 무엇인가?

1. [ ] 모델에 대한 입력을 생성하는 무작위 프로세스
2. [✓] AI의 출력을 안내하기 위한 명확하고 구체적인 지침을 작성하는 기술
3. [ ] AI 모델을 프로그래밍하는 데 사용되는 복잡한 코딩 언어
4. [ ] AI의 역할을 제한하는 방법

**Correct Answer:** 2

---

## Question 163

**Category:** Prompt Engineering
**Difficulty:** medium

### English

What is the primary purpose of providing context in prompts for AI language models?

1. [ ] To confuse the AI and test its capabilities
2. [✓] To guide the AI's understanding and steer its output in the desired direction
3. [ ] To make the prompt longer and more complex
4. [ ] To provide the AI with irrelevant information

### 한국어

AI 언어 모델의 프롬프트에서 맥락을 제공하는 주된 목적은 무엇입니까?

1. [ ] AI를 훈련스럽게 하고 그 능력을 테스트하기 위해
2. [✓] AI의 이해를 안내하고 원하는 방향으로 출력을 조정합니다.
3. [ ] 프롬프트를 더 길고 복잡하게 만들려면
4. [ ] AI에게 관련 없는 정보를 제공하기 위해

**Correct Answer:** 2

---

## Question 164

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary goal of PEFT in the context of large language models (LLMs)?

1. [ ] To train a new LLM from scratch
2. [✓] To efficiently adapt pre-trained LLMs to specific tasks
3. [ ] To reduce the size of pre-trained LLMs
4. [ ] To improve the general language understanding of LLMs

### 한국어

대규모 언어 모델(LLM)의 맥락에서 PET의 주요 목표는 무엇입니까?

1. [ ] 새로운 LLM을 처음부터 교육하려면
2. [✓] 사전 훈련된 LLM을 특정 작업에 효율적으로 적용하려면
3. [ ] 사전 훈련된 LLM의 크기를 줄이려면
4. [ ] LLM의 일반적인 언어 이해력을 향상시키기 위해

**Correct Answer:** 2

---

## Question 165

**Category:** Natural Language Processing
**Difficulty:** medium

### English

What is the primary focus of prompt learning in natural language processing?

1. [ ] Training language models from scratch on massive datasets
2. [ ] Improving the general language understanding capabilities of language models
3. [✓] Teaching language models to better understand and respond to instructions or prompts
4. [ ] Reducing the size of pre-trained language models

### 한국어

자연어 처리에서 신속한 학습의 주요 초점은 무엇입니까?

1. [ ] 대규모 데이터 세트를 기반으로 처음부터 언어 모델 학습
2. [ ] 언어 모델의 일반 언어 이해 능력 향상
3. [✓] 지나친 프로프트를 더 잘 이해하고 이에 대응하기 위한 언어 모델 교육
4. [ ] 사전 학습된 언어 모델의 크기 줄이기

**Correct Answer:** 3

---

## Question 166

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA NeMo?

1. [ ] To create realistic images and videos
2. [✓] To simplify and accelerate the development and deployment of conversational AI models
3. [ ] To analyze large datasets for business insights
4. [ ] To translate text between different languages

### 한국어

NVIDIA NeMo의 주요 목적은 무엇입니까?

1. [ ] 사실적인 이미지와 비디오를 만들려면
2. [✓] 대화형 AI 모델의 개발 및 배포를 단순화하고 가속화하기 위해
3. [ ] 비즈니스 통찰력을 위해 대규모 데이터 세트를 분석하려면
4. [ ] 다양한 언어 간의 텍스트를 번역하려면

**Correct Answer:** 2

---

## Question 167

**Category:** Training Techniques
**Difficulty:** medium

### English

Why is it important to experiment with various prompts when working with AI language models?

1. [ ] To keep the AI entertained and prevent boredom.
2. [✓] To discover the most effective prompts for achieving desired outcomes.
3. [ ] To trick the AI into revealing its hidden capabilities.
4. [ ] To generate random and unpredictable responses.

### 한국어

AI 언어 모델을 사용할 때 다양한 프롬프트를 실행하는 것이 왜 중요한가요?

1. [ ] AI를 즐겁게 해주고 지루함을 방지하기 위해서입니다.
2. [✓] 원하는 결과를 얻기 위한 효과적인 프롬프트를 발견하세요.
3. [ ] AI를 속여 숨겨진 능력을 드러내게 하는 것입니다.
4. [ ] 무작위적이고 예측할 수 없는 반응을 생성합니다.

**Correct Answer:** 2

---

## Question 168

**Category:** Retrieval-Augmented Generation
**Difficulty:** medium

### English

What is the primary purpose of Retrieval Augmented Generation (RAG)?

1. [ ] To train large language models (LLMs) from scratch
2. [✓] To enhance the capabilities of LLMs by combining them with external knowledge sources
3. [ ] To reduce the size of LLMs
4. [ ] To replace human knowledge with AI

### 한국어

검색 증강 생성(RAG)의 주요 목적은 무엇입니까?

1. [ ] 대규모 언어 모델(LLM)을 처음부터 훈련하려면
2. [✓] 외부 지식 소스와 결합하여 LLM의 역량을 강화합니다.
3. [ ] LLM의 크기를 줄이려면
4. [ ] 인간의 지식을 AI로 대체하기 위해

**Correct Answer:** 2

---

## Question 169

**Category:** Retrieval-Augmented Generation
**Difficulty:** medium

### English

Which type of database is commonly used in RAG for efficient document retrieval?

1. [ ] Relational databases (SQL)
2. [ ] Blockchain databases
3. [ ] Flat file storage
4. [✓] Vector databases

### 한국어

RAG에서는 효율적인 문서 검색을 위해 일반적으로 어떤 유형의 데이터베이스를 사용합니까?

1. [ ] 관계형 데이터베이스(SQL)
2. [ ] 블록체인 데이터베이스
3. [ ] 클라우드 파일 저장
4. [✓] 벡터 데이터베이스

**Correct Answer:** 4

---

## Question 170

**Category:** Data Visualization
**Difficulty:** medium

### English

Which of the following visualization techniques is best suited for displaying the frequency of different categories or items?

1. [ ] Heatmap
2. [✓] Bar chart
3. [ ] Scattertext
4. [ ] Network graph

### 한국어

다음 시각화 기술 중에서 다양한 범주나 항목의 빈도를 표시하는 데 가장 적합한 것은 무엇인가요?

1. [ ] 히트맵
2. [✓] 막대형 차트
3. [ ] 산점도
4. [ ] 네트워크 그래프

**Correct Answer:** 2

---

## Question 171

**Category:** Data Visualization
**Difficulty:** medium

### English

What is the primary goal of text data visualization?

1. [ ] To make text data more aesthetically pleasing
2. [✓] To transform unstructured text into visual representations for easier understanding and analysis
3. [ ] To replace the need for reading and interpreting text
4. [ ] To create complex and intricate visual displays

### 한국어

텍스트 데이터 시각화의 주요 목표는 무엇인가요?

1. [ ] 텍스트 데이터를 대용 미적으로 만들기 위해
2. [✓] 구조화되지 않은 텍스트를 시각적 표현으로 변환하여 더 쉽게 이해하고 분석할 수 있도록 합니다.
3. [ ] 텍스트를 읽고 해석할 필요성을 대체하기 위해
4. [ ] 복잡하고 정교한 시각적 디스플레이를 만들려면

**Correct Answer:** 2

---

## Question 172

**Category:** Data Visualization
**Difficulty:** medium

### English

Word clouds are particularly effective for:

1. [ ] Showing the exact frequency of each word in a text
2. [ ] Displaying the relationships between different words or concepts
3. [✓] Highlighting the most prominent or frequent words in a text
4. [ ] Visualizing the sentiment or emotional tone of a text

### 한국어

워드 클라우드는 다음과 같은 경우에 특히 효과적입니다.

1. [ ] 텍스트에서 각 단어의 정확한 빈도 표시
2. [ ] 다양한 단어나 개념 간의 관계 표시
3. [✓] 텍스트에서 가장 눈에 띄거나 자주 등장하는 단어 강조하기
4. [ ] 텍스트의 감정이나 감정적 톤을 시각화합니다.

**Correct Answer:** 3

---

## Question 173

**Category:** Data Visualization
**Difficulty:** medium

### English

Which visualization technique is best suited for revealing relationships between two numerical variables?

1. [ ] Bar chart
2. [ ] Pie chart
3. [✓] Scatter plot
4. [ ] Heatmap

### 한국어

두 수치 변수 간의 관계를 밝히는 데 가장 적합한 시각화 기술은 무엇인가요?

1. [ ] 막대형 차트
2. [ ] 파이 차트
3. [✓] 산점도
4. [ ] 히트맵

**Correct Answer:** 3

---

## Question 174

**Category:** Data Visualization
**Difficulty:** medium

### English

Line charts are commonly used to:

1. [✓] Show trends or changes in data over time
2. [ ] Compare the frequencies of different categories
3. [ ] Display the distribution of values across two dimensions
4. [ ] Visualize the hierarchical structure of data

### 한국어

선형 차트는 일반적으로 다음과 같은 경우에 사용됩니다.

1. [✓] 시간 경과에 따라 데이터의 증분 또는 변화를 표시
2. [ ] 다양한 카테고리의 범주를 비교하려고 함
3. [ ] 두 숫자의 절대 값 비교 표시
4. [ ] 데이터의 계층 구조를 시각화합니다

**Correct Answer:** 1

---

## Question 175

**Category:** Data Analysis Tools
**Difficulty:** medium

### English

What is the primary purpose of CuDF in the context of data analysis?

1. [ ] To visualize large datasets
2. [✓] To provide a GPU-accelerated DataFrame library for data manipulation and analysis
3. [ ] To build machine learning models
4. [ ] To manage database connections

### 한국어

데이터 분석 영역에서 CuDF의 주요 목적은 무엇입니까?

1. [ ] 대규모 데이터 세트를 시각화하려면
2. [✓] 데이터 조작 및 처리을 위한 GPU 가속 DataFrame 라이브러리 제공
3. [ ] 머신 러닝 모델을 교육하려면
4. [ ] 데이터베이스 연결을 관리하려면

**Correct Answer:** 2

---

## Question 176

**Category:** Data Visualization
**Difficulty:** medium

### English

Which type of plot is ideal for showing correlations between two continuous variables?

1. [✓] Scatter Plot
2. [ ] Pie Chart
3. [ ] Bar Chart
4. [ ] Box Plot

### 한국어

두 연속 변수 간의 상관관계를 보여주는 데 가장 적합한 차트 유형은 무엇입니까?

1. [✓] 산점도
2. [ ] 바이올린 차트
3. [ ] 매트릭스 차트
4. [ ] 상자 그림

**Correct Answer:** 1

---

## Question 177

**Category:** Data Analysis Tools
**Difficulty:** medium

### English

Which of the following tasks can be accelerated using Dask-cuDF?

1. [ ] Creating deep learning models
2. [ ] Running web applications
3. [✓] Distributed DataFrame operations across multiple GPUs
4. [ ] Building NoSQL databases

### 한국어

다음 중 Dask-cuDF를 사용하여 가능하게 할 수 있는 작업은 무엇입니까?

1. [ ] 데이터 프레임 생성
2. [ ] 연 애플리케이션의 실행
3. [✓] 여러 GPU에 걸친 분산 DataFrame 작업
4. [ ] NoSQL 데이터베이스 구성

**Correct Answer:** 3

---

## Question 178

**Category:** Data Visualization
**Difficulty:** medium

### English

Which visualization method is most effective for analyzing the distribution of text lengths in a dataset?

1. [ ] Line Chart
2. [ ] Heatmap
3. [ ] Box Plot
4. [✓] Histogram

### 한국어

데이터 세트에서 텍스트의 깊이 분류를 분석하는 데 가장 효과적인 시간절약 방법은 무엇입니까?

1. [ ] 선형 서치
2. [ ] 히프를 사용
3. [ ] 상자 스키밍
4. [✓] 워크스루 활용

**Correct Answer:** 4

---

## Question 179

**Category:** LLMs
**Difficulty:** medium

### English

How do LLMs learn to generate human-like text?

1. [ ] By interacting with human users in real-time conversations
2. [✓] By leveraging massive datasets and algorithms to learn patterns in language
3. [ ] By being explicitly programmed with grammar and vocabulary rules
4. [ ] By observing human behavior in various settings

### 한국어

1. LLM은 어떻게 인간과 유사한 텍스트를 생성하는 방법을 택하나요?

1. [ ] 실시간 대화에서 인간 사용자와 상호 작용하여
2. [✓] 대규모 데이터 세트와 알고리즘을 활용하여 언어 패턴을 학습합니다.
3. [ ] 완벽한 이해 구체의 인식적으로 프로그래밍되어 있음
4. [ ] 다양한 환경에서 인간의 행동을 관찰함으로써

**Correct Answer:** 2

---

## Question 180

**Category:** LLMs
**Difficulty:** medium

### English

What is a key concern when developing and deploying large language models (LLMs)?

1. [ ] Ensuring they can generate creative and entertaining text.
2. [ ] Minimizing their computational requirements.
3. [✓] Identifying and mitigating potential biases in their output.
4. [ ] Maximizing their ability to generate code.

### 한국어

2. 대규모 언어 모델(LLM)을 개발할 때 목표할 때 가장 중요한 고려 사항은 무엇인가요?

1. [ ] 창의적이고 재미있는 텍스트를 생성할 수 있도록 보장합니다.
2. [ ] 개선 요구 사항을 최소화합니다.
3. [✓] 훈습하면서 정확한 문법과 철자를 완성합니다.
4. [ ] 모델 생성 비용을 극대화합니다.

**Correct Answer:** 3

---

## Question 181

**Category:** Training Techniques
**Difficulty:** medium

### English

Which hyperparameter tuning method systematically explores all possible combinations from a predefined set of values?

1. [✓] Grid Search
2. [ ] Random Search
3. [ ] Bayesian Optimization
4. [ ] Genetic Algorithms

### 한국어

3. 여러 정렬의 각 집합에 모든 가능한 조합을 체계적으로 탐색하는 하이퍼파라미터 튜닝 방법은 무엇인가요?

1. [✓] 그리드 검색
2. [ ] 무작위 검색
3. [ ] 베이지안 최적화
4. [ ] 유전 알고리즘

**Correct Answer:** 1

---

## Question 182

**Category:** Model Architecture
**Difficulty:** medium

### English

What are hyperparameters in the context of large language models (LLMs)?

1. [ ] The words and phrases used to train the model.
2. [✓] The internal settings that govern the model's architecture, learning rate, batch size, etc.
3. [ ] The output generated by the model in response to a prompt.
4. [ ] The evaluation metrics used to assess the model's performance.

### 한국어

4. 대규모 언어 모델(LLM)에서 일반적인 하이퍼파라미터는 무엇인가요?

1. [ ] 모델을 운영하는 핵심적인 하드웨어 구문입니다.
2. [✓] 모델의 아키텍처, 학습률, 배치 크기 등을 결정하는 내부 설정입니다.
3. [ ] 프로젝트에 대한 향후 모델의 성장을 측정합니다.
4. [ ] 모델의 성능을 평가하는 데 사용되는 평가 지표입니다.

**Correct Answer:** 2

---

## Question 183

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary purpose of A/B testing in the context of LLMs?

1. [ ] To randomly deploy different LLM versions without any evaluation.
2. [✓] To systematically evaluate different versions of LLMs and their impact on user experience and key metrics
3. [ ] To compare the performance of LLMs against traditional rule-based systems
4. [ ] To measure the computational efficiency of different LLM architectures

### 한국어

1. LLM에서 A/B 테스트의 주요 목적은 무엇입니까?

1. [ ] 평가 없이 다양한 LLM 버전을 무작위로 배포합니다.
2. [✓] 실험을 진행하여 변경된 사양과 특정 목표 지표에 미치는 영향을 체계적으로 평가합니다.
3. [ ] LLM의 성능을 기존 규제 시스템과 비교하면서
4. [ ] 다양한 LLM 아키텍처의 계산 효율성을 측정하면서

**Correct Answer:** 2

---

## Question 184

**Category:** Development Practices
**Difficulty:** medium

### English

What is the primary benefit of using a Version Control System (VCS) in LLM development regarding reproducibility?

1. [ ] It automatically improves the model’s accuracy.
2. [ ] It prevents any changes from being made to the code or data.
3. [✓] It allows for easy tracking of changes, enabling reversion to previous versions and replication of experiments.
4. [ ] It generates new versions of the model automatically.

### 한국어

2. 재현성과 관련하여 LLM 개발에서 버전 제어 시스템(VCS)을 사용하는 주요 이유는 무엇입니까?

1. [ ] 모델의 정확도가 자동으로 향상됩니다.
2. [ ] 코드나 데이터가 전환되는 것을 방지합니다.
3. [✓] 모델 개발 과정을 사양과 다른 버전으로 되돌리고 실험을 재현할 수 있습니다.
4. [ ] 모델의 새로운 버전을 자동으로 생성합니다.

**Correct Answer:** 3

---

## Question 185

**Category:** Development Practices
**Difficulty:** medium

### English

Why is version control important for large language model (LLM) projects?

1. [ ] It allows for faster training of LLMs by optimizing computational resources.
2. [✓] It enables reproducibility, collaboration, and efficient management of LLM projects.
3. [ ] It prevents LLMs from making errors during text generation.
4. [ ] It automates hyperparameter tuning for better model performance.

### 한국어

3. 대규모 언어 모델(LLM) 프로젝트에 버전 제어가 중요한 이유는 무엇입니까?

1. [ ] 이를 통해 개인 리소스를 최적화하여 LLM의 학습 속도를 높일 수 있습니다.
2. [✓] LLM 프로젝트의 개선과, 협업 및 효율적인 관리가 가능합니다.
3. [ ] 이를 통해 LLM의 레벨과 성능 등에 오류를 찾는 과정을 실행할 수 있습니다.
4. [ ] 더 나은 모델 성능을 위해 하이퍼파라미터 튜닝을 재정립합니다.

**Correct Answer:** 2

---

## Question 186

**Category:** LLMs
**Difficulty:** medium

### English

Why is the BioNeMo LLM service particularly suitable for the biomedical and pharmaceutical industries?

1. [ ] Because it generates medical content based on general language models
2. [✓] Because it is pre-trained on massive biomedical datasets and allows customization for specific tasks
3. [ ] Because it replaces the need for human expertise in healthcare decision-making
4. [ ] Because it primarily focuses on real-time conversations with healthcare professionals

### 한국어

4. BioNeMo LLM 서비스가 생물의학 및 헬스 산업에 특히 적합한 이유는 무엇입니까?

1. [ ] 평가 없이 모델을 기반으로 의료 컨텐츠를 생성하기 때문이며
2. [✓] 대규모 의료 데이터세트에 대한 사전 학습 없이도 특정 질병에 대한 사용자의 정의가 가능하기 때문입니다.
3. [ ] 이는 의료 원격진료에 있어 인간의 질병 예측이 좀 더 용이 하기 때문입니다.
4. [ ] 주요 의료 과정에서의 실시간 데이터의 흐름을 유지기 때문입니다.

**Correct Answer:** 2

---

## Question 187

**Category:** AI Agents
**Difficulty:** medium

### English

How do NVIDIA AI Agents perceive and interact with their environment?

1. [ ] By following pre-programmed scripts for user interactions
2. [✓] By processing visual and auditory inputs using computer vision and natural language models
3. [ ] By only responding to text-based user commands
4. [ ] By relying solely on predefined responses without real-time reasoning

### 한국어

5. NVIDIA AI 엔터프라이즈 솔루션은 이렇게 변환된 인식을 어떻게 향상하고 신속 적용합니까?

1. [ ] 사용자 속성을 위한 새로운 사전 프로그램과의 스크립트를 만들고
2. [✓] 현재의 비전과 작업의 다양한 사용이 시각적 및 관심적 인식을 제공함으로써
3. [ ] 텍스트로부터 사용자의 정밀한 단평을 모으고
4. [ ] 실시간 추천 없이 미리 정의된 응답만을 일관함으로써

**Correct Answer:** 2

---

## Question 188

**Category:** Model Optimization
**Difficulty:** medium

### English

What is the primary purpose of Kernel Auto-Tuning?

1. [ ] To minimize memory usage during model execution
2. [ ] To enable parallel processing of multiple input streams
3. [✓] To select the most efficient kernels for a given GPU architecture
4. [ ] To optimize models for mixed-precision computation

### 한국어

커널 자동 튜닝의 주요 목적은 무엇입니까?

1. [ ] 같은 성능 중 메모리 사용을 최소화하려면
2. [ ] 여러 알고리즘의 병렬 처리를 활성화하려면
3. [✓] 주어진 GPU 아키텍처에 가장 적절한 커널을 선택하려면
4. [ ] 초밥 정도 계산을 위한 모델 최적화

**Correct Answer:** 3

---

## Question 189

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary focus of the NVIDIA BioNeMo LLM Service?

1. [ ] General-purpose language tasks
2. [ ] Financial analysis and predictions
3. [✓] Biomedical and pharmaceutical applications
4. [ ] Image and video processing

### 한국어

NVIDIA BioNeMo LLM 서비스의 주요 초점은 무엇입니까?

1. [ ] 일반 언어 작업
2. [ ] 재무 분석 및 예측
3. [✓] 생물학적 및 화학 응용 분야
4. [ ] 이미지 및 비디오 처리

**Correct Answer:** 3

---

## Question 190

**Category:** AI Agents
**Difficulty:** medium

### English

Which of the following capabilities falls under the “Perception” aspect of NVIDIA AI Agents?

1. [ ] Generating creative text responses
2. [✓] Processing visual and auditory input to understand the environment
3. [ ] Making complex decisions based on internal knowledge
4. [ ] Planning a sequence of actions to achieve a goal

### 한국어

다음 기능 중 NVIDIA AI Agents의 “지각” 측면에 속하는 것은 무엇입니까?

1. [ ] 정확한 테스트 로봇 생성
2. [✓] 주변 환경을 이해하기 위해 시각적, 청각적 입력을 처리합니다.
3. [ ] 내부 자신이 기계적 발전과 심화 연결
4. [ ] 목표를 중심하기 위한 일반의 행동 계획

**Correct Answer:** 2

---

## Question 191

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the core idea behind the Mixture of Experts (MoE) architectural paradigm?

1. [ ] Training multiple smaller models and combining their outputs.
2. [✓] Dividing the model into multiple specialized experts, each focusing on a specific task or domain
3. [ ] Reducing the size of the model by removing unnecessary parameters
4. [ ] Fine-tuning the model on a large dataset of diverse tasks

### 한국어

전문가 혼합(MoE) 모델 패러다임의 핵심 아이디어는 무엇입니까?

1. [ ] 여러 개의 작은 모델을 훈련하고 각각의 출력을 결합합니다.
2. [✓] 모델을 특정 작업이나 도메인에 연공하는 여러 전문가를 분할
3. [ ] 집중적으로 예방처리를 피하면서 모델 크기 줄이기
4. [ ] 다양한 작업의 대규모 데이터셋에 대한 모델 미세 조정

**Correct Answer:** 2

---

## Question 192

**Category:** Model Deployment
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA Triton Inference Server?

1. [ ] To train large language models (LLMs) from scratch.
2. [✓] To simplify the deployment of AI models at scale in production.
3. [ ] To collect and preprocess data for model training.
4. [ ] To design and optimize model architectures.

### 한국어

1. NVIDIA Triton 추론 서버의 주요 목적은 무엇입니까?

1. [ ] 연구실 없이 딥러닝을 처음부터 훈련합니다.
2. [✓] 생산 환경에서 AI 모델을 대규모로 배포하는 기본 구조합니다.
3. [ ] 모델 학습을 위해 데이터를 수집하고 정제합니다.
4. [ ] 모델 연구개발을 수행하기 최적화합니다.

**Correct Answer:** 2

---

## Question 193

**Category:** AI Development
**Difficulty:** medium

### English

What is the main purpose of NVIDIA AI Workflows?

1. [ ] To provide a marketplace for buying and selling AI models.
2. [ ] To focus solely on data collection and preprocessing.
3. [✓] To streamline and accelerate the entire AI development process.
4. [ ] To automate the deployment of AI models in production.

### 한국어

2. NVIDIA AI 솔루션의 주요 목적은 무엇입니까?

1. [ ] AI 모델을 할당할 수 있는 시장을 제공합니다.
2. [ ] 데이터 신뢰성 강화를 보장합니다.
3. [✓] AI 개발 프로세스 전반의 효율성을 가속화합니다.
4. [ ] 프로덕션에서 모델의 빠른 작업을 지원합니다.

**Correct Answer:** 3

---

## Question 194

**Category:** Optimization
**Difficulty:** medium

### English

What is NVIDIA cuOpt?

1. [ ] A cloud-based platform for managing logistics operations
2. [✓] A GPU-accelerated optimization library
3. [ ] A deep learning framework for image recognition
4. [ ] A programming language for developing logistics software

### 한국어

3. NVIDIA cuOpt란 무엇입니까?

1. [ ] 유류 운영 문제를 위한 솔루션의 기본 플랫폼
2. [✓] GPU 가속 최적화 라이브러리
3. [ ] 이미지 인식을 위한 고급 라이브러리
4. [ ] 효율적 프로그램 개발을 위한 프로그래밍 언어

**Correct Answer:** 2

---

## Question 195

**Category:** Conversational AI
**Difficulty:** medium

### English

What is the primary purpose of NVIDIA RIVA?

1. [ ] To generate realistic images
2. [✓] To enable developers to build and deploy real-time, highly accurate conversational AI applications
3. [ ] To analyze large datasets for business insights
4. [ ] To translate text between different languages

### 한국어

4. NVIDIA Riva의 주요 목적은 무엇입니까?

1. [ ] 사전과 이미지 생성하기
2. [✓] 개발자가 실시간으로 음성 인식이 높은 대화형 AI 애플리케이션을 구축하고 배포할 수 있도록 지원
3. [ ] 비디오나 음성으로부터 대규모 데이터 세트를 분석하고 해석
4. [ ] 다양한 언어 간에 텍스트를 변환하기

**Correct Answer:** 2

---

## Question 196

**Category:** Recommender Systems
**Difficulty:** medium

### English

What is NVIDIA Merlin?

1. [ ] A cloud-based platform for managing customer relationships
2. [ ] A deep learning framework for image recognition
3. [✓] An open-source framework for building and deploying recommender systems
4. [ ] A programming language for developing e-commerce websites

### 한국어

5. NVIDIA Merlin이란 무엇입니까?

1. [ ] 고객 관계 관리를 위한 솔루션의 기본 플랫폼
2. [ ] 이미지 인식을 위한 라이브러리입니다
3. [✓] 추천 시스템 구성 및 배포를 위한 오픈 소스 프레임워크
4. [ ] 정보처리 형식에서 제품을 위한 프로그래밍 언어

**Correct Answer:** 3

---

## Question 197

**Category:** Explainable AI
**Difficulty:** medium

### English

The concept of Explainable AI (XAI) is most closely associated with which pillar of responsible AI?

1. [ ] Fairness
2. [✓] Transparency & Explainability
3. [ ] Accountability
4. [ ] Privacy

### 한국어

설명 가능한 AI(XAI) 개념은 책임 있는 AI의 기둥 중 가장 밀접하게 연관되어 있습니까?

1. [ ] 공정성
2. [✓] 투명성 및 설명 가능성
3. [ ] 책임
4. [ ] 존중

**Correct Answer:** 2

---

## Question 198

**Category:** Data Privacy
**Difficulty:** medium

### English

What is data consent in the context of AI and data handling?

1. [ ] Implicit agreement assumed from users when they use a service.
2. [✓] Explicit permission from individuals to collect, use, and share their data.
3. [ ] The right of companies to use data without informing users.
4. [ ] The process of obtaining data from public sources.

### 한국어

AI와 데이터 처리의 맥락에서 데이터 주권은 무엇입니까?

1. [ ] 사용자가 서비스를 사용할 때 명목적으로 동일답다고 가정합니다.
2. [✓] 개인이 자신의 데이터를 수집, 사용, 공유하도록 의식적으로 허가합니다.
3. [ ] 사용자가 명시적 강요만으로 데이터를 사용할 수 있는 개인의 권리.
4. [ ] 공공 소스에서 데이터를 얻는 과정.

**Correct Answer:** 2

---

## Question 199

**Category:** AI Safety
**Difficulty:** medium

### English

What is the primary purpose of Nvidia’s NeMo Guardrails toolkit?

1. [ ] To accelerate the training of large language models
2. [✓] To build safer and more controlled conversational AI models
3. [ ] To improve the accuracy of image recognition models
4. [ ] To optimize the performance of deep learning algorithms

### 한국어

Nvidia의 NeMo Guardrails를 통한 주요 목적은 무엇입니까?

1. [ ] 대규모 언어 모델의 학습을 가속화설명력
2. [✓] 더욱 안전하고 통제 가능한 대화형 AI 모델을 구축하려면
3. [ ] 이미지 인식 모델의 정확도를 향상시키기 위해
4. [ ] 일반적 알고리즘의 성능을 최적화하려면

**Correct Answer:** 2

---

## Question 200

**Category:** AI Fairness
**Difficulty:** medium

### English

What is the main goal of using the Omniverse Replicator in the context of AI fairness?

1. [ ] To improve the accuracy of AI models on benchmark datasets.
2. [✓] To generate synthetic data that enhances diversity and representation in training datasets
3. [ ] To create explainable AI models
4. [ ] To establish governance structures for AI development

### 한국어

AI 공정성 전략에서 Omniverse Replicator를 사용하는 주요 목표는 무엇입니까?

1. [ ] 복잡한 데이터 세트에서 AI 모델의 명확도를 개선합니다.
2. [✓] 훈련 데이터 세트의 다양성과 편견을 정량하는 합성 데이터를 생성합니다.
3. [ ] 설명 가능한 AI 모델을 연구하다
4. [ ] AI 개발을 위한 가상현실 구조 구축

**Correct Answer:** 2

---

## Question 201

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following statements is true about agglomerative clustering?

1. [ ] It's a top-down approach
2. [✓] It starts with each data point as its own cluster
3. [ ] It's computationally less expensive than divisive clustering for large datasets
4. [ ] It doesn't require a distance metric

### 한국어

다음 중 응집적 클러스터링에 관해 사실인 진술은 무엇입니까?

1. [ ] 그것은 상향식 접근 방식입니다
2. [✓] 각 데이터 포인트로 자체 클러스터로 시작됩니다.
3. [ ] 대규모 데이터 세트의 경우 분할 클러스터링보다 계산 비용이 저렴합니다.
4. [ ] 거리 측정이 필요하지 않습니다.

**Correct Answer:** 2

---

## Question 202

**Category:** AI Ethics
**Difficulty:** medium

### English

What is the primary goal of Trustworthy AI in NVIDIA's generative AI and LLMs?

1. [ ] A: To enhance AI performance without considering ethical implications
2. [✓] B: To ensure AI systems are reliable, safe, fair, transparent, and accountable
3. [ ] C: To make AI systems self-learning and fully autonomous
4. [ ] D: To prioritize AI accuracy over ethical considerations

### 한국어

1. NVIDIA의 생성 AI와 LLM에서 신뢰할 수 있는 AI의 주요 목표는 무엇입니까?

1. [ ] A. 문제의 모바일 경험에서 인지 성능 향상을시키고 있습니다.
2. [✓] B. AI 시스템이 윤리적이고 안정적인 결정으로부터 책임이 있는지 확인하기 위해
3. [ ] C. AI 시스템을 자체 학습하여 문제 해결하기 위해
4. [ ] D. 문제의 고급사용자만의 사용자 정의를 우선시합니다.

**Correct Answer:** 2

---

## Question 203

**Category:** Data Privacy
**Difficulty:** medium

### English

Why is data privacy crucial in artificial intelligence and large language model (LLM) development?

1. [ ] A: Because it ensures AI models can collect unlimited data for better performance
2. [✓] B: Because it builds trust, mitigates risks, ensures fairness, and complies with regulations
3. [ ] C: Because AI models require personal data to function effectively
4. [ ] D: Because it allows AI developers to bypass regulatory requirements

### 한국어

2. 인공지능과 대규모 언어 모델(LLM) 개발에 있어서 데이터 개인정보 보호가 왜 중요한가요?

1. [ ] A. 사용자가 민감한 행동을 위해 개인정보를 습득할 수 있도록 장려하기 때문입니다.
2. [✓] B. 신뢰 구축으로, 인류를 보호하며, 공정성을 보장하며, 규제를 준수하기 때문입니다.
3. [ ] C. AI 모델이 교육자료를 추천하면 개인 데이터가 필요하기 때문입니다.
4. [ ] D. 개발자가 국가 요구 사항을 무시할 수 있기 때문입니다.

**Correct Answer:** 2

---

## Question 204

**Category:** Data Privacy
**Difficulty:** medium

### English

Which of the following is a key approach used by NVIDIA to ensure data privacy in AI development?

1. [ ] A: Storing all collected data in centralized databases for easier access
2. [✓] B: Using federated learning, confidential computing, and privacy-preserving techniques
3. [ ] C: Collecting as much data as possible to improve AI accuracy
4. [ ] D: Ignoring data privacy concerns if the AI system operates in a country without strict regulations

### 한국어

3. 다음 중 NVIDIA가 개발에서 데이터 개인 정보 보호를 보장하기 위해 사용하는 주요 접근 방식은 무엇입니까?

1. [ ] A. 수집된 모든 데이터를 중앙 데이터베이스에서 저장하여 더 쉽게 접근 가능
2. [✓] B. 암호 학습, 커플 통계 및 개인 정보 보호 기술 사용
3. [ ] C. 왜곡중립 정책을 지배하는 공개 데이터 사용
4. [ ] D. 엄격한 규제가 없는 국가에서 시스템의 운용되는 경우 데이터 개인 정보 보호 문제를 무시합니다.

**Correct Answer:** 2

---

## Question 205

**Category:** AI Ethics
**Difficulty:** medium

### English

How does NVIDIA ensure AI trustworthiness in its solutions?

1. [✓] A: By embedding trustworthy AI principles at every stage of AI development
2. [ ] B: By manually reviewing AI outputs to ensure ethical compliance
3. [ ] C: By relying solely on third-party organizations to establish AI safety standards
4. [ ] D: By restricting AI models to avoid real-world applications

### 한국어

4. NVIDIA는 어떻게 복구 시뮬레이션의 AI 신뢰성을 보장합니까?

1. [✓] A. 개발된 모든 데이터를 디지털 있는 시스템을 보관함으로써
2. [ ] B. 문제의 고유 설정을 사용자 정보와 신뢰의 흐름을 보관합니다.
3. [ ] C. 신뢰성을 문제에 적용하여 생산적인 방법으로
4. [ ] D. 일반적인 응용 프로그램 및 일반적 규칙 기반 모델을 활용함으로써

**Correct Answer:** 1

---

## Question 206

**Category:** Bias Mitigation
**Difficulty:** medium

### English

How does NVIDIA approach bias mitigation in AI systems?

1. [ ] A: By relying solely on human-curated datasets for training
2. [ ] B: By completely eliminating bias through AI algorithms
3. [✓] C: By using the Omniverse Replicator to generate synthetic data
4. [ ] D: By avoiding transparency and explainability in AI models

### 한국어

5. NVIDIA는 AI 시스템의 문제 해결에 어떤 접근 방식을 취합니까?

1. [ ] A. 관련 통합 시뮬의 복구 방법을 데이터 AI에 포함하는 것은 잘못된 생각입니다. 따라서, 이는 강력한 설계 변경 및 디버깅이 심한 데이터를 AI로 통합합니다. NVIDIA는 대강연 데이터 통합 방식에 의해 발생 가능한 기능적 설계 강화를 제공합니다.
2. [ ] B. 복구를 위해 확장된 통합이 개선된 문제 해결 방법입니다. NVIDIA는 검증절로 관한 AI 설계의 끝점인 고급화 정책을 사용하며 클라우드를 사용하는 것이 있습니다. 또한 문제의 정비 관리자를 최소화하고 다른 팀과의 상호작용과 조화를 통해 ‘NVIDIA AI 실내 버전’ 응용을 권장하고 있습니다.
3. [✓] C. Omniverse Replicator 를 생산적 증명에서 해결하여 문제를 생성하기를 목표로 합니다. NVIDIA의 Omniverse Replicator를 사용하여 더 크고 다양한 데이터 문제를 제당하는 도구로, 스케일의 타임을 더 많이 얻어 봅니다. 자세한 내용은 'NVIDIA AI 문제 습관' 항목을 참조하십시오.
4. [ ] D. 문제의 방지 작업과 최종 실행을 함께 보장함으로써 이루어지는 것입입니다. NVIDIA는 AI의 방지 계약 설멩 강화를 권장하며, CI/CD 생산 서비스와의 파트너쉽 관계를 통해 설복할 수 있도록 합니다. 자세한 내용은 'NVIDIA의 최적 AI 지원' 항목을 참조하십시오.

**Correct Answer:** 3

---

## Question 207

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is the primary goal of a regression algorithm in machine learning?

1. [ ] To assign input data into predefined categories or classes.
2. [✓] To predict a continuous numerical value based on input features.
3. [ ] To group similar data points together based on their inherent patterns.
4. [ ] To discover hidden structures in unlabeled data.

### 한국어

머신 러닝에서 회귀 알고리즘의 주요 목표는 무엇인가요?

1. [ ] 입력 데이터로 미리 정의된 부분과 클래스에 할당합니다.
2. [✓] 입력 특징을 기반으로 연속적인 수치 값을 예측합니다.
3. [ ] 고유한 패턴을 기준으로 유사한 데이터 포인트를 그룹화합니다.
4. [ ] 레이블이 지정되지 않은 데이터에서 숨겨진 구조를 발견합니다.

**Correct Answer:** 2

---

## Question 208

**Category:** Model Architecture
**Difficulty:** medium

### English

What does LogisticRegression.coef_ represent in a logistic regression model?

1. [ ] The predicted probabilities for each class
2. [✓] The weights or coefficients assigned to each feature in the model
3. [ ] The accuracy of the model
4. [ ] The log-odds of the positive class

### 한국어

로지스틱 회귀 모델에서 LogisticRegression.coef_는 무엇을 나타내나요?

1. [ ] 각 클래스에 대한 예측 확률
2. [✓] 모델의 각 기능에 할당된 가중치 또는 계수
3. [ ] 모델의 정확도
4. [ ] 양의 클래스의 로그 오즈

**Correct Answer:** 2

---

## Question 209

**Category:** Clustering
**Difficulty:** medium

### English

Which Clustering method can help us to find clusters of arbitrary shapes?

1. [ ] K-Means Clustering
2. [ ] Hierarchical Clustering
3. [✓] DBScan Clustering
4. [ ] K-Medoids Clustering

### 한국어

어떤 클러스터링 방법이 임의의 모양의 클러스터를 찾는 데 도움이 될 수 있습니까?

1. [ ] 계층적 클러스터링
2. [ ] 계속적 클러스터링
3. [✓] DBScan 클러스터링
4. [ ] K-Medoids 클러스터링

**Correct Answer:** 3

---

## Question 210

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

What does a high recall indicate about the model?

1. [ ] The model has a low rate of false positives.
2. [✓] The model is excellent at identifying all instances of a specific class.
3. [ ] The model is good at predicting a specific class when it does predict it.
4. [ ] The model is well-balanced in terms of precision and recall.

### 한국어

높은 재현율은 모델에 대해 무엇을 나타내는가?

1. [ ] 해당 모델은 거짓 양성률이 높습니다.
2. [✓] 이 모델은 특정 클래스의 모든 인스턴스를 식별하는 데 매우 뛰어납니다.
3. [ ] 이 모델은 특정 클래스를 예측하는 데 효과적입니다.
4. [ ] 이 모델은 정밀도와 재현율 측면에서 균형이 잘 잡혀 있습니다.

**Correct Answer:** 2

---

## Question 211

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

Which metric is best suited for imbalanced datasets?

1. [ ] Accuracy
2. [ ] Recall
3. [ ] Precision
4. [✓] F1 Score

### 한국어

불균형 데이터 세트에 가장 적합한 지표는 무엇인가요?

1. [ ] 정확성
2. [ ] 정기하다
3. [ ] 정도
4. [✓] F1 점수

**Correct Answer:** 4

---

## Question 212

**Category:** Evaluation Metrics
**Difficulty:** medium

### English

Which of the following formulas represents precision?

1. [ ] TP / (TP + FN)
2. [✓] TP / (TP + FP)
3. [ ] (TP + TN) / (TP + FP + FN + TN)
4. [ ] 2 X Precision X Recall / (Precision + Recall)

### 한국어

다음 중 어느 공식이 정밀도를 나타내나요?

1. [ ] TP / (TP + FN)
2. [✓] TP / (TP + FP)
3. [ ] TP + TN / (TP + FP + FN + TN)
4. [ ] 2 x 정밀도 x 재현율 / (정밀도 + 재현율)

**Correct Answer:** 2

---

## Question 213

**Category:** Regression Analysis
**Difficulty:** medium

### English

What does an R-squared value of 0.85 indicate?

1. [✓] 85% of the variance in the target variable is explained by the model
2. [ ] The model's predictions are 85% accurate
3. [ ] The average error of the model is 0.85 units
4. [ ] 15% of the variance in the target variable is unexplained by the model

### 한국어

1. R-제곱 값이 0.85는 무엇을 나타냅니까?

1. [✓] 목표 변수의 분산의 85%는 모델에 의해 설명됩니다.
2. [ ] 모델의 예측 정확도는 85%입니다.
3. [ ] 모델의 평균 오차율은 0.85 단위입니다.
4. [ ] 목표 변수의 분산 중 15%는 모델에 의해 설명되지 않습니다.

**Correct Answer:** 1

---

## Question 214

**Category:** Model Evaluation Metrics
**Difficulty:** medium

### English

In a scenario where even small errors can have significant consequences, which metric would you pay more attention to?

1. [✓] MAE
2. [ ] RMSE
3. [ ] R-squared
4. [ ] It depends on the specific context.

### 한국어

2. 아무리 작은 오류라도 중대한 결과를 초래할 수 있는 상황에서 어떤 지표에 더 많은 주의를 기울여야 할까요?

1. [✓] 정확도
2. [ ] RMSE
3. [ ] R제곱
4. [ ] 이는 구체적인 상황에 따라 달라집니다.

**Correct Answer:** 1

---

## Question 215

**Category:** Classification Metrics
**Difficulty:** medium

### English

Which of the following is NOT a metric directly derived from a confusion matrix?

1. [ ] Accuracy
2. [ ] Precision
3. [ ] Recall
4. [✓] Mean Squared Error (MSE)

### 한국어

3. 다음 중 혼동 행렬에서 직접 파생된 지표가 아닌 것은 무엇입니까?

1. [ ] 정확성
2. [ ] 정도
3. [ ] 상기력
4. [✓] 평균 제곱 오차(MSE)

**Correct Answer:** 4

---

## Question 216

**Category:** Classification Metrics
**Difficulty:** medium

### English

In a confusion matrix, what does a high number of False Negatives indicate?

1. [ ] The model is predicting many positive cases incorrectly.
2. [✓] The model is failing to identify many actual positive cases.
3. [ ] The model is performing well in identifying negative cases.
4. [ ] The model has a high accuracy.

### 한국어

4. 혼동 행렬에서 거짓 부정의 수가 많다는 것은 무엇을 의미합니까?

1. [ ] 해당 모델은 많은 양성 사례를 잘못 예측하고 있습니다.
2. [✓] 이 모델은 실제로 양성 환자 사례를 많이 식별하지 못하고 있습니다.
3. [ ] 해당 모델은 부정적인 사례를 식별하는 데 좋은 성과를 보이고 있습니다.
4. [ ] 해당 모델은 정확도가 높습니다.

**Correct Answer:** 2

---

## Question 217

**Category:** Classification Problems
**Difficulty:** medium

### English

Which of the following is an example of a classification problem?

1. [ ] Predicting the price of a house
2. [✓] Identifying whether an email is spam or not
3. [ ] Estimating the number of customers in a store
4. [ ] Predicting the temperature of a city

### 한국어

5. 다음 중 분류 문제의 예는 무엇입니까?

1. [ ] 주택 가격 예측
2. [✓] 이메일이 스팸인지 아닌지 식별하기
3. [ ] 매장의 고객 수 추산
4. [ ] 도시의 온도 예측

**Correct Answer:** 2

---

## Question 218

**Category:** Regression Metrics
**Difficulty:** medium

### English

Which evaluation metric is NOT typically used for regression models?

1. [ ] R-squared (R²)
2. [ ] Mean Absolute Error (MAE)
3. [✓] F1-score
4. [ ] Root Mean Squared Error (RMSE)

### 한국어

6. 어떤 평가 지표가 일반적으로 회귀 모델에 사용되지 않습니까?

1. [ ] R제곱(R²)
2. [ ] 평균 절대 오차(MAE)
3. [✓] F1 점수
4. [ ] 평균 제곱근 오차(RMSE)

**Correct Answer:** 3

---

## Question 219

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following is NOT a typical application of hierarchical clustering?

1. [ ] Image segmentation
2. [ ] Customer segmentation
3. [✓] Linear regression
4. [ ] Anomaly detection

### 한국어

다음 중 계층적 클러스터링의 일반적인 적용 분야가 아닌 것은 무엇입니까?

1. [ ] 이미지 분할
2. [ ] 고객 세분화
3. [✓] 선형 회귀
4. [ ] 이상 감지

**Correct Answer:** 3

---

## Question 220

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following is the first step in the k-means algorithm?

1. [ ] Assignment of data points to the nearest centroids
2. [ ] Recalculation of centroids
3. [✓] Random initialization of centroids
4. [ ] Iteration until convergence

### 한국어

다음 중 k-평균 알고리즘의 첫 번째 단계는 무엇입니까?

1. [ ] 가장 가까운 중심에 데이터 포인트 할당
2. [ ] 중심점 재계산
3. [✓] 중심점의 무작위 초기화
4. [ ] 수렴할 때까지 반복

**Correct Answer:** 3

---

## Question 221

**Category:** Clustering
**Difficulty:** medium

### English

Which of the following methods helps assess how well each data point fits within its assigned cluster in k-means?

1. [ ] Elbow Method
2. [✓] Silhouette Analysis
3. [ ] Domain Knowledge
4. [ ] Grid Search

### 한국어

다음 방법 중 어떤 것이 k-공간에서 각 데이터 포인트가 할당된 클러스터에 얼마나 잘 들어맞는지 평가하는 데 도움이 됩니까?

1. [ ] 관측치 방법
2. [✓] 실루엣 분석
3. [ ] 도메인 지식
4. [ ] 그리드 검색

**Correct Answer:** 2

---

## Question 222

**Category:** Clustering
**Difficulty:** medium

### English

What are we looking for in the plot generated by the Elbow Method?

1. [ ] A sharp peak
2. [ ] A gradual slope
3. [✓] A bend or "elbow" point
4. [ ] A straight line

### 한국어

엘보우방법으로 생성된 플롯에서 우리는 무엇을 찾고 있는가?

1. [ ] 낮아진 분점
2. [ ] 점진적인 감소
3. [✓] 균형 또는 '팔꿈치' 지점
4. [ ] 직선

**Correct Answer:** 3

---

## Question 223

**Category:** Clustering
**Difficulty:** medium

### English

What is the visual representation of the hierarchical clustering process called?

1. [ ] Scatter plot
2. [✓] Dendrogram
3. [ ] Histogram
4. [ ] Box plot

### 한국어

계층적 클러스터링 과정의 시각적 표현은 무엇이라고 하나요?

1. [ ] 산포도
2. [✓] 덴드로그램
3. [ ] 히스토그램
4. [ ] 상자 그림

**Correct Answer:** 2

---

## Question 224

**Category:** Association Rule Mining
**Difficulty:** medium

### English

What are the two key metrics used to evaluate the strength of an association rule?

1. [ ] Accuracy and Precision
2. [✓] Support and Confidence
3. [ ] Recall and F1-score
4. [ ] Mean and Median

### 한국어

연관 규칙의 강도를 평가하는 데 사용되는 두 가지 주요 지표는 무엇입니까?

1. [ ] 정확도와 정밀도
2. [✓] 지연과 신뢰
3. [ ] 리콜 및 F1 점수
4. [ ] 평균과 중앙값

**Correct Answer:** 2

---

## Question 225

**Category:** Association Rule Mining
**Difficulty:** medium

### English

Which metric quantifies the likelihood of item Y being purchased when item X is purchased, relative to the overall likelihood of Y being purchased?

1. [ ] Support
2. [ ] Confidence
3. [✓] Lift
4. [ ] Count

### 한국어

어떤 지표는 품목 X가 구매될 때 품목 Y가 구매될 가능성을 Y가 구매될 전체 가능성에 비해 정량화하는가?

1. [ ] 지지력
2. [ ] 신뢰
3. [✓] 승강기
4. [ ] 세다

**Correct Answer:** 3

---

## Question 226

**Category:** Association Rule Mining
**Difficulty:** medium

### English

Which of the following is NOT a step in the association rule mining process?

1. [ ] Generate Frequent Itemsets
2. [ ] Generate Rules
3. [ ] Evaluate Rules
4. [✓] Cluster Analysis

### 한국어

다음 중 연관 규칙 마이닝 프로세스의 단계가 아닌 것은 무엇입니까?

1. [ ] 빈발한 항목 집합 생성
2. [ ] 규칙 생성
3. [ ] 규칙 평가
4. [✓] 클러스터 분석

**Correct Answer:** 4

---

## Question 227

**Category:** RAPIDS
**Difficulty:** medium

### English

Which of the following is NOT a key feature of RAPIDS?

1. [ ] Open-Source Software Library
2. [ ] GPU Acceleration
3. [ ] Drop-In Replacement for Existing Libraries
4. [✓] Automatic Model Selection

### 한국어

다음 중 RAPIDS의 핵심이 아닌 것은 무엇입니까?

1. [ ] 오픈 소스 소프트웨어 라이브러리
2. [ ] GPU 가속
3. [ ] 기존 도서관에 대한 드롭인 교체
4. [✓] 자동 모델 선택

**Correct Answer:** 4

---

## Question 228

**Category:** Model Architecture
**Difficulty:** medium

### English

Which layer in a DNN is responsible for receiving the raw input data?

1. [✓] Input Layer
2. [ ] Hidden Layer
3. [ ] It determines the accuracy of the model.
4. [ ] It has no significant role in machine learning

### 한국어

DNN의 어느 계층이 원시 입력 데이터를 수신하는 역할을 합니까?

1. [✓] 입력 레이어
2. [ ] 숨겨진 레이어
3. [ ] 이는 정확성 정확도를 결정합니다.
4. [ ] 마지막에서 중요한 역할을 합니다.

**Correct Answer:** 1

---

## Question 229

**Category:** Model Architecture
**Difficulty:** medium

### English

Which type of Deep Neural Network is best suited for processing images and videos?

1. [ ] Multi-Layer Perceptron (MLP)
2. [✓] Convolutional Neural Network (CNN)
3. [ ] Recurrent Neural Network (RNN)
4. [ ] Generative Adversarial Network (GAN)

### 한국어

이런 유형의 딥 신경망이 이미지와 비디오를 처리하는 데 가장 적합합니까?

1. [ ] 다층 퍼셉트론(MLP)
2. [✓] 합성곱 신경망(CNN)
3. [ ] 순환 신경망(RNN)
4. [ ] 생성적 적대 신경망(GAN)

**Correct Answer:** 2

---

## Question 230

**Category:** Model Architecture
**Difficulty:** medium

### English

What role do Weights play in an artificial neuron?

1. [ ] Introduce non-linearity
2. [✓] Determine the importance of each input
3. [ ] Provide a constant offset
4. [ ] Receive the initial data

### 한국어

인공 뉴런에서 가중치는 어떤 역할을 하나요?

1. [ ] 비선형성을 도입합니다
2. [✓] 각 입력의 중요성을 결정하세요
3. [ ] 큰 단일 값으로 계산
4. [ ] 초기 데이터 수신

**Correct Answer:** 2

---

## Question 231

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the first step in the computation process of an artificial neuron?

1. [ ] Apply the activation function
2. [✓] Calculate the weighted sum
3. [ ] Transmit the output signal
4. [ ] Adjust the bias

### 한국어

인공 뉴런의 계층 경계에서 첫 번째 단계는 무엇입니까?

1. [ ] 활성화 함수를 적용합니다
2. [✓] 가중치를 계산합니다
3. [ ] 출력 신호를 전송합니다
4. [ ] 입력을 조정하다

**Correct Answer:** 2

---

## Question 232

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the initial step in the Gradient Descent algorithm?

1. [ ] Calculate the gradient of the loss function
2. [ ] Update the model parameters
3. [✓] Initialize the model parameters with random values
4. [ ] Repeat steps until convergence

### 한국어

경사 하강 알고리즘의 초기 단계는 무엇입니까?

1. [ ] 손실 함수의 기울기를 계산합니다
2. [ ] 모델 입력처리를 만듭니다
3. [✓] 알맞은 모듈로 모델 매개변수를 초기화합니다
4. [ ] 추출된 매개변수를 변형합니다

**Correct Answer:** 3

---

## Question 233

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the mathematical formula for the ReLU activation function?

1. [✓] f(x) = max(0, x)
2. [ ] f(x) = 1 / (1 + e^-x)
3. [ ] f(x) = tanh(x)
4. [ ] f(x) = x

### 한국어

ReLU 활성화 함수의 수학 공식은 무엇인가요?

1. [✓] f(x) = max(0, x)
2. [ ] f(x) = 1 / (1 + e^-x)
3. [ ] f(x) = tanh(x)
4. [ ] f(x) = x

**Correct Answer:** 1

---

## Question 234

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the purpose of applying an activation function in a neuron?

1. [ ] To normalize the input values
2. [✓] To introduce non-linearity into the model
3. [ ] To calculate the weighted sum of inputs
4. [ ] To produce the final prediction

### 한국어

뚜렷이 활성화 함수를 적용하는 목적은 무엇인가요?

1. [ ] 입력값을 규정화하기 위해
2. [✓] 모델의 비선형성을 도입하려면
3. [ ] 입력의 가중평균을 계산하려면
4. [ ] 새로운 예측을 생성하려면

**Correct Answer:** 2

---

## Question 235

**Category:** Model Architecture
**Difficulty:** medium

### English

In the equation Z = W * X + b, what does Z represent?

1. [ ] The weight matrix
2. [ ] The input matrix
3. [ ] The bias vector
4. [✓] The matrix of weighted sums for all neurons in a layer

### 한국어

Z = W * x + b 방정식에서 Z는 무엇을 나타내나요?

1. [ ] 가중치 행렬
2. [ ] 편향 행렬
3. [ ] 하이퍼볼릭 탄젠트
4. [✓] 계층의 모든 뉴런에 대한 가중 합의 행렬

**Correct Answer:** 4

---

## Question 236

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the primary goal of backpropagation in neural networks?

1. [ ] To initialize the model's parameters
2. [ ] To make predictions on new data
3. [✓] To minimize the overall error and improve model accuracy
4. [ ] To introduce non-linearity into the model

### 한국어

신경망에서 역전파 알고리즘의 주요 목적은 무엇인가요?

1. [ ] 모델의 파라미터를 초기화하려면
2. [ ] 새로운 데이터에 대한 예측을 하려면
3. [✓] 성능을 최적화하고 모델의 정확도를 향상시키려면
4. [ ] 모델의 비선형성을 도입하려면

**Correct Answer:** 3

---

## Question 237

**Category:** Training Techniques
**Difficulty:** medium

### English

Which step involves feeding the input data through the network to generate a prediction?

1. [✓] Forward Pass
2. [ ] Loss Calculation
3. [ ] Backward Pass
4. [ ] Weight Initialization

### 한국어

예측을 생성하기 위해 딥러닝 네트워크에 공급하는 단계는 무엇인가?

1. [✓] 프로토콜 분석
2. [ ] 손실 계산
3. [ ] 역전파
4. [ ] 가중치 초기화

**Correct Answer:** 1

---

## Question 238

**Category:** Data Preprocessing
**Difficulty:** medium

### English

Given a categorical feature with values ['red', 'green', 'blue'], what would be the one-hot encoded representation of 'green'?

1. [ ] [1, 0, 0]
2. [✓] [0, 1, 0]
3. [ ] [0, 0, 1]
4. [ ] [1, 1, 0]

### 한국어

'red', 'green', 'blue' ]라는 범주의 특성이 주어졌을 때, 'green'의 원핫 인코딩 표현은 무엇인가요?

1. [ ] [0, 1, 0]
2. [✓] [1, 0, 0]
3. [ ] [0, 0, 1]
4. [ ] [1, 1, 0]

**Correct Answer:** 2

---

## Question 239

**Category:** Model Architecture
**Difficulty:** medium

### English

What type of data are Convolutional Neural Networks (CNNs) primarily designed to process?

1. [ ] Sequential data, such as text or time series
2. [ ] Tabular data with structured features
3. [✓] Grid-like data, such as images and video
4. [ ] Audio data

### 한국어

합성곱 신경망(CNN)은 주로 어떤 유형의 데이터를 처리하도록 설계되었습니까?

1. [ ] 텍스트나 시계열과 같은 순차적 데이터
2. [ ] 구조화된 값이 있는 표 형식 데이터
3. [✓] 이미지, 비디오 등 2 그리드 형탤 데이터
4. [ ] 오디오 데이터

**Correct Answer:** 3

---

## Question 240

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of Pooling Layers in a CNN?

1. [ ] To increase the spatial dimensions of the data
2. [ ] To introduce non-linearity into the model
3. [✓] To reduce the spatial dimensions of the data by downsampling
4. [ ] To generate the final output predictions

### 한국어

CNN에서 풀링 레이어의 주요 목적은 무엇입니까?

1. [ ] 데이터의 공간적 차원을 늘리려면
2. [ ] 모델의 반상성능을 도울하려면
3. [✓] 다운샘플링을 통해 데이터의 공간적 차원을 줄이려면
4. [ ] 최종 출력 예측을 생성하려면

**Correct Answer:** 3

---

## Question 241

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the core concept behind transfer learning?

1. [ ] Training a model from scratch on a small dataset.
2. [✓] Leveraging knowledge from a pre-trained model on a new but related task.
3. [ ] Creating a completely new neural network architecture for every task.
4. [ ] Only using labeled data for training.

### 한국어

전이 학습의 핵심 개념은 무엇입니까?

1. [ ] 작은 데이터세트를 이용해 처음부터 모델을 학습합니다.
2. [✓] 사전 훈련된 모델의 지식을 새롭지만 관련된 작업에 활용합니다.
3. [ ] 모든 작업에 대해 완전히 새로운 신경망 아키텍처를 만듭니다.
4. [ ] 레이블이 지정된 데이터만 사용하여 학습합니다.

**Correct Answer:** 2

---

## Question 242

**Category:** Training Techniques
**Difficulty:** medium

### English

In which scenario is transfer learning most likely to be beneficial?

1. [ ] You have abundant labeled data for your specific task.
2. [ ] The pre-trained model was trained on a task completely unrelated to your target task.
3. [ ] You have ample computational resources and a large dataset for your new task.
4. [✓] You have a small dataset for your specific task and limited computational resources.

### 한국어

어떤 시나리오에서 전이 학습이 가장 유익할 가능성이 높습니까?

1. [ ] 다량의 특정 환경에 적합한 레이블이 지정된 데이터가 풍부합니다.
2. [ ] 사전 학습된 모델은 대상 작업과 전혀 관련이 없는 작업에 대해 학습되었습니다.
3. [ ] 새로운 작업을 수행하기에 충분한 컴퓨팅 리소스와 대규모 데이터 세트를 찾고 있습니다.
4. [✓] 다량의 특정 환경에 필요한 데이터 세트는 작고 컴퓨팅 리소스도 제한적입니다.

**Correct Answer:** 4

---

## Question 243

**Category:** Model Architecture
**Difficulty:** medium

### English

When loading the VGG16 model, what does setting include_top=False signify?

1. [✓] It excludes the final fully connected classification layers of the model
2. [ ] It excludes the convolutional base of the model
3. [ ] It loads the model without pre-trained weights
4. [ ] It disables transfer learning

### 한국어

VGG16 모델을 로드할 때 include_top=False로 설정하는 것은 무엇을 의미합니까?

1. [✓] 모델의 최상 층에 있는 Dense 계층을 제외합니다.
2. [ ] 모델의 학습량 기반을 제외합니다.
3. [ ] 사전 훈련된 가중치 없이 모델을 로드합니다.
4. [ ] 같이 학습을 비활성화합니다.

**Correct Answer:** 1

---

## Question 244

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the purpose of freezing layers in the VGG16 model during transfer learning?

1. [✓] To prevent the pre-trained weights from being updated during training
2. [ ] To slightly speed up the training process
3. [ ] To ensure the model learns only from the new data
4. [ ] To reduce the model’s complexity

### 한국어

같이 학습 없이 VGG16 모델에서 레이어를 동결하는 '활용'은 무엇입니까?

1. [✓] 사전 훈련된 가중치가 없는 모델에서는 정확성을 저하
2. [ ] 훈련 과정 맨 마지막부터 접근하려면
3. [ ] 모델에 새로운 데이터셋만 학습하도록 하려면
4. [ ] 모델의 복잡성을 줄이려면

**Correct Answer:** 1

---

## Question 245

**Category:** Deep Learning
**Difficulty:** medium

### English

Which activation function maps the input to a range between 0 and 1 and is historically popular but suffers from vanishing gradients?

1. [✓] Sigmoid
2. [ ] Hyperbolic Tangent (tanh)
3. [ ] Rectified Linear Unit (ReLU)
4. [ ] Linear

### 한국어

어떤 활성 함수가 입력을 0~1 사이의 범위에 매핑하며, 역사적으로 입력 값 자체가 기울기가 사라지는 문제가 있는가?

1. [✓] 시그모이드
2. [ ] 쌍곡탄젠트(tanh)
3. [ ] 정류 선형 유닛(ReLU)
4. [ ] 선형

**Correct Answer:** 1

---

## Question 246

**Category:** Deep Learning
**Difficulty:** medium

### English

Which activation function is similar to sigmoid but maps the input to a range between -1 and 1?

1. [ ] Sigmoid
2. [✓] Hyperbolic Tangent (tanh)
3. [ ] Rectified Linear Unit (ReLU)
4. [ ] Linear

### 한국어

시그모이드와 유사하지만 입력을 -1과 1 사이의 범위로 매핑하는 활성화 함수는 무엇인가?

1. [ ] 시그모이드
2. [✓] 쌍곡탄젠트(tanh)
3. [ ] 정류 선형 유닛(ReLU)
4. [ ] 선형

**Correct Answer:** 2

---

## Question 247

**Category:** Transfer Learning
**Difficulty:** medium

### English

Which of the following is a common approach in transfer learning?

1. [ ] Training a model from scratch with random weights
2. [ ] Completely discarding pre-trained models in every training iteration
3. [ ] Avoiding the use of neural networks
4. [✓] Using a pre-trained model as a feature extractor and fine-tuning only specific layers

### 한국어

다음 중 같이 학습에서 일반적인 접근 방식은 무엇인가?

1. [ ] 무작위 가중치를 사용하여 처음부터 모델 학습
2. [ ] 모든 훈련 반복에서 사전 훈련 모델을 무시합니다.
3. [ ] 신경망 사전 훈련
4. [✓] 가중치 변환에 생성적 기능 출력을 사용하는 특성 데이터에 페널티 적용

**Correct Answer:** 4

---

## Question 248

**Category:** NLP
**Difficulty:** medium

### English

What is the primary challenge that Natural Language Processing (NLP) aims to address?

1. [✓] The complexity and ambiguity of human language.
2. [ ] The speed at which humans can process information.
3. [ ] The vast amount of data generated by machines.
4. [ ] The difficulty of programming computers in binary code.

### 한국어

자연어 처리(NLP)가 해결하고자 하는 주요 과제는 무엇입니까?

1. [✓] 인간 언어의 복잡성과 모호성.
2. [ ] 인간이 정보를 처리할 수 있는 속도.
3. [ ] 기계가 생성하는 양질의 데이터.
4. [ ] 이진 코드를 컴퓨터를 프로그래밍하는 것은 어렵다.

**Correct Answer:** 1

---

## Question 249

**Category:** NLP
**Difficulty:** medium

### English

Which NLP preprocessing technique involves breaking down a text into smaller units like words or subwords?

1. [✓] Tokenization
2. [ ] Stopword Removal
3. [ ] Stemming
4. [ ] Lemmatization

### 한국어

어떤 NLP 전처리 기법이 텍스트를 단어나 하위 단어와 같은 더 작은 단위로 분해하는 것을 포함합니까?

1. [✓] 토큰화
2. [ ] 불용어 제거
3. [ ] 어간 분석
4. [ ] 레마티제이션

**Correct Answer:** 1

---

## Question 250

**Category:** NLP
**Difficulty:** medium

### English

Which text normalization technique aims to reduce words to their base or root form, often by removing suffixes?

1. [✓] Stemming
2. [ ] Lemmatization
3. [ ] Expanding contractions
4. [ ] Tokenization

### 한국어

어떤 텍스트 정규화 기술이 접미사를 제거하여 단어를 기본 형태나 어근 형태로 줄이는 것을 목표로 합니까?

1. [✓] 어간 분석
2. [ ] 레마티제이션
3. [ ] 추상 추출
4. [ ] 토큰화

**Correct Answer:** 1

---

## Question 251

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

When selecting a machine learning model, what is a common trade-off that practitioners need to consider?

1. [ ] Accuracy vs. Speed
2. [✓] Complexity vs. Interpretability
3. [ ] Data Size vs. Model Size
4. [ ] Supervised vs. Unsupervised Learning

### 한국어

머신 러닝 모델을 선택할 때 실무자가 고려해야 할 일반적인 균형점은 무엇인가요?

1. [ ] 정확도 대 속도
2. [✓] 복잡성 대 해석 가능성
3. [ ] C-데이터 필요량 대 모델 크기
4. [ ] 지도 학습 vs. 비지도 학습

**Correct Answer:** 2

---

## Question 252

**Category:** NLP
**Difficulty:** medium

### English

When building an NLP pipeline, how should you choose the specific components to include?

1. [ ] Randomly select components.
2. [ ] Always use the same components for every task
3. [✓] Base the selection on the specific NLP task you are trying to solve
4. [ ] Only use pre-built pipelines, never customize

### 한국어

NLP 파이프라인을 구축할 때 포함할 특정 구성 요소를 어떻게 선택해야 합니까?

1. [ ] 무작위로 구성요소를 선택합니다.
2. [ ] 모든 작업이 항상 동일한 구성 요소를 사용하십시오.
3. [✓] 해결하려는 특정 NLP 작업에 따라 선택을 기반으로 하세요.
4. [ ] 미리 구축된 파이프라인만 사용하고 사용자 정의하지 마십시오.

**Correct Answer:** 3

---

## Question 253

**Category:** NLP
**Difficulty:** medium

### English

Which of the following is NOT a typical type of named entity recognized in NLP tasks?

1. [ ] Person
2. [ ] Organization
3. [ ] Location
4. [✓] Adjective

### 한국어

다음 중 NLP 작업에서 인식되는 일반적인 명명된 엔티티 유형이 아닌 것은 무엇입니까?

1. [ ] 사람
2. [ ] 조직
3. [ ] 위치
4. [✓] 형용사

**Correct Answer:** 4

---

## Question 254

**Category:** NLP
**Difficulty:** medium

### English

What is the primary goal of Named Entity Recognition (NER)?

1. [✓] To identify and classify named entities in text, such as names of people, organizations, locations, etc.
2. [ ] To translate text from one language to another
3. [ ] To generate human-like text
4. [ ] To summarize large documents

### 한국어

명명된 개체 인식(NER)의 주요 목표는 무엇인가요?

1. [✓] 사람, 조직, 위치 등의 이름 등 텍스트에서 명명된 엔티티를 식별하고 분류합니다.
2. [ ] 한 언어에서 다른 언어로 텍스트를 번역하려면
3. [ ] 인간과 유사한 텍스트를 생성하려면
4. [ ] 대용량 문서를 요약하려면

**Correct Answer:** 1

---

## Question 255

**Category:** Word Embeddings
**Difficulty:** medium

### English

What are word embeddings?

1. [ ] Sparse matrices representing the frequency of words in a document.
2. [✓] Dense vector representations of words in a continuous vector space.
3. [ ] One-hot encoded representations of words.
4. [ ] Syntactic trees capturing the grammatical structure of sentences.

### 한국어

워드 임베딩이란 무엇인가요?

1. [ ] 문서에서 단어의 빈도를 나타내는 희소 행렬입니다.
2. [✓] 연속적인 벡터 공간에서 단어에 밀집 벡터 표현입니다.
3. [ ] 단어의 원작 인코딩 표현.
4. [ ] 문장의 문법적 구조를 포함하는 구문 트리.

**Correct Answer:** 2

---

## Question 256

**Category:** Word Embeddings
**Difficulty:** medium

### English

How are pre-trained word embeddings typically used in NLP models?

1. [ ] They are directly fed into the final output layer of the model.
2. [✓] They are used as input features to the model.
3. [ ] They replace the need for any other feature engineering.
4. [ ] They are only used for language generation tasks.

### 한국어

사전 훈련된 단어 임베딩은 일반적으로 NLP 모델에서 어떻게 사용됩니까?

1. [ ] 이는 모델의 최종 출력 계층에 직접 입력됩니다.
2. [✓] 이는 모델의 입력 기능으로 사용됩니다.
3. [ ] 이는 다른 기능 엔지니어링 필요성을 대체합니다.
4. [ ] 이는 언어 생성 작업에만 사용됩니다.

**Correct Answer:** 2

---

## Question 257

**Category:** Word Embeddings
**Difficulty:** medium

### English

Which of the following are the two main architectures used in Word2Vec?

1. [✓] Continuous Bag-of-Words (CBOW) and Skip-gram
2. [ ] Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)
3. [ ] Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRUs)
4. [ ] Transformer and BERT

### 한국어

다음 중 Word2Vec에 사용되는 두 가지 주요 아키텍처는 무엇입니까?

1. [✓] 연속 백 오브 워드(CBOW) 및 스킵그램
2. [ ] 합성곱 신경망(CNN)과 순환 신경망(RNN)
3. [ ] 장단기 기억(LSTM) 및 게이트형 순환 단위(GRU)
4. [ ] 트랜스포머와 BERT

**Correct Answer:** 1

---

## Question 258

**Category:** Word Embeddings
**Difficulty:** medium

### English

In the Continuous Bag-of-Words (CBOW) architecture of Word2Vec, what is the model trying to predict?

1. [ ] The next word in a sentence.
2. [✓] The missing word in a sentence given its surrounding context.
3. [ ] The surrounding context words given a target word
4. [ ] The sentiment of a sentence

### 한국어

Word2Vec의 CBOW(Continuous Bag-of-Words) 아키텍처에서 모델은 무엇을 예측하려고 합니까?

1. [ ] 문장의 다음 단어.
2. [✓] 주변 맥락을 고려했을 때 문장에서 빠진 단어.
3. [ ] 입력 단어가 주어졌을 때 주변 맥락 단어
4. [ ] 문장의 감정

**Correct Answer:** 2

---

## Question 259

**Category:** NLP
**Difficulty:** medium

### English

Which of the following best describes the nature of text data?

1. [ ] Highly structured and uniform
2. [✓] Unstructured and diverse
3. [ ] Primarily numerical
4. [ ] Limited to short sentences

### 한국어

다음 중 텍스트 데이터의 특성을 가장 잘 설명하는 것은 무엇입니까?

1. [ ] 고도로 구조화되고 규일함
2. [✓] 비구조적이고 다양함
3. [ ] 주로 숫자
4. [ ] 짧은 문장으로 제한됨

**Correct Answer:** 2

---

## Question 260

**Category:** NLP
**Difficulty:** medium

### English

Which key feature of sequence models enables them to excel at natural language processing tasks like machine translation, where understanding the context of words in a sentence is crucial?

1. [✓] Capture Dependencies
2. [ ] Handle Variable Length
3. [ ] Predict Future Values
4. [ ] Generate New Sequences

### 한국어

시퀀스 모델의 어떤 주요 특징이 기계 번역과 같은 자연어 처리 작업에서 탁월한 성과를 낼 수 있게 해주는가? 이 작업에서 문장 속 단어의 맥락을 이해하는 것이 중요하다.

1. [✓] 중축성 편차
2. [ ] 가변 길이 처리
3. [ ] 미래 가치 예측
4. [ ] 새로운 시퀀스 생성

**Correct Answer:** 1

---

## Question 261

**Category:** RNNs
**Difficulty:** medium

### English

In an RNN, how is the input at each time step processed?

1. [ ] It is directly fed into the output layer.
2. [✓] It is combined with the previous hidden state.
3. [ ] It is processed independently of the previous hidden state.
4. [ ] It is first passed through a convolutional layer.

### 한국어

RNN에서 각 시간 단계의 입력은 어떻게 처리되나요?

1. [ ] 이는 출력 계층에 직접 공급됩니다.
2. [✓] 이는 이전의 숨겨진 상태와 결합됩니다.
3. [ ] 이는 이전의 숨겨진 상태와 독립적으로 처리됩니다.
4. [ ] 먼저 함성곱 계층을 통과합니다.

**Correct Answer:** 2

---

## Question 262

**Category:** RNNs
**Difficulty:** medium

### English

Which of the following is NOT an application of RNNs in Natural Language Processing (NLP)?

1. [ ] Machine translation
2. [ ] Sentiment analysis
3. [✓] Image recognition
4. [ ] Text generation

### 한국어

다음 중 자연어 처리(NLP)에 RNN을 적용한 것이 아닌 것은 무엇입니까?

1. [ ] 기계 번역
2. [ ] 감정 분석
3. [✓] 이미지 인식
4. [ ] 텍스트 생성

**Correct Answer:** 3

---

## Question 263

**Category:** Deep Learning
**Difficulty:** medium

### English

Which of the following architectures are designed to mitigate the vanishing gradient problem? (Choose 2 Correct Answers)

1. [ ] Convolutional Neural Networks (CNNs)
2. [✓] Long Short-Term Memory (LSTM) networks
3. [ ] Gated Recurrent Units (GRUs)
4. [ ] Generative Adversarial Networks (GANs)
5. [ ] Multilayer Perceptrons (MLPs)

### 한국어

다음 아키텍처 중 어느 것이 그래디언트 소실 문제를 완화하도록 설계되었습니까? (정답 2개 선택)

1. [ ] 합성곱 신경망(CNN)
2. [✓] 장단기 메모리(LSTM) 네트워크
3. [ ] 게이트형 순환 회로(GRU)
4. [ ] 생성적 적대 신경망(GAN)
5. [ ] 다층 퍼셉트론(MLP)

**Correct Answer:** 2

---

## Question 264

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the core issue in the vanishing gradient problem?

1. [ ] Gradients become exponentially larger as they propagate backward through layers.
2. [✓] Gradients become exponentially smaller as they propagate backward through layers.
3. [ ] Gradients remain constant as they propagate backward through layers.
4. [ ] Gradients fluctuate randomly as they propagate backward through layers.

### 한국어

사라지는 기울기 문제의 핵심 문제는 무엇입니까?

1. [ ] 기울기는 레이어에 따라 뒤로 전달될수록 기하급수적으로 커집니다.
2. [✓] 기울기는 계층을 따라 뒤로 전달될수록 기하급수적으로 작아집니다.
3. [ ] 기울기는 레이어를 따라 뒤로 전달되면서도 일정하게 유지됩니다.
4. [ ] 기울기는 층을 따라 뒤로 전달되면서 무작위로 변동합니다.

**Correct Answer:** 2

---

## Question 265

**Category:** Transformers
**Difficulty:** medium

### English

What is the key innovation introduced by the Transformer architecture?

1. [ ] Convolutional layers
2. [ ] Recurrent neural networks
3. [✓] Self-attention mechanisms
4. [ ] Long short-term memory cells

### 한국어

Transformer 아키텍처가 도입한 주요 혁신은 무엇입니까?

1. [ ] 합성곱 레이어
2. [ ] 순환 신경망
3. [✓] 자기 주의 메커니즘
4. [ ] 장기 단기 기억 셀

**Correct Answer:** 3

---

## Question 266

**Category:** Transformers
**Difficulty:** medium

### English

What is the purpose of having multiple attention heads in Transformers?

1. [ ] To increase the model's computational complexity
2. [✓] To allow the model to focus on different aspects of the input simultaneously
3. [ ] To reduce the number of parameters in the model
4. [ ] To enable the model to process images and text data together

### 한국어

트랜스포머에 여러 개의 어텐션 헤더가 있는 목적은 무엇입니까?

1. [ ] 모델의 계산 복잡성을 높이려면
2. [✓] 모델이 입력의 다양한 부분에 동시에 집중할 수 있도록 하려면
3. [ ] 모델의 매개변수 수를 줄이려면
4. [ ] 모델이 이미지와 텍스트 데이터를 함께 처리할 수 있도록 하려면

**Correct Answer:** 2

---

## Question 267

**Category:** Transformers
**Difficulty:** medium

### English

What is the primary role of positional encoding in Transformers?

1. [✓] To provide information about the absolute position of each word in the sequence.
2. [ ] To enable the model to distinguish between different words in the vocabulary.
3. [ ] To reduce the number of parameters in the model.
4. [ ] To improve the model's ability to handle image data.

### 한국어

트랜스포머에서 위치 인코딩의 주요 역할은 무엇입니까?

1. [✓] 시퀀스에서 각 단어의 절대 위치에 대한 정보를 제공합니다.
2. [ ] 모델이 입력의 순익 다양한 단어를 구별할 수 있도록 합니다.
3. [ ] 모델의 매개변수 수를 줄이려면.
4. [ ] 모델의 이미지 데이터 처리 능력을 향상시킵니다.

**Correct Answer:** 1

---

## Question 268

**Category:** Transformers
**Difficulty:** medium

### English

How is positional encoding typically incorporated into the model's input?

1. [ ] It is used to replace the word embeddings entirely.
2. [ ] It is fed into a separate network that generates attention masks.
3. [✓] It is concatenated with the word embeddings.
4. [ ] It is used to initialize the model's weights.

### 한국어

위치 인코딩은 일반적으로 어떻게 모델의 입력에 통합됩니까?

1. [ ] 이는 단어 임베딩을 완전히 대체하는 데 사용됩니다.
2. [ ] 이는 주의 마스크를 생성하는 별도의 네트워크에 입력됩니다.
3. [✓] 이는 단어 임베딩과 연결됩니다.
4. [ ] 모델의 가중치를 초기화하는 데 사용됩니다.

**Correct Answer:** 3

---

## Question 269

**Category:** Transformers
**Difficulty:** medium

### English

What is the primary challenge posed by the permutation-invariant nature of self-attention in Transformers when dealing with natural language?

1. [ ] It makes it difficult to capture long-range dependencies in a sentence.
2. [ ] It prevents the model from distinguishing between synonyms.
3. [✓] It makes it difficult to understand the relationships between words in a sentence.
4. [ ] It leads to the model generating grammatically incorrect sentences.

### 한국어

자연어를 다룰 때 트랜스포머에서 자기 주의의 순열 불변적 특성으로 인해 발생하는 주요 과제는 무엇입니까?

1. [ ] 문맥이 장거리 종속성을 포함하기 어렵게 만듭니다.
2. [ ] 이로 인해 모델이 동일한 단어를 구별하지 못합니다.
3. [✓] 문장 속 단어 사이의 관계를 이해하는 것이 어렵습니다.
4. [ ] 이로 인해 모델이 문법적으로 잘못된 문장을 생성하게 됩니다.

**Correct Answer:** 3

---

## Question 270

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the primary purpose of memory cells in LSTMs?

1. [ ] To process input sequences in parallel.
2. [ ] To introduce non-linearity into the network.
3. [✓] To maintain long-term information across time steps.
4. [ ] To regulate the learning rate during training.

### 한국어

LSTM에서 메모리 셀의 주요 목적은 무엇입니까?

1. [ ] 입력 시퀀스를 병렬로 처리합니다.
2. [ ] 네트워크의 비선형성을 도입합니다.
3. [✓] 시간 단위에 걸쳐 장기 정보를 유지합니다.
4. [ ] 훈련 중 학습률을 조절합니다.

**Correct Answer:** 3

---

## Question 271

**Category:** LLMs
**Difficulty:** medium

### English

What is the purpose of pre-training in LLM development?

1. [ ] To specialize the model for a specific task
2. [✓] To teach the model general language patterns from diverse text sources
3. [ ] To reduce the model's size
4. [ ] To improve the model's inference speed

### 한국어

LLM 개발에서 사전 교육의 목적은 무엇입니까?

1. [ ] 특정 작업에 맞게 모델을 전문화하려면
2. [✓] 다양한 텍스트 소스에서 모델 일반 언어 패턴을 가르치려면
3. [ ] 모델의 크기를 줄이려면
4. [ ] 모델의 추론 속도를 개선하려면

**Correct Answer:** 2

---

## Question 272

**Category:** Transformers
**Difficulty:** medium

### English

What is the main purpose of a Transformer pipeline in Hugging Face's Transformers library?

1. [ ] To train a Transformer model from scratch.
2. [ ] To fine-tune a pre-trained Transformer model on a specific task
3. [✓] To simplify the process of applying pre-trained Transformer models to various NLP tasks
4. [ ] To visualize the internal workings of a Transformer model

### 한국어

Hugging Face의 Transformers 라이브러리에서 Transformer 파이프라인의 주요 목적은 무엇입니까?

1. [ ] Transformer 모델을 처음부터 학습합니다.
2. [ ] 특정 작업에 대해서 사전 훈련된 Transformer 모델을 미세 조정하려면
3. [✓] 다양한 NLP 작업에 사전 훈련된 Transformer 모델을 적용하는 프로세스를 단순화하려면
4. [ ] Transformer 모델의 내부 작동을 시각화하려면

**Correct Answer:** 3

---

## Question 273

**Category:** NLP
**Difficulty:** medium

### English

When using a Hugging Face pipeline for text classification, what is the typical input?

1. [ ] A pre-trained LLM
2. [✓] A list of text samples to be classified
3. [ ] The desired output labels
4. [ ] The path to a dataset

### 한국어

텍스트 분류에 Hugging Face 파이프라인을 사용할 때 일반적인 입력은 무엇입니까?

1. [ ] 사전 훈련된 LLM
2. [✓] 분류할 텍스트 샘플 목록
3. [ ] 원하는 출력 레이블
4. [ ] 데이터 세트 경로

**Correct Answer:** 2

---

## Question 274

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is a primary expectation from learning the fundamentals of machine learning?

1. [✓] Understanding different machine learning algorithms and their applications
2. [ ] Writing low-level assembly code for GPUs
3. [ ] Developing new operating systems for AI workloads
4. [ ] Designing hardware components for deep learning models

### 한국어




**Correct Answer:** 1

---

## Question 275

**Category:** Model Architecture
**Difficulty:** medium

### English

What is the core principle behind Generative Adversarial Networks (GANs)?

1. [ ] Two neural networks collaborate to create realistic content.
2. [ ] One neural network learns to compress data, while another decompresses it.
3. [✓] Two neural networks compete against each other, one generating content and the other evaluating its realism.
4. [ ] A single neural network learns to predict the next word in a sequence.

### 한국어

생성적 적대 신경망(GAN)의 핵심 원리는 무엇입니까?

1. [ ] 두 개의 신경망이 협력하여 사실적인 콘텐츠를 만듭니다.
2. [ ] 한 신경망은 데이터를 압축하는 법을 배우고, 다른 신경망은 압축을 해제합니다.
3. [✓] 두 개의 신경망이 서로 경쟁하는데, 하나는 콘텐츠를 생성하고 다른 하나는 콘텐츠의 현실성을 평가합니다.
4. [ ] 단일 신경망은 시퀀스의 다음 단계를 예측하는 법을 학습합니다.

**Correct Answer:** 3

---

## Question 276

**Category:** Training Techniques
**Difficulty:** medium

### English

Why is diversity crucial in the data used to train generative AI models?

1. [ ] It helps the model avoid overfitting to specific patterns
2. [✓] It makes the model more versatile and capable of generating a wider range of content
3. [ ] It reduces the computational resources required for training
4. [ ] It ensures the model's output is always factually accurate

### 한국어

생성 시 모델을 훈련하는 데 사용되는 데이터에서 다양성이 왜 중요한가요?

1. [ ] 이는 모델이 특정 패턴에 과도하게 맞춰지는 것을 방지하는 데 도움이 됩니다.
2. [✓] 이는 모델을 더욱 다재다능하게 만들고 더 광범위한 콘텐츠를 생성할 수 있게 해줍니다.
3. [ ] 훈련에 필요한 계산 리소스를 줄여줍니다.
4. [ ] 이는 모델의 출력이 항상 사실적으로 정확함을 보장합니다.

**Correct Answer:** 2

---

## Question 277

**Category:** LLMs
**Difficulty:** medium

### English

What is the advantage of incorporating texts from specific fields like medicine, law, or finance into LLM training data?

1. [✓] It allows the model to develop specialized knowledge in those domains
2. [ ] It improves the model's overall language understanding
3. [ ] It speeds up the training process
4. [ ] It enhances the model's ability to generate poetry

### 한국어

의학, 법률, 금융 등 특정 분야의 텍스트를 LLM 교육 데이터에 통합하는 이점은 무엇입니까?

1. [✓] 이를 통해 모델은 해당 도메인에 대한 전문 지식을 개발할 수 있습니다.
2. [ ] 모델의 전반적인 언어 이해도가 향상됩니다.
3. [ ] 훈련 과정을 가속화합니다.
4. [ ] 이는 모델의 생성 능력을 향상시킵니다.

**Correct Answer:** 1

---

## Question 278

**Category:** Training Techniques
**Difficulty:** medium

### English

What is a direct consequence of training Large Language Models (LLMs) on poor-quality data?

1. [ ] Improved accuracy and reliability.
2. [ ] Increased generalization to new information.
3. [✓] Inaccurate outputs and biased responses.
4. [ ] Faster training times and reduced computational costs.

### 한국어

품질이 낮은 데이터로 대규모 언어 모델(LLM)을 훈련하면 직접적인 결과는 무엇입니까?

1. [ ] 정확도와 신뢰성이 향상되었습니다.
2. [ ] 새로운 정보에 대한 일반화가 강해졌습니다.
3. [✓] 부정확한 출력과 편향된 응답.
4. [ ] 훈련 시간과 단축되고 계산 비용이 절감됩니다.

**Correct Answer:** 3

---

## Question 279

**Category:** AI Infrastructure
**Difficulty:** medium

### English

How does NVIDIA contribute to the data pipeline for AI tasks?

1. [ ] By manually curating training datasets for AI models
2. [✓] By enabling GPU acceleration and distributed computing for data processing
3. [ ] By replacing the need for diverse training data through AI simulations
4. [ ] By focusing only on hardware and not on AI data pipelines

### 한국어

NVIDIA 사 작업을 위한 데이터 파이프라인이 어떻게 기여합니까?

1. [ ] AI 모델 훈련을 위한 데이터 세트를 수동으로 큐레이팅하여
2. [✓] 데이터 처리를 위한 GPU 가속 및 분산 컴퓨팅을 활성화함으로써
3. [ ] AI 시뮬레이션을 통해 다양한 효과의 데이터의 필요성을 대체함으로써
4. [ ] AI 데이터 파이프라인이 아닌 하드웨어에만 집중함으로써

**Correct Answer:** 2

---

## Question 280

**Category:** Training Techniques
**Difficulty:** medium

### English

What are the key challenges of feeding poor-quality data to large language models (LLMs)?

1. [ ] It improves the model’s ability to generalize new information.
2. [✓] It results in inaccurate outputs, biased responses, and unreliable predictions.
3. [ ] It has no impact on the performance of LLMs.
4. [ ] It speeds up the training process of LLMs.

### 한국어

품질이 낮은 데이터를 대규모 언어 모델(LLM)에 공급하는 데 있어 주요 과제는 무엇입니까?

1. [ ] 이는 새로운 정보에 대한 모델의 능력을 향상시킵니다.
2. [✓] 그 결과 편향된 출력, 편향된 응답, 신뢰할 수 없는 예측이 발생합니다.
3. [ ] 이는 LLM의 성능에 영향을 미치지 않습니다.
4. [ ] LLM의 교육 과정이 빨라집니다.

**Correct Answer:** 2

---

## Question 281

**Category:** LLMs
**Difficulty:** medium

### English

What does "zero-shot learning" refer to in the context of LLMs?

1. [✓] The model's ability to learn new tasks without any prior examples or training.
2. [ ] The model's ability to perform tasks with zero errors.
3. [ ] The initial stage of training where the model has no knowledge.
4. [ ] The process of fine-tuning the model on a specific task.

### 한국어

1. LLM에서 '제로샷 러닝'이란 무엇을 의미합니까?

1. [✓] ① 모델은 사전 지식나 훈련 없이도 새로운 작업을 학습할 수 있는 능력을 갖추고 있습니다.
2. [ ] ② 모델이 오류 없이 작업을 수행할 수 있는 능력입니다.
3. [ ] ③ 모델이 아무런 지식도 가지고 있지 않은 환경의 초기 단계입니다.
4. [ ] ④ 특정 작업에 맞게 모델을 미세 조정하는 과정입니다.

**Correct Answer:** 1

---

## Question 282

**Category:** LLMs
**Difficulty:** medium

### English

What is the core principle behind few-shot learning in Large Language Models (LLMs)?

1. [ ] LLMs require massive amounts of labeled data to learn any task.
2. [✓] LLMs can learn to perform tasks by observing only a few examples or demonstrations.
3. [ ] LLMs can only generate text, not understand or classify it.
4. [ ] LLMs are incapable of adapting to new tasks without extensive retraining.

### 한국어

2. 대규모 언어 모델(LLM)에서 퓨샷 학습의 핵심 원리는 무엇입니까?

1. [ ] ① LLM은 어떤 작업을 학습하기 위해 엄청난 양의 레이블이 지정된 데이터가 필요합니다.
2. [✓] ② LLM은 몇 가지 예시만 관찰해도 작업을 수행하는 방법을 배울 수 있습니다.
3. [ ] ③ LLM은 텍스트를 생성할 수만 있고 이해하거나 분류할 수는 없습니다.
4. [ ] ④ LLM은 광범위한 재교육 없이는 새로운 업무에 적용할 수 없습니다.

**Correct Answer:** 2

---

## Question 283

**Category:** LLMs
**Difficulty:** medium

### English

How does instruction fine-tuning improve the performance of LLMs?

1. [ ] It increases the model's size and complexity
2. [✓] It enables the model to understand and follow instructions more accurately.
3. [ ] It makes the model more creative and capable of generating diverse outputs.
4. [ ] It reduces the need for large-scale pre-training

### 한국어

3. 교육 세부 조정을 통해 LLM의 성과가 어떻게 향상됩니까?

1. [ ] ① 모델의 크기와 복잡성이 증가합니다.
2. [✓] ② 이를 통해 모델의 지식을 더 정확하게 이해하고 따를 수 있습니다.
3. [ ] ③ 이를 통해 모델은 더욱 창의적이 되고 다양한 결과물을 생성할 수 있습니다.
4. [ ] ④ 대규모 사전 훈련의 필요성이 줄어듭니다.

**Correct Answer:** 2

---

## Question 284

**Category:** LLMs
**Difficulty:** medium

### English

What does cross-entropy loss measure in the context of LLMs?

1. [ ] The difference between predicted and actual numerical values.
2. [✓] The dissimilarity between the predicted probability distribution of words and the actual distribution in the training data
3. [ ] The margin between correct and incorrect classifications.
4. [ ] The distance between two probability distributions.

### 한국어

4. LLM 맥락에서 교차 엔트로피 손실은 무엇을 측정합니까?

1. [ ] ① 예측된 수치와 실제 수치의 차이.
2. [✓] ② 예측된 단어의 확률 분포와 훈련 데이터에서의 실제 분포의 차이
3. [ ] ③ 올바른 분류와 잘못된 분류 사이의 차이.
4. [ ] ④ 두 확률 분포 사이의 거리.

**Correct Answer:** 2

---

## Question 285

**Category:** LLMs
**Difficulty:** medium

### English

What is the primary goal of LLM alignment?

1. [ ] Maximizing the accuracy of language models on benchmark datasets.
2. [ ] Making sure LLMs generate the most creative and entertaining responses possible.
3. [✓] Ensuring that the behavior and outputs of LLMs are in line with human values, preferences, and ethical principles
4. [ ] Reducing the computational resources required to train LLMs.

### 한국어

LLM 정의의 주요 목표는 무엇입니까?

1. [ ] 벤치마크 데이터 세트에서 얻어진 모델의 정확도를 극대화합니다.
2. [ ] LLM이 가능한 한 가장 창의적이고 재미있는 답변을 낼 수 있도록 보장합니다.
3. [✓] LLM 행동의 결과가 인간의 가치, 신뢰도 및 윤리 원칙에 부합하는지 확인합니다.
4. [ ] LLM을 훈련하는 데 필요한 컴퓨팅 리소스를 줄입니다.

**Correct Answer:** 3

---

## Question 286

**Category:** LLMs
**Difficulty:** medium

### English

Which aspect of LLM output evaluation focuses on the grammatical correctness and natural flow of the generated text?

1. [ ] Accuracy
2. [✓] Fluency
3. [ ] Relevance
4. [ ] Coherence

### 한국어

LLM 결과를 평가할 어떤 측정이 생성된 텍스트의 문법적 정확성과 자연스러운 흐름에 초점을 맞춥니까?

1. [ ] 정확성
2. [✓] 유창성
3. [ ] 관련성
4. [ ] 통일

**Correct Answer:** 2

---

## Question 287

**Category:** NLP
**Difficulty:** medium

### English

A lower perplexity score indicates:

1. [ ] The model is less confident in its predictions.
2. [ ] The model is more likely to produce grammatically incorrect sentences.
3. [✓] The model is better at predicting the next word in a sequence.
4. [ ] The model is less suitable for language generation tasks.

### 한국어

낮은 등차도 점수는 다음을 나타냅니다.

1. [ ] 해당 모델은 예측에 대한 신뢰도가 낮습니다.
2. [ ] 이 모델은 문맥적으로 관련성 있는 문장을 생성할 가능성이 더 높습니다.
3. [✓] 이 모델은 시퀀스의 다음 단어를 예측하는 데 더 뛰어납니다.
4. [ ] 이 모델은 언어 생성 작업에 적합하지 않습니다.

**Correct Answer:** 3

---

## Question 288

**Category:** LLMs
**Difficulty:** medium

### English

Why is human feedback crucial in identifying biases in LLM outputs?

1. [✓] Humans are better at detecting subtle biases and nuances in language than automated systems.
2. [ ] Humans can provide large amounts of labeled data for retraining LLMs.
3. [ ] Humans are immune to biases and can therefore provide perfectly objective feedback.
4. [ ] Human feedback is the only way to evaluate the performance of LLMs.

### 한국어

LLM 결과문의 함량을 파악하는 데 인간의 피드백이 왜 중요한가요?

1. [✓] 언어를 자동화된 시스템보다 언어 속의 미묘한 편차와 차 nuance를 더 잘 감지합니다.
2. [ ] 인간은 LLM을 추적하여 학습의 레이블이 지정된 데이터피드백을 제공할 수 있습니다.
3. [ ] 인간은 환경에 맞게 있음으로 존엄함하면서 객관적인 피드백을 제공할 수 있습니다.
4. [ ] LLM의 성과를 평가할 수 있는 유일한 방법은 인간의 피드백입니다.

**Correct Answer:** 1

---

## Question 289

**Category:** Training Techniques
**Difficulty:** medium

### English

GPUs possess dedicated high-bandwidth memory. What benefit does this provide during LLM training?

1. [ ] Enables faster data transfer between the CPU and GPU
2. [ ] Allows for the storage of larger LLM models
3. [ ] Reduces the overall power consumption of the system
4. [✓] Facilitates quick access and processing of vast amounts of training data

### 한국어

GPU는 적은 그래픽 메모리를 가지고 있습니다. 이는 LLM 학습 중에 어떤 이점을 제공합니까?

1. [ ] CPU와 GPU 간의 더 빠른 데이터 전송을 가능하게 합니다.
2. [ ] 더 큰 LLM 모델을 저장할 수 있습니다.
3. [ ] 시스템의 전체 전력을 절감할 수 있습니다.
4. [✓] 대량의 입력 교육 데이터에 대한 빠른 검색 및 처리를 용이하게 합니다.

**Correct Answer:** 4

---

## Question 290

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

What is the role of 'Data' in machine learning?

1. [✓] It provides the examples and patterns the model learns from.
2. [ ] It acts as the brain of the model.
3. [ ] It determines the accuracy of the model.
4. [ ] It has no significant role in machine learning.

### 한국어

머신러닝에서 '데이터'의 역할은 무엇인가요?

1. [✓] 모델이 학습할 예제와 패턴을 제공합니다.
2. [ ] 이는 모델의 틀이나 역할을 합니다.
3. [ ] 이는 모델의 정체성을 결정합니다.
4. [ ] 머신러닝에서는 중요한 역할이 없습니다.

**Correct Answer:** 1

---

## Question 291

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

In the context of predicting house sale prices, what is the role of the 'Algorithm'?

1. [ ] It represents the final predicted sale price of the house.
2. [ ] It is the data used to train the model, such as square footage and number of bedrooms.
3. [✓] It is the specific machine learning model (e.g., linear regression, decision tree) that learns the relationship between features like square footage and the sale price.
4. [ ] It refers to the process of selecting and transforming features, such as creating a new feature that combines square footage and a number of bedrooms.

### 한국어

주택 매매 가격을 예측하는 머신러닝에서 '출력값(목표)'의 역할은 무엇인가요?

1. [ ] 이는 주택의 실제 매매 가격을 나타냅니다.
2. [ ] 모델을 훈련하는 데 사용되는 데이터로, 입력값 될 수 없이 있습니다.
3. [✓] 이는 현재의 판매 가격 및 동의 환경을 예측하는 특정 머신 러닝 모델(예: 선형 회귀, 의사결정 트리)입니다.
4. [ ] 이는 현재의 정보 수끌 결합된 새로운 특징을 만드는 것과 같이 특징을 선택하고 변형하는 과정을 말합니다.

**Correct Answer:** 3

---

## Question 292

**Category:** Deep Learning
**Difficulty:** medium

### English

Which of the following utilizes artificial neural networks with multiple layers to learn complex patterns in data?

1. [✓] Deep Learning
2. [ ] Artificial Intelligence
3. [ ] Machine Learning
4. [ ] Robotics

### 한국어

다음 중 여러 층으로 구성된 인공 신경망을 활용하여 데이터의 복잡한 패턴을 학습하는 것은 무엇입니까?

1. [✓] 딥러닝
2. [ ] 인공지능
3. [ ] C-머신 러닝
4. [ ] 초보자 학습

**Correct Answer:** 1

---

## Question 293

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

In which type of machine learning does the algorithm learn from labeled data, where the correct output is provided for each input example?

1. [ ] Unsupervised Learning
2. [✓] Supervised Learning
3. [ ] Reinforcement Learning
4. [ ] Transfer Learning

### 한국어

각 입력 데이터에 대해 올바른 출력이 레이블이 지정된 데이터에서 알고리즘이 학습하는 머신 러닝 유형은 무엇입니까?

1. [ ] 비지도 학습
2. [✓] 지도 학습
3. [ ] C-강화 학습
4. [ ] 전이 학습

**Correct Answer:** 2

---

## Question 294

**Category:** Machine Learning Fundamentals
**Difficulty:** medium

### English

Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?

1. [ ] AI is a subset of Deep Learning, which is a subset of Machine Learning
2. [✓] Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning
3. [ ] Machine Learning and Deep Learning are completely separate from AI
4. [ ] Deep Learning is a broader concept that includes both AI and Machine Learning

### 한국어




**Correct Answer:** 2

---

## Question 295

**Category:** Reinforcement Learning
**Difficulty:** medium

### English

Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False

1. [✓] True
2. [ ] False

### 한국어




**Correct Answer:** 1

---

## Question 296

**Category:** Training Techniques
**Difficulty:** medium

### English

What is the primary purpose of feature scaling in machine learning?

1. [ ] It improves the interpretability of categorical data
2. [✓] It prevents certain features from dominating others due to different scales
3. [ ] It removes duplicate rows from the dataset
4. [ ] It eliminates the need for model validation

### 한국어




**Correct Answer:** 2

---

## Question 297

**Category:** Preprocessing
**Difficulty:** medium

### English

What is the purpose of StandardScaler() in sklearn.preprocessing?

1. [ ] It converts categorical variables into numerical values
2. [ ] It normalizes features by scaling them between 0 and 1
3. [✓] It standardizes features by removing the mean and scaling to unit variance
4. [ ] It replaces missing values in a dataset

### 한국어




**Correct Answer:** 3

---

## Question 298

**Category:** Machine Learning
**Difficulty:** medium

### English

What is a primary expectation from learning the fundamentals of machine learning?

1. [✓] Understanding different machine learning algorithms and their applications
2. [ ] Writing low-level assembly code for GPUs
3. [ ] Developing new operating systems for AI workloads
4. [ ] Designing hardware components for deep learning models

### 한국어

머신 러닝의 기본을 배우는 데 있어 가장 기대되는 것은 무엇입니까?

1. [✓] 다양한 머신 러닝 알고리즘과 그 응용 프로그램의 이해
2. [ ] GPU와 최적화 연관성을 빠르게 적기
3. [ ] 새 워크로드를 위한 새로운 운영 체제 개발
4. [ ] 머신 러닝 모델을 위한 하드웨어 구성 요소 설계

**Correct Answer:** 1

---

## Question 299

**Category:** Machine Learning
**Difficulty:** medium

### English

Which of the following best describes the relationship between AI, Machine Learning, and Deep Learning?

1. [ ] AI is a subset of Deep Learning, which is a subset of Machine Learning
2. [✓] Machine Learning is a subset of AI, and Deep Learning is a subset of Machine Learning
3. [ ] Machine Learning and Deep Learning are completely separate from AI
4. [ ] Deep Learning is a broader concept that includes both AI and Machine Learning

### 한국어

다음 중 AI, 머신러닝, 딥러닝의 관계를 가장 잘 설명하는 것은 무엇입니까?

1. [ ] AI는 머신 러닝에 의해 완전히 구현된 기술입니다.
2. [✓] 머신 러닝은 AI의 하위 집합이고 딥 러닝은 머신 러닝의 하위 집합입니다.
3. [ ] 머신러닝과 딥러닝은 AI와 완전히 별개입니다.
4. [ ] 딥러닝은 AI와 머신러닝을 모두 포함하는 더 광범위한 개념입니다.

**Correct Answer:** 2

---

## Question 300

**Category:** Reinforcement Learning
**Difficulty:** medium

### English

Reinforcement Learning involves an agent learning by interacting with an environment and receiving rewards or penalties. State True or False

1. [✓] True
2. [ ] False

### 한국어

강화 학습은 에이전트가 환경과 상호 작용하고 보상이나 페널티를 받아 학습하는 것을 포함합니다. 참 또는 거짓을 나타냅니다.

1. [✓] 진실
2. [ ] 거짓

**Correct Answer:** 1

---

## Question 301

**Category:** Machine Learning
**Difficulty:** medium

### English

What is the primary purpose of feature scaling in machine learning?

1. [ ] It improves the interpretability of categorical data
2. [✓] It prevents certain features from dominating others due to different scales
3. [ ] It removes duplicate rows from the dataset
4. [ ] It eliminates the need for model validation

### 한국어

머신 러닝에서 기능 스케일링의 주요 목적은 무엇입니까?

1. [ ] 반응형 데이터를 핵심적으로 향상시킵니다.
2. [✓] 이는 다른 규모의 연속 특징이 다른 기능과 기울기를 지배하는 것을 방지합니다.
3. [ ] 데이터의 세트에서 정확 복사를 피합니다.
4. [ ] 모델 검증의 필요성이 없습니다.

**Correct Answer:** 2

---

## Question 302

**Category:** Machine Learning
**Difficulty:** medium

### English

What is the purpose of StandardScaler() in sklearn.preprocessing?

1. [ ] It converts categorical variables into numerical values
2. [ ] It normalizes features by scaling them between 0 and 1
3. [✓] It standardizes features by removing the mean and scaling to unit variance
4. [ ] It replaces missing values in a dataset

### 한국어

sklearn.preprocessing에서 StandardScaler()의 목적은 무엇입니까?

1. [ ] 반응형 변수를 숫자 값으로 변환합니다.
2. [ ] 0과 1 사이의 스케일링으로 기능을 정규화합니다.
3. [✓] 평균과 표준편차로 입력 변수를 스케일링하여 기능을 표준화합니다.
4. [ ] 데이터 세트에서 누락된 값을 대체합니다.

**Correct Answer:** 3

---

